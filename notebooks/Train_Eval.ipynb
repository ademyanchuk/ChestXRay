{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from apex import amp\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2\n",
    "import skimage.io\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "from chestxray.config import (PANDA_PATH,\n",
    "                              MODEL_PATH,\n",
    "                              PANDA_IMGS,\n",
    "                              PANDA_MASKS,\n",
    "                              TRAIN_CSV)\n",
    "# Competition related config\n",
    "from chestxray.config import CFG\n",
    "\n",
    "# Misc\n",
    "from chestxray.misc import seed_torch\n",
    "\n",
    "# Datasets\n",
    "from chestxray.datasets import get_transforms, TrainDataset, ZeroDataset\n",
    "\n",
    "# Viz\n",
    "from chestxray.visualize import (show_from_ids, show_batch, imshow, \n",
    "                                 plot_classes_preds, reverse_show_img, \n",
    "                                 plot_confusion_matrix)\n",
    "\n",
    "# Nets\n",
    "from chestxray.nets import TinyV2ConvNet, make_RN50_cls\n",
    "from chestxray.model_utils import (trainable_params, cce_loss_at_init, \n",
    "                                   init_last_layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='GeForce RTX 2070 SUPER', major=7, minor=5, total_memory=7979MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is debug only (to check all moving parts make sense)\n",
    "CFG.debug = False\n",
    "EXP_NAME = \"rn50_512\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Writer for Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/{EXP_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = pd.read_csv(TRAIN_CSV)\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvsAAAHyCAYAAAB1ZgEbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5BuZX0n+u8PiCC4xWu8JoM6oCZqIuComOhWz1gajTERS3JMghplNKKjQio5iAkxmnFK1AQwOpgEjEwdSOHRFN6SmuAWEScqaJDxhsrGSLyj281Vkd/5412ddJpu2Jfe/e799OdT1fXs91nrt9azfMrm+65el+ruAAAA49lr3gMAAAB2DWEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFD7rMZGquq/Jzk8ySFJ7pbk+iRXJnlPktO6+7vL1ByR5MQkj0py+ySXJ/mrJKd2949X2M/Tkhyf5OFJ9k7yf5L8eXe/41bGdnSSlyT5mSQ/TvKpJCd393t36GD//bavSHLHJJt3dlsAALCCg5L8oLvvt72F1d07vfeq+mGSS5J8Nsm3khyQWYg/PMm/JHlUd//zovV/Jcm7ktyQ5JwkVyf55SQPTHJudz9rmX0cm+TUJN+dan6Y5Mgk903yxu4+fpmak5Mcl+RrSc5NcrskRyW5S5KXdvdpO3nc37397W9/lwc/+ME7s5nttnXr1iTJhg0b1nS/rC3zvD6Y5/GZ4/XBPK8P85rnz33uc7n++uuv7u67bm/taoX9/br7hmX6X5fkhCRv7e7fmfrumORLSQ5M8pju/uTCNpKcn+TRSX69u89etJ2Dknw+ybVJDuvuzVP/nZN8IskDkhzR3R9bVHNEko8m+XKSR3T39xZt6+LMvpA8aGFbO3jcFx966KGHXnzxxTu6iR2yadOmJMnGjRvXdL+sLfO8Ppjn8Znj9cE8rw/zmufDDjssl1xyySXdfdj21q7KNfvLBf3J30ztwYv6jkxy9yRnLwT9Rds4cfr44iXbeX6SfTO7JGjzoprvJfmT6eOLltQsfH7dQtCfajYnecu0veeteFAAALCH29U36P7y1F66qO8JU/vBZda/IMl1SY6oqn23seYDS9bZmRoAABjGqlzG868bqzo+yR0yu0Tn8CS/kFnQ/7+6+9vTOp+Ylh3e3be4/qWqLkvys0l+prs/N/V9O7Mbf++2ws2+12R2Wc4B3X1dVR2Q5Jok13T3LS6qqqq7Jfl2km919z224bhWuk7nQQcffPD+p59++m1tYlW5LnB9MM/rg3kenzleH8zz+jCveT7mmGNy+eWX79BlPKvyNJ5Fjk+yODx/MMlzF4L+5MCp3bLCNhb677SdNQdM6123g/sAAIChrGrY7+57JklV3SPJEUlen+RTVfW07r5kNfe1llb6FlVVF2/YsOHQtb5Jw01A64N5Xh/M8/jM8fpgnteHec3zzvwlYZdcs9/d3+zudyd5UpK7JvnrRYsXzqofeIvCf9///R2o2bKk3Z59AADAUHbpDbrdfWVmz97/2ek6+ST5wtQesnT9qtonyf2S3JTkK4sW3VrNvTK7hOdr3X3dtN9rk1yV5A7T8qUWng70xe06IAAA2IPs6qfxJMm9p3bhrbjnT+2Tl1n3sUn2T3JRd9+4qP/Wap6yZJ2dqQEAgGHsdNivqkOq6haXy1TVXtNLtX4ys/C+8Kz7c5N8J8lRVXX4ovX3S/La6eNbl2zujCQ3Jjl2einWQs2dM3tpV5K8bUnNwudXTest1ByU5CXT9s7YpoMEAIA90GrcoPtLSf5bVV2Y5Iok383siTyPS3L/JN9I8sKFlbv7B1X1wsxC/6aqOjvJ1UmenuSBU/85i3fQ3VdU1e8mOSXJJ6vqnCQ/zOwFXfdN8sbFb8+dai6qqjcleWWSS6vq3CS3S/LsJHdJ8tKdeXsuAADs7lYj7P+vJP8xs2fqPzyzx1lem9n18O9Mckp3X724oLvfU1WPS/KqJM9Msl+SL2UWzE/pZR7+392nVtXmzB7v+VuZ/VXis0lO7O53LDew7j6uqj6T2Zn8Y5LcnOSSJG/o7vfu5HEDAMBubafDfndfluTYHaj7aGZ/FdiemvOSnLedNWcmOXN7agAAYARrcYMuAAAwB8I+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKBW4zn7zMFlV23Jc3//ffMexpra/PqnznsIAAB7FGf2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAg9pn3gMAVnbZVVvy3N9/37yHsaY2v/6p8x4CAAzDmX0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABjUTof9qrprVb2gqt5dVV+qquuraktVXVhVv11Vey1Z/6Cq6lv5OftW9nV0VX28qq6Z9rGpqp52K+vvXVWvqKpLp3FdXVXvr6ojdva4AQBgd7fPKmzjWUnemuTrST6U5KtJ7pHk15L8RZKnVNWzuruX1P1Tkvcss73LlttJVZ2c5LgkX0vy9iS3S3JUkvOq6qXdfdqS9SvJ2UmOTPKFJKcluUuSZye5oKqe2d1/u/2HCwAAe4bVCPtfTPL0JO/r7psXOqvqhCQfT/LMzIL/u5bUfbq7T9qWHUxn4o9L8uUkj+ju7039b0hycZKTq+q93b15UdlRmQX9i5I8sbtvmGreluTCJG+vqvO7e+v2HS4AAOwZdvoynu4+v7vPWxz0p/5vJHnb9HHjTu7mRVP7uoWgP+1jc5K3JNk3yfOW1Lx4ak9cCPpTzSeSnJPk7pl9GQAAgCHt6ht0fzS1Ny2z7N5V9V+q6oSpfditbOcJU/vBZZZ9YMk6qar9khyR5LokH9mWGgAAGE3d8lL6Vdpw1T5JPpXkIUme3N1/N/UflOSKFco2JTm6u7+6aDsHJLkmyTXdvWGZ/dwtybeTfKu77zH1/Wxm1/5f1t0PXabm8CSfSPLx7n7kNhzLxSssetDBBx+8/+mnn35bm1hVW7duzQ0/ujnfvH5Ndzt3D7nPgfMewpoyz+vD1q2zKwk3bLjFrzcGYY7XB/O8Psxrno855phcfvnll3T3YdtbuyvP7L8+s6D//oWgP7kuyR8nOSzJnaefx2V2c+/GJP8wBfwFC//l37LCfhb677STNQAAMJTVuEH3FqrqZZndUPv5JL+5eFl3fyvJHywpuaCqnpTZjbOPTPKCJH+2K8a2I1b6FlVVF2/YsOHQjRs3rul4Nm3alCuv2pKTP7NLpm+3tfk5G+c9hDVlnteHTZs2JUnW+vcIa8ccrw/meX2Y1zzvzF8SVv3MflUdm1lQ/2ySx3f31dtS1903ZfaoziR57KJFC2fhV/rb/kL/93eyBgAAhrKqYb+qXp7k1Myul3/89ESe7fHtqf3Xy3i6+9okVyW5Q1Xda5mag6f2i4v6vpzkx0nuP907sC01AAAwlFUL+1X1e0nenOTTmQX9b+3AZh41tV9Z0n/+1D55mZqnLFkn06M2L0qyf5Jf3JYaAAAYzaqE/ap6dWY35F6c2QusvnMr6x5aVbfYb1U9Mckrpo9nLVm88Lz+V1XVnRfVHJTkJUluTHLGkpq3Tu1rp0dxLtQ8IrO36H47t3zRFwAADGOn7/yrqqOTvCazy2Y+kuRlVbV0tc3dfeb07zclObiqLkrytanvYfm3Z96/ursvWlzc3RdV1ZuSvDLJpVV1bpLbZRba75LkpUvenpskZ2f25t4jk3yqqs5LctepZu8kL+zuH+zocQMAwO5uNR7zcb+p3TvJy1dY58NJzpz+/c4kv5rkEZldTvMTSb6Z5G+SnNbdy70EK919XFV9JrMz+cckuTnJJUne0N3vXWb9rqpfz+xynucneWmSG5JckOS1S79QAADAaHY67Hf3SUlO2o71/zLJX+7gvs7Mv31p2Jb1b8rsPoI378j+AABgT7YrX6oFAADMkbAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAY1E6H/aq6a1W9oKreXVVfqqrrq2pLVV1YVb9dVcvuo6qOqKr3V9XVU82lVfXyqtr7Vvb1tKraNG3/mqr6x6o6+jbGd3RVfXxaf8tU/7SdPW4AANjdrcaZ/WcleXuSRyb5xyR/muRdSR6S5C+S/E1V1eKCqvqVJBckeWySdyc5Lcntkrw5ydnL7aSqjk1y3rTds6Z93jvJmVV18go1Jyc5M8m9pvXPSvLQJOdN2wMAgGHtswrb+GKSpyd5X3ffvNBZVSck+XiSZyb5tcy+AKSq7phZ8P5xko3d/cmp/9VJzk9yZFUd1d1nL9rWQUlOTnJ1ksO7e/PU/5okn0hyXFW9q7s/tqjmiCTHJflykkd09/em/jckuTjJyVX13oVtAQDAaHb6zH53n9/d5y0O+lP/N5K8bfq4cdGiI5PcPcnZC0F/Wv+GJCdOH1+8ZDfPT7JvktMWh/MpwP/J9PFFS2oWPr9uIehPNZuTvGXa3vNu+wgBAGDPtBpn9m/Nj6b2pkV9T5jaDy6z/gVJrktyRFXt2903bkPNB5assy37+UCSV0/r/OHyQ/83VXXxCosetHXr1mzatOm2NrGqtm7dmnvcPjn+oTfd9soDWev/nefNPK8PW7duTbL+jns9Mcfrg3leH+Y1zwv73RG77Gk8VbVPkt+aPi4O3A+c2i8urenum5JckdmXkPtvY83Xk1yb5L5Vtf+07wOS3CfJNdPypS6f2kO26WAAAGAPtCvP7L8+s5tp39/df7eo/8Cp3bJC3UL/nbaz5oBpvet2cB8r6u7Dluuvqos3bNhw6MaNG7dlM6tm06ZNufKqLTn5M7v6DzO7l83P2TjvIawp87w+LJwdWuvfI6wdc7w+mOf1YV7zvGHDhh2u3SVn9qvqZZndHPv5JL+5K/YBAADculUP+9MjLf8syWeTPL67r16yysJZ9QOzvIX+7+9AzZYl7fbsAwAAhrKqYb+qXp7k1CSXZRb0v7HMal+Y2ltcLz9d53+/zG7o/co21twrs0t4vtbd1yVJd1+b5Kokd5iWL3Xw1N7iHgAAABjFqoX9qvq9zF6K9enMgv63Vlj1/Kl98jLLHptk/yQXLXoSz23VPGXJOjtTAwAAw1iVsD+9EOv1mb2s6ond/Z1bWf3cJN9JclRVHb5oG/slee308a1Las5IcmOSY6cXbC3U3DnJCdPHty2pWfj8qmm9hZqDkrxk2t4Zt35kAACw59rpx3xU1dFJXpPZG3E/kuRlVbV0tc3dfWaSdPcPquqFmYX+TVV1dmZvxn16Zo/YPDfJOYuLu/uKqvrdJKck+WRVnZPkh5m9oOu+Sd64+O25U81FVfWmJK9McmlVnZvkdkmeneQuSV7q7bkAAIxsNZ7pd7+p3TvJy1dY58NJzlz40N3vqarHJXlVkmcm2S/JlzIL5qd0dy/dQHefWlWbkxyf2fP798rsJuATu/sdy+20u4+rqs9kdib/mCQ3J7kkyRu6+73bd5gAALBn2emw390nJTlpB+o+muSXtrPmvCTnbWfNmVn0RQMAANaLXfYGXQAAYL6EfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAYl7AMAwKCEfQAAGJSwDwAAgxL2AQBgUMI+AAAMStgHAIBBCfsAADAoYR8AAAa1KmG/qo6sqlOr6iNV9YOq6qo6a4V1D5qWr/Rz9q3s5+iq+nhVXVNVW6pqU1U97VbW37uqXlFVl1bV9VV1dVW9v6qOWI3jBgCA3dk+q7SdE5P8XJJrknwtyYO2oeafkrxnmf7Lllu5qk5Octy0/bcnuV2So5KcV1Uv7e7TlqxfSc5OcmSSLyQ5Lcldkjw7yQVV9czu/tttGCcAAOyRVivsvyKzEP6lJI9L8qFtqPl0d5+0LRufzsQfl+TLSR7R3d+b+t+Q5OIkJ1fVe7t786KyozIL+hcleWJ33zDVvC3JhUneXlXnd/fWbRkDAADsaVblMp7u/lB3X97dvRrbW8aLpvZ1C0F/2u/mJG9Jsm+S5y2pefHUnrgQ9KeaTyQ5J8ndM/syAAAAQ5rnDbr3rqr/UlUnTO3DbmXdJ0ztB5dZ9oEl66Sq9ktyRJLrknxkW2oAAGA0q3UZz474z9PPv6qqTUmO7u6vLuo7IMl9klzT3V9fZjuXT+0hi/oekGTvJF/p7pu2sWZFVXXxCosetHXr1mzatGlbNrNqtm7dmnvcPjn+ocsd2rjW+n/neTPP68PWrbMrCdfbca8n5nh9MM/rw7zmeWG/O2IeZ/avS/LHSQ5LcufpZ+E6/41J/mEK+AsOnNotK2xvof9OO1kDAABDWfMz+939rSR/sKT7gqp6UmY3zj4yyQuS/Nlaj20l3X3Ycv1VdfGGDRsO3bhx45qOZ9OmTbnyqi05+TPz/MPM2tv8nI3zHsKaMs/rw8LZobX+PcLaMcfrg3leH+Y1zxs2bNjh2t3mpVrT5TZ/MX187KJFC2fhD8zyFvq/v5M1AAAwlN0m7E++PbX/ehlPd1+b5Kokd6iqey1Tc/DUfnFR35eT/DjJ/atqudOiy9UAAMBQdrew/6ip/cqS/vOn9snL1DxlyTqZHrV5UZL9k/zittQAAMBo1jzsV9WhVXWL/VbVEzN7OVeSnLVk8dum9lVVdedFNQcleUmSG5OcsaTmrVP72ulRnAs1j8jsLbrfTvKuHTsKAADY/a3KnX9V9Ywkz5g+3nNqH11VZ07//k53Hz/9+01JDq6qizJ7626SPCz/9sz7V3f3RYu3390XVdWbkrwyyaVVdW6S22UW2u+S5KVL3p6bJGcn+bXMXpz1qao6L8ldp5q9k7ywu3+w40cNAAC7t9V6zMfPJzl6Sd/9p58kuTLJQth/Z5JfTfKIzC6n+Ykk30zyN0lO6+7lXoKV7j6uqj6T2Zn8Y5LcnOSSJG/o7vcus35X1a9ndjnP85O8NMkNSS5I8tqlXygAAGA0qxL2u/ukJCdt47p/meQvd3A/ZyY5czvWvynJm6cfAABYV3a3G3QBAIBVIuwDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFD7zHsAAOvdZVdtyXN//33zHsaa2vz6p857CADrgjP7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIPaZ94DAAAYwWVXbclzf/998x7Gmtr8+qfOewjcBmEfAHYxIRCYF5fxAADAoJzZBwBghxy0zv5idfxDb8pD7nPgvIexXZzZBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwKGEfAAAGJewDAMCghH0AABiUsA8AAIMS9gEAYFDCPgAADErYBwCAQQn7AAAwqFUJ+1V1ZFWdWlUfqaofVFVX1Vm3UXNEVb2/qq6uquur6tKqenlV7X0rNU+rqk1VtaWqrqmqf6yqo29jP0dX1cen9bdM9U/b0WMFAIA9xWqd2T8xybFJfj7JVbe1clX9SpILkjw2ybuTnJbkdknenOTsFWqOTXJekockOSvJ25PcO8mZVXXyCjUnJzkzyb2m9c9K8tAk503bAwCAYa1W2H9FkkOS3DHJi29txaq6Y2bB+8dJNnb3b3f372b2ReFjSY6sqqOW1ByU5OQkVyc5vLtf0t2vSPKwJF9OclxVPXpJzRFJjpuWP6y7X9HdL0ly2LSdk6ftAgDAkFYl7Hf3h7r78u7ubVj9yCR3T3J2d39y0TZuyOwvBMktvzA8P8m+SU7r7s2Lar6X5E+mjy9aUrPw+XXTegs1m5O8Zdre87ZhvAAAsEeqbcvn27HBqo1JPpTkf3b3byyz/Kwkz0nyf3f3/7tk2T5JtmR2Sc8duvvGqf/CJI9JckR3f2xJzb2S/EuSr3X3Ty3q/1qS+yS5d3d/fUnNo5NclOTC7v7FbTimi1dY9KCDDz54/9NPP/22NrGqtm7dmht+dHO+ef2a7nbuHnKfA+c9hDVlntcH8zw+c7w+rNd5Xm/ucftkv5/YKxs2bFjT/R5zzDG5/PLLL+nuw7a3dh5P43ng1H5x6YLuvinJFUn2SXL/baz5epJrk9y3qvZPkqo6ILOgf83SoD+5fGoP2ZEDAACAPcE+c9jnwlf9LSssX+i/03bWHDCtd90O7mNFK32LqqqLN2zYcOjGjRu3ZTOrZtOmTbnyqi05+TPzmL752fycjfMewpoyz+uDeR6fOV4f1us8rzfHP/SmPOQuG7LW2W9n/pLgOfsAADCoeYT9hbPqK13Mt9D//R2o2bKk3Z59AADAUOYR9r8wtbe4Xn66Qfd+SW5K8pVtrLlXZpfwfK27r0uS7r42s+f932FavtTBU3uLewAAAGAU8wj750/tk5dZ9tgk+ye5aOFJPNtQ85Ql6+xMDQAADGMeYf/cJN9JclRVHb7QWVX7JXnt9PGtS2rOSHJjkmMXvwirqu6c5ITp49uW1Cx8ftW03kLNQUleMm3vjB0/DAAA2L2tyi3jVfWMJM+YPt5zah9dVWdO//5Odx+fJN39g6p6YWahf1NVnZ3ZG22fntkjNs9Ncs7i7Xf3FVX1u0lOSfLJqjonyQ8ze0HXfZO8cenz97v7oqp6U5JXJrm0qs7N7Pn9z05ylyQvXfyCLgAAGM1qPR/q55McvaTv/vm3Z+VfmeT4hQXd/Z6qelySVyV5ZpL9knwps2B+ynJv4u3uU6tq87Sd38rsrxKfTXJid79juUF193FV9ZnMzuQfk+TmJJckeUN3v3fHDhUAAPYMqxL2u/ukJCdtZ81Hk/zSdtacl+S87aw5M8mZ21MDAAAj8Jx9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoOYW9qtqc1X1Cj/fWKHmiKp6f1VdXVXXV9WlVfXyqtr7VvbztKraVFVbquqaqvrHqjp61x0ZAADsHvaZ8/63JPnTZfqvWdpRVb+S5F1JbkhyTpKrk/xykjcneUySZy1Tc2ySU5N8N8lZSX6Y5MgkZ1bVQ7v7+NU5DAAA2P3MO+x/v7tPuq2VquqOSd6e5MdJNnb3J6f+Vyc5P8mRVXVUd5+9qOagJCdn9qXg8O7ePPW/JsknkhxXVe/q7o+t5gEBAMDuYk+5Zv/IJHdPcvZC0E+S7r4hyYnTxxcvqXl+kn2TnLYQ9Kea7yX5k+nji3bVgAEAYN7mfWZ/36r6jSQ/neTaJJcmuaC7f7xkvSdM7QeX2cYFSa5LckRV7dvdN25DzQeWrAMAAMOp7p7Pjqs2J/kPyyy6IsnzuvvDi9b9RJLDM7sc5+JltnVZkp9N8jPd/bmp79tJ7pbkbt393WVqrklyQJIDuvu62xjrLfY5edDBBx+8/+mnn35r5atu69atueFHN+eb16/pbufuIfc5cN5DWFPmeX0wz+Mzx+vDep3n9eYet0/2+4m9smHDhjXd7zHHHJPLL7/8ku4+bHtr53kZzxlJnpjknpmF7ocm+R9JDkrygar6uUXrLvzG2LLCthb677QDNevrtxEAAOvG3C7j6e4/WtJ1WZIXTWfcj0tyUpJfXetxLWelb1FVdfGGDRsO3bhx45qOZ9OmTbnyqs7ypqAAAAstSURBVC05+TPzvgprbW1+zsZ5D2FNmef1wTyPzxyvD+t1nteb4x96Ux5ylw1Z6+y3M39J2B1v0H3b1D52Ud9tnYVf6P/+DtSsdOYfAAD2aLtj2P/21B6wqO8LU3vI0pWrap8k90tyU5KvbGPNvabtf+22rtcHAIA91e4Y9h81tYuD+/lT++Rl1n9skv2TXLToSTy3VfOUJesAAMBw5hL2q+rBVXXAMv0HJTlt+njWokXnJvlOkqOq6vBF6++X5LXTx7cu2dwZSW5Mcuy03YWaOyc5Yfr4tgAAwKDmdRfJszN7g+0FSa5MsjXJA5I8Ncl+Sd6f2dtvkyTd/YOqemFmoX9TVZ2d2Ztxn57kgVP/OYt30N1XVNXvJjklySer6pwkP8zsBV33TfJGb88FAGBk8wr7H8ospD88yWMyu37++0kuTPLOJO/sJS8A6O73VNXjkrwqyTMz+1LwpSSvTHLK0vWnmlOn5/kfn+S3MvtLxmeTnNjd79g1hwYAALuHuYT96YVZH77NFW9Z99Ekv7SdNeclOW979wUAAHu63fEGXQAAYBUI+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEENH/ar6r5V9VdV9S9VdWNVba6qP62qO897bAAAsCvtM+8B7EpV9YAkFyX5ySR/m+TzSf5Tkv+a5MlV9Zju/u4chwgAALvM6Gf2/zyzoP+y7n5Gd/9+dz8hyZuTPDDJ6+Y6OgAA2IWGDfvTWf0nJdmc5C1LFv9hkmuT/GZVHbDGQwMAgDUxbNhP8vip/fvuvnnxgu7emuSjSfZP8qi1HhgAAKyF6u55j2GXqKo3JDk+yfHd/cZllp+W5CVJfqe733ob27p4hUU/t+++++790z/90zs93u1x88035+bu3HTzba87kv1+Yu95D2FNmef1wTyPzxyvD+t1ntebffZK9qrKXnut7fnyr371q7nxxhuv7u67bm/tyDfoHji1W1ZYvtB/p53Yx49vvPHGLZdffvnmndjGjnjQ1H5+jffL2jLP64N5Hp85Xh/M8/owr3k+KMkPdqRw5LC/arr7sHmPYbGFvzTsbuNidZnn9cE8j88crw/meX3YE+d55Gv2F87cH7jC8oX+76/BWAAAYM2NHPa/MLWHrLD84Kn94hqMBQAA1tzIYf9DU/ukqvp3x1lVG5I8Jsl1Sf73Wg8MAADWwrBhv7u/nOTvM7uh4SVLFv9RkgOSvLO7r13joQEAwJoY/Qbd30lyUZJTquqJST6X5JGZPYP/i0leNcexAQDALjXsc/YXVNVPJXlNkicnuWuSryd5d5I/6u7vzXNsAACwKw0f9gEAYL0a9pp9AABY74R9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhfw9SVfetqr+qqn+pqhuranNV/WlV3XneY2N1VNWRVXVqVX2kqn5QVV1VZ817XKyeqrprVb2gqt5dVV+qquuraktVXVhVv11Vfi8Poqr+e1X9Q1X98zTPV1fVp6rqD6vqrvMeH7tGVf3G9Lu7q+oF8x4PO2/KW73CzzfmPb7b4qVae4iqekCSi5L8ZJK/TfL5JP8pyeOTfCHJY7r7u/MbIauhqj6d5OeSXJPka0kelOR/dvdvzHVgrJqqelGSt2b2Nu8PJflqknsk+bUkByZ5V5JntV/Oe7yq+mGSS5J8Nsm3khyQ5FFJDk/yL0ke1d3/PL8Rstqq6qeSfCbJ3knukOSF3f0X8x0VO6uqNie5U5I/XWbxNd198tqOaPvsM+8BsM3+PLOg/7LuPnWhs6relOQVSV6X5EVzGhur5xWZhfwvJXlcZmGQsXwxydOTvK+7b17orKoTknw8yTMzC/7vms/wWEV37O4blnZW1euSnJDk/0nyO2s+KnaJqqokZyT5bpL/L8nx8x0Rq+z73X3SvAexI/y5eA8wndV/UpLNSd6yZPEfJrk2yW9W1QFrPDRWWXd/qLsvd1Z3XN19fneftzjoT/3fSPK26ePGNR8Yq265oD/5m6k9eK3Gwpp4WZInJHleZv9dht2CsL9nePzU/v0yAWFrko8m2T+zPw8De64fTe1Ncx0Fu9ovT+2lcx0Fq6aqHpzk9Un+rLsvmPd42CX2ne7HOKGq/mtVPb6q9p73oLaFy3j2DA+c2i+usPzyzM78H5LkH9ZkRMCqqqp9kvzW9PGD8xwLq6uqjs/s+u0DM7te/xcyC/qvn+e4WB3T/3ffmdn9NyfMeTjsOvfMbJ4Xu6KqntfdH57HgLaVsL9nOHBqt6ywfKH/TmswFmDXeH2ShyR5f3f/3bwHw6o6PrObsBd8MMlzu/vbcxoPq+sPkjw8yS909/XzHgy7xBlJPpLk/yTZmuT+SY5NckySD1TVo7v7n+Y4vlvlMh6AOauqlyU5LrOnbP3mnIfDKuvue3Z3ZXZm8NcyCwqfqqpD5zsydlZVPTKzs/lv7O6PzXs87Brd/UfT/Vbf7O7ruvuy7n5RkjcluX2Sk+Y7wlsn7O8ZFs7cH7jC8oX+76/BWIBVVFXHJvmzzB7P+PjuvnrOQ2IXmYLCuzO77PKuSf56zkNiJ0yX7/x1ZpfYvnrOw2E+Fh6q8Ni5juI2CPt7hi9M7SErLF94osNK1/QDu6GqenmSU5NcllnQ3+1fzsLO6+4rM/ty97NVdbd5j4cddofM/rv84CQ3LH7RUmZPykuSt099yz2fnT3fwqV4u/XTEF2zv2dYeNb6k6pqryXP5t6Q5DFJrkvyv+cxOGD7VdXvZXad/qeT/Ofu/s6ch8TauvfU/niuo2Bn3JjkL1dYdmhm1/FfmNkJO5f4jGnhKYhfmesoboOwvwfo7i9X1d9n9qffl2R2JnDBH2X2jfJ/dLfn+sIeoKpeneQ1SS5O8iSX7oynqg5J8s3u3rKkf68kf5zZSxIv6u7vzWN87LzpZtwXLLesqk7KLOy/wxt092zTY1W/ujRjVdVBSU6bPp61xsPaLsL+nuN3klyU5JSqemKSzyV5ZGbP4P9iklfNcWyskqp6RpJnTB/vObWPrqozp39/p7u9lXEPVlVHZxb0f5zZ0x1eNnvx5r+zubvPXOOhsbp+Kcl/q6oLk1yR2VtV75HZm7Hvn+QbSV44v+EB2+jZSY6rqguSXJnZ03gekOSpSfZL8v4kJ89veLdN2N9DTGf3D88sJDw5s/+QfD2zG/v+yNmhYfx8kqOX9N1/+klmv2iE/T3b/aZ27yQvX2GdDyc5c01Gw67yv5L8x8yeqf/wzB6NfG1mJ2femeQUf9GBPcKHMnvf0cMzu2z6gMweiHJhZv9ffufu/tb72s3HBwAA7CBP4wEAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAxK2AcAgEEJ+wAAMChhHwAABiXsAwDAoIR9AAAYlLAPAACDEvYBAGBQwj4AAAzq/wci1KRP5hsUgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 381
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = TRAIN_DF[CFG.target_col].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Eval Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_loop(train_dataset, val_dataset, model, optimizer, criterion, batch_sz=CFG.batch_size, num_epochs=CFG.epoch, tb_tag=\"\", model_name=\"debug\"):\n",
    "    # Write first layer weights to TB\n",
    "    if not CFG.debug:\n",
    "        conv1_weight = model.conv1.weight.data.to(\"cpu\")\n",
    "        img_grid = torchvision.utils.make_grid(conv1_weight, normalize=True)\n",
    "        writer.add_image(tag=f\"Model conv1 weights {tb_tag}\", img_tensor=img_grid, global_step=0)\n",
    "    \n",
    "    # define a data loader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_sz, shuffle=True, num_workers=6)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_sz, shuffle=False, num_workers=4)\n",
    "    model.to(device)\n",
    "    if CFG.use_amp:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "    \n",
    "#     scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n",
    "#     scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    # Define epochs numbers to look into input images and predictions\n",
    "    # No more than 10 times per full training\n",
    "    vis_step = np.ceil(num_epochs/10).astype(int)\n",
    "    visual_epochs = list(range(0, num_epochs, vis_step))\n",
    "    \n",
    "#     best_qwk = -100\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Training Phase\n",
    "        # Set training mode\n",
    "        model.train();\n",
    "        train_running_loss = 0.0\n",
    "        train_epoch_preds, train_epoch_labels = [], []\n",
    "        # create random step\n",
    "        rand_step = np.random.randint(0, len(train_dataloader))\n",
    "        \n",
    "        # Iterate over train data.\n",
    "        tk_train = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for i, data in tk_train:\n",
    "            # Calculate global step\n",
    "            train_global_step = epoch * len(train_dataloader) + i\n",
    "            \n",
    "            inputs, labels = data\n",
    "            # Visualize input to the model:\n",
    "            if epoch in visual_epochs and i == rand_step:\n",
    "                img = reverse_show_img(inputs[0])\n",
    "                writer.add_image(tag=f\"Input Image {tb_tag}\", img_tensor=img, global_step=train_global_step, dataformats=\"HWC\")\n",
    "                del img\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            if CFG.use_amp:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            # loss is mean across batch, multiply by batch size\n",
    "            # divide by number of steps in epoch (so loss is normalized)\n",
    "            train_running_loss += loss.item() / len(train_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Training loss {tb_tag}\", scalar_value=loss.item(), global_step=train_global_step)\n",
    "            \n",
    "            # collect train preds and labels for QWK\n",
    "            train_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            train_epoch_labels.append(labels.to('cpu').numpy())\n",
    "        \n",
    "        # Validation Phase\n",
    "        # Set evaluation mode\n",
    "        model.eval();\n",
    "        val_running_loss = 0.0\n",
    "        val_epoch_preds, val_epoch_labels = [], []\n",
    "        # Iterate over val data\n",
    "        tk_val = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "        for j, data in tk_val:\n",
    "            # Calculate global step\n",
    "            val_global_step = epoch * len(val_dataloader) + j\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() / len(val_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Validation loss {tb_tag}\", scalar_value=loss.item(), global_step=val_global_step)\n",
    "            \n",
    "            # collect validation preds and labels for QWK\n",
    "            val_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            val_epoch_labels.append(labels.to('cpu').numpy())\n",
    "            \n",
    "            # visualise predictions for 0th validation batch\n",
    "            if epoch in visual_epochs and j == 0:\n",
    "                writer.add_figure(tag=f\"Actuals vs Predictions {tb_tag}\", figure=plot_classes_preds(outputs.to('cpu'), inputs.to('cpu'), labels.to('cpu')), \n",
    "                                  global_step=val_global_step)\n",
    "        \n",
    "#         scheduler.step()\n",
    "        # \"End of Epoch\" Phase\n",
    "        print(f'Training Loss: {train_running_loss:.4f}\\tValidation Loss: {val_running_loss:.4f}')\n",
    "        \n",
    "        # Calculate epoch QWK and preds distribution\n",
    "        train_epoch_preds = np.concatenate(train_epoch_preds)\n",
    "        train_epoch_labels = np.concatenate(train_epoch_labels)\n",
    "        val_epoch_preds = np.concatenate(val_epoch_preds)\n",
    "        val_epoch_labels = np.concatenate(val_epoch_labels)\n",
    "        print(f'Counter train preds: {Counter(train_epoch_preds)}\\tCounter val preds: {Counter(val_epoch_preds)}')\n",
    "        \n",
    "        train_qwk = cohen_kappa_score(train_epoch_preds, train_epoch_labels, weights='quadratic')\n",
    "        val_qwk = cohen_kappa_score(val_epoch_preds, val_epoch_labels, weights='quadratic')\n",
    "        print(f\"Epoch train QWK: {train_qwk:.3f}\\tval QWK: {val_qwk:.3f}\")\n",
    "        writer.add_scalar(tag=f\"Training QWK {tb_tag}\", scalar_value=train_qwk, global_step=epoch)\n",
    "        writer.add_scalar(tag=f\"Validation QWK {tb_tag}\", scalar_value=val_qwk, global_step=epoch)\n",
    "        \n",
    "        # On the best val loss do:\n",
    "        if val_running_loss < best_val_loss:\n",
    "            # update best and save model\n",
    "            best_val_loss = val_running_loss\n",
    "            print(f'  Epoch {epoch} - Save Best Loss: {best_val_loss:.4f} Model')\n",
    "            torch.save(model.state_dict(), f'{MODEL_PATH}/{model_name}.pth')\n",
    "            \n",
    "            # add losses as text to TB\n",
    "            writer.add_text(\"On save:\", \n",
    "                            f\"tr_loss: {train_running_loss:.4f}, tr_qwk: {train_qwk:.4f}, val_loss: {val_running_loss:.4f}, val_qwk: {val_qwk:.4f}\",\n",
    "                            global_step=train_global_step)\n",
    "            \n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                conv1_weight = model.conv1.weight.data.to(\"cpu\")\n",
    "                img_grid = torchvision.utils.make_grid(conv1_weight, normalize=True)\n",
    "                writer.add_image(tag=f\"Model conv1 weights {tb_tag}\", img_tensor=img_grid, global_step=train_global_step)\n",
    "            \n",
    "            # add confusion matrix to TB\n",
    "            writer.add_figure(tag=f\"Confusion matrix {tb_tag}\", figure=plot_confusion_matrix(val_epoch_labels, val_epoch_preds), \n",
    "                                  global_step=val_global_step)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CV - strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    folds_fn = \"folds_db.csv\"\n",
    "    try: \n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.sample(n=100, random_state=CFG.seed).reset_index(drop=True).copy()\n",
    "else:\n",
    "    folds_fn = \"folds.csv\"\n",
    "    try:\n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PANDA_PATH/folds_fn).exists():\n",
    "    train_labels = folds[CFG.target_col].values\n",
    "    kf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n",
    "        folds.loc[val_index, 'fold'] = int(fold)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(PANDA_PATH/folds_fn, index=None)\n",
    "    folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10616 entries, 0 to 10615\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   image_id       10616 non-null  object\n",
      " 1   data_provider  10616 non-null  object\n",
      " 2   isup_grade     10616 non-null  int64 \n",
      " 3   gleason_score  10616 non-null  object\n",
      " 4   fold           10616 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 414.8+ KB\n"
     ]
    }
   ],
   "source": [
    "folds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/498 [00:01<04:08,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/498 [00:02<02:55,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–Ž         | 18/498 [00:06<02:41,  2.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-171b7725ea1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_eval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b0b558dde5a9>\u001b[0m in \u001b[0;36mtrain_eval_loop\u001b[0;34m(train_dataset, val_dataset, model, optimizer, criterion, batch_sz, num_epochs, tb_tag, model_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[0;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "\n",
    "model_ft = make_RN50_cls()\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "train_eval_loop(train_ds, val_ds, model_ft, optimizer, criterion, num_epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'chestxray.config', 'debug': False, 'use_amp': True, 'img_height': 512, 'img_width': 512, 'lr': 0.0001, 'batch_size': 16, 'epoch': 30, 'seed': 1982, 'target_size': 6, 'img_id_col': 'image_id', 'target_col': 'isup_grade', 'n_fold': 4, '__dict__': <attribute '__dict__' of 'CFG' objects>, '__weakref__': <attribute '__weakref__' of 'CFG' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "print(CFG.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Experiment Description:\", f\"{CFG.__dict__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/498 [00:01<04:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/498 [00:02<03:08,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:36<00:00,  3.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:16<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4665\tValidation Loss: 1.4490\n",
      "Counter train preds: Counter({0: 3032, 1: 2581, 5: 993, 3: 546, 4: 509, 2: 301})\tCounter val preds: Counter({0: 1226, 1: 761, 3: 299, 2: 266, 5: 66, 4: 36})\n",
      "Epoch train QWK: 0.500\tval QWK: 0.468\n",
      "  Epoch 0 - Save Best Loss: 1.4490 Model\n",
      "Confusion matrix, without normalization\n",
      "[[659  53   2   5   2   2]\n",
      " [311 304  27  19   3   2]\n",
      " [ 72 166  60  34   1   2]\n",
      " [ 56 105  48  87   6   9]\n",
      " [ 82  88  60  61  11  11]\n",
      " [ 46  45  69  93  13  40]]\n",
      "Epoch 1/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:25<00:00,  3.43it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3407\tValidation Loss: 1.3155\n",
      "Counter train preds: Counter({0: 2896, 1: 2475, 5: 1001, 4: 639, 3: 516, 2: 435})\tCounter val preds: Counter({0: 862, 1: 632, 5: 470, 4: 306, 2: 269, 3: 115})\n",
      "Epoch train QWK: 0.592\tval QWK: 0.633\n",
      "  Epoch 1 - Save Best Loss: 1.3155 Model\n",
      "Confusion matrix, without normalization\n",
      "[[557 111   1   5  34  15]\n",
      " [177 306  91  18  55  19]\n",
      " [ 34 102  90  24  34  51]\n",
      " [ 38  44  55  28  41 105]\n",
      " [ 32  48  18  24  97  94]\n",
      " [ 24  21  14  16  45 186]]\n",
      "Epoch 2/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:29<00:00,  3.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2716\tValidation Loss: 1.3196\n",
      "Counter train preds: Counter({0: 2722, 1: 2534, 5: 998, 4: 689, 2: 518, 3: 501})\tCounter val preds: Counter({0: 883, 1: 742, 5: 611, 2: 209, 4: 106, 3: 103})\n",
      "Epoch train QWK: 0.629\tval QWK: 0.626\n",
      "Epoch 3/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:31<00:00,  3.28it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:16<00:00, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1939\tValidation Loss: 1.3221\n",
      "Counter train preds: Counter({0: 2673, 1: 2474, 5: 954, 4: 730, 3: 591, 2: 540})\tCounter val preds: Counter({0: 1126, 1: 604, 5: 441, 4: 267, 2: 111, 3: 105})\n",
      "Epoch train QWK: 0.660\tval QWK: 0.615\n",
      "Epoch 4/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 183/498 [00:52<01:33,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:21<00:00,  3.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0790\tValidation Loss: 1.6279\n",
      "Counter train preds: Counter({0: 2531, 1: 2415, 5: 989, 4: 784, 2: 660, 3: 583})\tCounter val preds: Counter({0: 1435, 1: 537, 4: 373, 5: 155, 3: 98, 2: 56})\n",
      "Epoch train QWK: 0.723\tval QWK: 0.543\n",
      "Epoch 5/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9349\tValidation Loss: 1.6240\n",
      "Counter train preds: Counter({0: 2469, 1: 2291, 5: 1004, 4: 831, 2: 700, 3: 667})\tCounter val preds: Counter({1: 1202, 0: 760, 4: 458, 3: 127, 5: 57, 2: 50})\n",
      "Epoch train QWK: 0.782\tval QWK: 0.575\n",
      "Epoch 6/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7516\tValidation Loss: 1.9702\n",
      "Counter train preds: Counter({0: 2333, 1: 2245, 5: 981, 4: 925, 2: 775, 3: 703})\tCounter val preds: Counter({1: 1508, 0: 540, 2: 289, 4: 164, 3: 89, 5: 64})\n",
      "Epoch train QWK: 0.840\tval QWK: 0.483\n",
      "Epoch 7/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:18<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5690\tValidation Loss: 1.8170\n",
      "Counter train preds: Counter({0: 2264, 1: 2141, 4: 959, 5: 953, 2: 893, 3: 752})\tCounter val preds: Counter({0: 1172, 5: 527, 1: 370, 4: 255, 2: 246, 3: 84})\n",
      "Epoch train QWK: 0.889\tval QWK: 0.604\n",
      "Epoch 8/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3986\tValidation Loss: 2.5961\n",
      "Counter train preds: Counter({0: 2227, 1: 2087, 4: 943, 5: 941, 2: 932, 3: 832})\tCounter val preds: Counter({1: 1270, 0: 573, 2: 313, 3: 243, 4: 202, 5: 53})\n",
      "Epoch train QWK: 0.921\tval QWK: 0.532\n",
      "Epoch 9/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 333/498 [01:32<00:43,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2734\tValidation Loss: 1.9737\n",
      "Counter train preds: Counter({0: 2201, 1: 2054, 2: 946, 5: 938, 4: 926, 3: 897})\tCounter val preds: Counter({1: 886, 0: 844, 5: 440, 3: 282, 2: 137, 4: 65})\n",
      "Epoch train QWK: 0.938\tval QWK: 0.628\n",
      "Epoch 10/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:18<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1860\tValidation Loss: 2.2774\n",
      "Counter train preds: Counter({0: 2183, 1: 2028, 2: 973, 4: 936, 5: 926, 3: 916})\tCounter val preds: Counter({1: 853, 0: 730, 2: 307, 4: 304, 5: 278, 3: 182})\n",
      "Epoch train QWK: 0.966\tval QWK: 0.614\n",
      "Epoch 11/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1438\tValidation Loss: 2.4345\n",
      "Counter train preds: Counter({0: 2180, 1: 2027, 2: 991, 5: 923, 4: 923, 3: 918})\tCounter val preds: Counter({0: 931, 1: 597, 5: 443, 3: 336, 4: 202, 2: 145})\n",
      "Epoch train QWK: 0.975\tval QWK: 0.644\n",
      "Epoch 12/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1475\tValidation Loss: 2.9400\n",
      "Counter train preds: Counter({0: 2200, 1: 1993, 2: 1005, 4: 931, 5: 920, 3: 913})\tCounter val preds: Counter({0: 821, 1: 730, 4: 507, 5: 340, 2: 129, 3: 127})\n",
      "Epoch train QWK: 0.965\tval QWK: 0.598\n",
      "Epoch 13/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1385\tValidation Loss: 2.8731\n",
      "Counter train preds: Counter({0: 2179, 1: 2014, 2: 996, 4: 934, 3: 925, 5: 914})\tCounter val preds: Counter({5: 783, 1: 766, 0: 639, 3: 256, 2: 113, 4: 97})\n",
      "Epoch train QWK: 0.975\tval QWK: 0.592\n",
      "Epoch 14/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1242\tValidation Loss: 2.8354\n",
      "Counter train preds: Counter({0: 2185, 1: 2014, 2: 991, 4: 925, 3: 924, 5: 923})\tCounter val preds: Counter({5: 630, 0: 585, 1: 521, 4: 473, 3: 271, 2: 174})\n",
      "Epoch train QWK: 0.973\tval QWK: 0.522\n",
      "Epoch 15/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0779\tValidation Loss: 2.7924\n",
      "Counter train preds: Counter({0: 2183, 1: 1992, 2: 1006, 4: 936, 3: 926, 5: 919})\tCounter val preds: Counter({0: 880, 1: 831, 3: 480, 5: 215, 2: 151, 4: 97})\n",
      "Epoch train QWK: 0.986\tval QWK: 0.603\n",
      "Epoch 16/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0993\tValidation Loss: 2.7047\n",
      "Counter train preds: Counter({0: 2174, 1: 2017, 2: 1000, 3: 932, 5: 920, 4: 919})\tCounter val preds: Counter({1: 741, 0: 620, 5: 416, 3: 407, 2: 289, 4: 181})\n",
      "Epoch train QWK: 0.974\tval QWK: 0.585\n",
      "Epoch 17/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 165/498 [00:46<01:28,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1216\tValidation Loss: 3.4735\n",
      "Counter train preds: Counter({0: 2193, 1: 1996, 2: 1003, 5: 926, 4: 926, 3: 918})\tCounter val preds: Counter({1: 738, 5: 622, 4: 595, 0: 554, 2: 137, 3: 8})\n",
      "Epoch train QWK: 0.967\tval QWK: 0.543\n",
      "Epoch 18/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1044\tValidation Loss: 3.2364\n",
      "Counter train preds: Counter({0: 2173, 1: 2008, 2: 999, 3: 938, 4: 923, 5: 921})\tCounter val preds: Counter({0: 1290, 4: 375, 1: 347, 5: 277, 2: 254, 3: 111})\n",
      "Epoch train QWK: 0.977\tval QWK: 0.604\n",
      "Epoch 19/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0667\tValidation Loss: 2.6297\n",
      "Counter train preds: Counter({0: 2179, 1: 2000, 2: 1002, 4: 935, 3: 929, 5: 917})\tCounter val preds: Counter({0: 633, 1: 618, 2: 534, 4: 316, 3: 314, 5: 239})\n",
      "Epoch train QWK: 0.986\tval QWK: 0.617\n",
      "Epoch 20/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0882\tValidation Loss: 3.8330\n",
      "Counter train preds: Counter({0: 2182, 1: 2006, 2: 1005, 4: 929, 3: 925, 5: 915})\tCounter val preds: Counter({0: 848, 5: 760, 4: 656, 1: 234, 2: 127, 3: 29})\n",
      "Epoch train QWK: 0.977\tval QWK: 0.477\n",
      "Epoch 21/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0918\tValidation Loss: 2.9216\n",
      "Counter train preds: Counter({0: 2183, 1: 1997, 2: 1006, 3: 930, 4: 930, 5: 916})\tCounter val preds: Counter({0: 723, 1: 698, 4: 525, 5: 298, 3: 245, 2: 165})\n",
      "Epoch train QWK: 0.977\tval QWK: 0.587\n",
      "Epoch 22/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0688\tValidation Loss: 3.0613\n",
      "Counter train preds: Counter({0: 2176, 1: 1999, 2: 1004, 4: 941, 3: 927, 5: 915})\tCounter val preds: Counter({0: 1036, 5: 493, 2: 487, 1: 406, 4: 184, 3: 48})\n",
      "Epoch train QWK: 0.987\tval QWK: 0.581\n",
      "Epoch 23/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0538\tValidation Loss: 2.8430\n",
      "Counter train preds: Counter({0: 2174, 1: 2002, 2: 1003, 4: 932, 3: 928, 5: 923})\tCounter val preds: Counter({0: 923, 1: 616, 2: 400, 5: 305, 4: 214, 3: 196})\n",
      "Epoch train QWK: 0.983\tval QWK: 0.590\n",
      "Epoch 24/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0962\tValidation Loss: 3.2823\n",
      "Counter train preds: Counter({0: 2180, 1: 1998, 2: 1008, 4: 930, 3: 927, 5: 919})\tCounter val preds: Counter({0: 1259, 1: 531, 5: 468, 3: 199, 4: 113, 2: 84})\n",
      "Epoch train QWK: 0.973\tval QWK: 0.584\n",
      "Epoch 25/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 241/498 [01:07<01:08,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0890\tValidation Loss: 3.2064\n",
      "Counter train preds: Counter({0: 2182, 1: 1997, 2: 1004, 3: 932, 4: 930, 5: 917})\tCounter val preds: Counter({0: 1181, 1: 547, 2: 450, 5: 305, 4: 98, 3: 73})\n",
      "Epoch train QWK: 0.981\tval QWK: 0.550\n",
      "Epoch 26/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|â–‰         | 46/498 [00:13<02:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0596\tValidation Loss: 2.8168\n",
      "Counter train preds: Counter({0: 2183, 1: 1993, 2: 1007, 4: 933, 3: 932, 5: 914})\tCounter val preds: Counter({0: 803, 1: 687, 5: 419, 2: 408, 3: 219, 4: 118})\n",
      "Epoch train QWK: 0.985\tval QWK: 0.611\n",
      "Epoch 27/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:15<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0690\tValidation Loss: 3.4654\n",
      "Counter train preds: Counter({0: 2180, 1: 2001, 2: 1004, 4: 934, 3: 924, 5: 919})\tCounter val preds: Counter({1: 963, 0: 521, 2: 339, 3: 315, 5: 308, 4: 208})\n",
      "Epoch train QWK: 0.984\tval QWK: 0.591\n",
      "Epoch 28/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0550\tValidation Loss: 3.5768\n",
      "Counter train preds: Counter({0: 2176, 1: 2006, 2: 1003, 4: 937, 3: 929, 5: 911})\tCounter val preds: Counter({1: 1102, 0: 785, 3: 258, 4: 248, 5: 235, 2: 26})\n",
      "Epoch train QWK: 0.985\tval QWK: 0.593\n",
      "Epoch 29/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [02:17<00:00,  3.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 166/166 [00:14<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0738\tValidation Loss: 3.0092\n",
      "Counter train preds: Counter({0: 2173, 1: 2007, 2: 1000, 3: 935, 4: 924, 5: 923})\tCounter val preds: Counter({1: 787, 0: 628, 3: 422, 2: 310, 4: 262, 5: 245})\n",
      "Epoch train QWK: 0.982\tval QWK: 0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "\n",
    "model_ft = make_RN50_cls()\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "train_eval_loop(train_ds, val_ds, model_ft, optimizer, criterion, model_name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with CV, on fold 0\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7832\tValidation Loss: 1.6735\n",
      "Counter train preds: Counter({1: 50, 4: 11, 3: 8, 0: 6})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.193\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5393\tValidation Loss: 1.6932\n",
      "Counter train preds: Counter({1: 39, 0: 21, 3: 7, 4: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.236\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4436\tValidation Loss: 1.7056\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 7, 5: 5, 4: 3})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.321\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.88it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4152\tValidation Loss: 1.6723\n",
      "Counter train preds: Counter({0: 33, 1: 31, 3: 5, 4: 5, 5: 1})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.282\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3904\tValidation Loss: 1.6386\n",
      "Counter train preds: Counter({1: 33, 0: 28, 4: 6, 3: 5, 5: 3})\tCounter val preds: Counter({1: 15, 5: 3, 0: 3, 2: 2, 4: 1, 3: 1})\n",
      "Epoch train QWK: 0.393\tval QWK: 0.186\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3730\tValidation Loss: 1.6927\n",
      "Counter train preds: Counter({0: 33, 1: 26, 5: 7, 3: 4, 4: 4, 2: 1})\tCounter val preds: Counter({1: 13, 5: 6, 2: 4, 3: 1, 0: 1})\n",
      "Epoch train QWK: 0.517\tval QWK: 0.545\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3238\tValidation Loss: 1.8837\n",
      "Counter train preds: Counter({0: 30, 1: 29, 5: 6, 3: 6, 4: 4})\tCounter val preds: Counter({1: 9, 5: 7, 2: 6, 3: 3})\n",
      "Epoch train QWK: 0.438\tval QWK: 0.329\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3055\tValidation Loss: 2.0990\n",
      "Counter train preds: Counter({1: 34, 0: 22, 5: 8, 3: 7, 4: 2, 2: 2})\tCounter val preds: Counter({2: 12, 5: 5, 3: 5, 1: 2, 4: 1})\n",
      "Epoch train QWK: 0.552\tval QWK: 0.326\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3063\tValidation Loss: 2.0883\n",
      "Counter train preds: Counter({1: 35, 0: 25, 4: 7, 3: 5, 5: 3})\tCounter val preds: Counter({2: 13, 5: 5, 1: 3, 3: 2, 4: 1, 0: 1})\n",
      "Epoch train QWK: 0.549\tval QWK: 0.199\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.73it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.8377\n",
      "Counter train preds: Counter({1: 37, 0: 24, 5: 7, 4: 3, 3: 3, 2: 1})\tCounter val preds: Counter({1: 21, 3: 2, 2: 1, 5: 1})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.305\n",
      "Train with CV, on fold 1\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7209\tValidation Loss: 1.7380\n",
      "Counter train preds: Counter({0: 59, 3: 15, 1: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.263\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5459\tValidation Loss: 1.7958\n",
      "Counter train preds: Counter({0: 36, 1: 32, 3: 5, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.331\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4606\tValidation Loss: 1.9763\n",
      "Counter train preds: Counter({1: 34, 0: 29, 4: 8, 3: 4})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4206\tValidation Loss: 1.8872\n",
      "Counter train preds: Counter({1: 32, 0: 24, 4: 8, 3: 6, 5: 3, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.441\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4067\tValidation Loss: 2.2129\n",
      "Counter train preds: Counter({1: 36, 0: 25, 3: 10, 5: 2, 2: 1, 4: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3640\tValidation Loss: 2.9000\n",
      "Counter train preds: Counter({1: 33, 0: 24, 3: 12, 2: 4, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.364\tval QWK: 0.000\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3085\tValidation Loss: 2.7819\n",
      "Counter train preds: Counter({1: 33, 0: 20, 3: 11, 2: 4, 4: 4, 5: 3})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.568\tval QWK: 0.000\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3142\tValidation Loss: 2.3783\n",
      "Counter train preds: Counter({1: 36, 0: 21, 3: 9, 2: 5, 5: 3, 4: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.116\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2917\tValidation Loss: 3.1009\n",
      "Counter train preds: Counter({1: 38, 0: 19, 2: 6, 4: 5, 3: 4, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.433\tval QWK: 0.009\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2545\tValidation Loss: 2.9466\n",
      "Counter train preds: Counter({1: 32, 0: 20, 3: 10, 4: 5, 2: 5, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.635\tval QWK: 0.009\n",
      "Train with CV, on fold 2\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6856\tValidation Loss: 1.8174\n",
      "Counter train preds: Counter({1: 48, 3: 15, 0: 12})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.208\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.56it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5455\tValidation Loss: 2.4182\n",
      "Counter train preds: Counter({1: 37, 0: 21, 3: 16, 2: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.313\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4741\tValidation Loss: 2.2700\n",
      "Counter train preds: Counter({1: 33, 0: 26, 3: 14, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.287\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4289\tValidation Loss: 2.4097\n",
      "Counter train preds: Counter({1: 35, 0: 28, 3: 7, 2: 5})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.247\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3615\tValidation Loss: 2.0392\n",
      "Counter train preds: Counter({1: 39, 0: 25, 3: 7, 2: 4})\tCounter val preds: Counter({0: 24, 2: 1})\n",
      "Epoch train QWK: 0.307\tval QWK: 0.064\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4250\tValidation Loss: 1.6867\n",
      "Counter train preds: Counter({1: 41, 0: 26, 3: 8})\tCounter val preds: Counter({0: 20, 2: 3, 1: 2})\n",
      "Epoch train QWK: 0.266\tval QWK: 0.214\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3328\tValidation Loss: 1.7360\n",
      "Counter train preds: Counter({1: 34, 0: 24, 3: 12, 2: 4, 5: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.365\tval QWK: 0.130\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.17it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3236\tValidation Loss: 1.8248\n",
      "Counter train preds: Counter({1: 33, 0: 21, 2: 13, 3: 6, 5: 2})\tCounter val preds: Counter({0: 17, 1: 5, 2: 3})\n",
      "Epoch train QWK: 0.316\tval QWK: 0.272\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2498\tValidation Loss: 2.4719\n",
      "Counter train preds: Counter({1: 34, 0: 24, 2: 8, 3: 8, 5: 1})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.392\tval QWK: 0.259\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2657\tValidation Loss: 2.4212\n",
      "Counter train preds: Counter({1: 39, 0: 21, 2: 6, 3: 6, 5: 3})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.409\tval QWK: 0.259\n",
      "Train with CV, on fold 3\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.78it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7337\tValidation Loss: 1.6500\n",
      "Counter train preds: Counter({1: 49, 2: 14, 0: 6, 5: 3, 3: 3})\tCounter val preds: Counter({1: 24, 0: 1})\n",
      "Epoch train QWK: 0.123\tval QWK: -0.030\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5647\tValidation Loss: 1.7000\n",
      "Counter train preds: Counter({1: 40, 0: 18, 3: 12, 2: 5})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.232\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.87it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4733\tValidation Loss: 1.6935\n",
      "Counter train preds: Counter({1: 33, 0: 27, 3: 13, 2: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.337\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.66it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4141\tValidation Loss: 1.6876\n",
      "Counter train preds: Counter({0: 29, 1: 28, 3: 10, 2: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.475\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3655\tValidation Loss: 1.6186\n",
      "Counter train preds: Counter({1: 35, 0: 26, 3: 7, 5: 4, 2: 3})\tCounter val preds: Counter({1: 21, 2: 3, 0: 1})\n",
      "Epoch train QWK: 0.395\tval QWK: 0.012\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3591\tValidation Loss: 1.6763\n",
      "Counter train preds: Counter({1: 32, 0: 23, 3: 11, 2: 8, 5: 1})\tCounter val preds: Counter({2: 17, 0: 6, 1: 2})\n",
      "Epoch train QWK: 0.413\tval QWK: 0.313\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.6529\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 5, 2: 4, 4: 4, 5: 2})\tCounter val preds: Counter({1: 12, 2: 9, 5: 2, 0: 2})\n",
      "Epoch train QWK: 0.424\tval QWK: 0.269\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3050\tValidation Loss: 1.7019\n",
      "Counter train preds: Counter({1: 36, 0: 21, 2: 6, 3: 5, 5: 4, 4: 3})\tCounter val preds: Counter({2: 13, 5: 7, 4: 3, 0: 2})\n",
      "Epoch train QWK: 0.454\tval QWK: 0.364\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:00<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2645\tValidation Loss: 1.7029\n",
      "Counter train preds: Counter({1: 36, 0: 22, 5: 7, 2: 5, 3: 4, 4: 1})\tCounter val preds: Counter({2: 10, 5: 5, 0: 5, 1: 4, 3: 1})\n",
      "Epoch train QWK: 0.461\tval QWK: 0.309\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2169\tValidation Loss: 2.0975\n",
      "Counter train preds: Counter({1: 33, 0: 22, 2: 9, 3: 6, 5: 5})\tCounter val preds: Counter({4: 14, 5: 8, 0: 3})\n",
      "Epoch train QWK: 0.530\tval QWK: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"test_fold_{}.pth\"\n",
    "for fold in range(CFG.n_fold):\n",
    "    train_df = folds[folds[\"fold\"] != fold].copy()\n",
    "    val_df = folds[folds[\"fold\"] == fold].copy()\n",
    "    \n",
    "    train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "    val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "    \n",
    "    model = TinyV2ConvNet(CFG.target_size)\n",
    "    # initialize bias in the model\n",
    "    cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "    model = init_last_layer_bias(model, cls_probas)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    print(f\"Train with CV, on fold {fold}\")\n",
    "    model = train_eval_loop(train_ds, val_ds, model, optimizer, criterion, tb_tag=fold)\n",
    "    torch.save(model.state_dict(), MODEL_PATH/checkpoint.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestxray",
   "language": "python",
   "name": "chestxray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
