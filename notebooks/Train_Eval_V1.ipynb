{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingWarmRestarts\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from apex import amp\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2\n",
    "import skimage.io\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "from chestxray.config import (PANDA_PATH,\n",
    "                              MODEL_PATH,\n",
    "                              PANDA_IMGS,\n",
    "                              PANDA_MASKS,\n",
    "                              TRAIN_CSV)\n",
    "# Competition related config\n",
    "from chestxray.config import CFG\n",
    "\n",
    "# Misc\n",
    "from chestxray.misc import seed_torch\n",
    "\n",
    "# Datasets\n",
    "from chestxray.datasets import get_transforms, TrainDataset, TilesTrainDataset, LazyTilesDataset, PatchTrainDataset, H5PatchDataset, SeqenceRandomSampler\n",
    "\n",
    "# Viz\n",
    "from chestxray.visualize import (show_from_ids, show_batch, imshow, \n",
    "                                 plot_classes_preds, reverse_show_img, \n",
    "                                 plot_confusion_matrix, text_classes_preds)\n",
    "\n",
    "# Nets\n",
    "from chestxray.nets import TinyV2ConvNet, freeze_botom, PatchModel\n",
    "from chestxray.model_utils import (trainable_params, cce_loss_at_init, \n",
    "                                   init_last_layer_bias)\n",
    "# Losses\n",
    "from chestxray.losses import LabelSmoothSoftmaxCEV1\n",
    "\n",
    "# Optim\n",
    "from chestxray.optimizers import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='GeForce RTX 2070 SUPER', major=7, minor=5, total_memory=7979MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = pd.read_csv(TRAIN_CSV)\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 381
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = TRAIN_DF[CFG.target_col].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21-05-2020-15-12\n"
     ]
    }
   ],
   "source": [
    "CFG.debug = False\n",
    "now = datetime.now()\n",
    "\n",
    "EXP_NAME = now.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "print(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/{EXP_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if resume should continue previous writer\n",
    "# PREV_NAME = \"21-05-2020-15-12\"\n",
    "# writer = SummaryWriter(f'runs/{PREV_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = {\n",
    "    \"cce\" : nn.CrossEntropyLoss(),\n",
    "    \"ls_soft_ce\" : LabelSmoothSoftmaxCEV1(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key - string, value - tuple(sceduler, if it epoch type)\n",
    "epoch_type = True\n",
    "SCHEDULERS = {\n",
    "    \"reduce_on_plateau\" : (ReduceLROnPlateau, epoch_type),\n",
    "    \"one_cycle\": (OneCycleLR, not epoch_type),\n",
    "    \"cawr\": (CosineAnnealingWarmRestarts, not epoch_type),\n",
    "    \"none\": (None, None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Eval Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_loop(train_dataloader, val_dataloader, model, optimizer, criterion, scheduler, sch_is_epoch_type, accum_step=CFG.accum_step, checkpoint=False,\n",
    "                    num_epochs=CFG.epoch, device=device, tb_tag=\"\", model_name=\"debug\"):\n",
    "    \"\"\"Split it into the set of inner functions to siplify the loop itself\"\"\"\n",
    "    # Inner Functions\n",
    "    # write to TensorBoard helpers\n",
    "    def weights_to_tb(step=0):\n",
    "        conv1_weight = list(model.parameters())[0].data.to(\"cpu\")\n",
    "        img_grid = torchvision.utils.make_grid(conv1_weight, normalize=True)\n",
    "        writer.add_image(tag=f\"Model conv1 weights {tb_tag}\", img_tensor=img_grid, global_step=step)\n",
    "    \n",
    "    def input_img_to_tb(inputs, step):\n",
    "        img = reverse_show_img(inputs[0], denorm=True)\n",
    "        writer.add_image(tag=f\"Input Image {tb_tag}\", img_tensor=img, global_step=step, dataformats=\"HWC\")\n",
    "        del img\n",
    "    \n",
    "    def preds_to_tb(outputs, inputs, labels, step):\n",
    "        figure=plot_classes_preds(outputs.to('cpu'), inputs.to('cpu'), labels.to('cpu'))\n",
    "        writer.add_figure(tag=f\"Actuals vs Predictions {tb_tag}\", figure=figure, global_step=step)\n",
    "    \n",
    "    def text_preds_to_tb(outputs, labels, step):\n",
    "        preds_text = text_classes_preds(outputs.to(\"cpu\"), labels.to(\"cpu\"))\n",
    "        writer.add_text(f\"Actuals vs Predictions {tb_tag}\", preds_text, global_step=step)\n",
    "        \n",
    "    def metrics_to_tb(mode, train_loss, train_score, val_loss, val_score, step):\n",
    "        writer.add_text(f\"On best {mode} save:\", \n",
    "                        f\"tr_loss: {train_loss:.4f}, tr_qwk: {train_score:.4f}, val_loss: {val_loss:.4f}, val_qwk: {val_score:.4f}\", \n",
    "                        global_step=step)\n",
    "    \n",
    "    def conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, step):\n",
    "        writer.add_figure(tag=f\"Confusion matrix {tb_tag}\", figure=plot_confusion_matrix(val_epoch_labels, val_epoch_preds),\n",
    "                          global_step=step)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Train/Eval Loop\n",
    "    # write first layer weights to TB @ init phase\n",
    "    if not CFG.debug:\n",
    "        weights_to_tb()\n",
    "    \n",
    "    # prepare model and optimizer\n",
    "    model.to(device)\n",
    "    if CFG.use_amp: # automatic mixed precision\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n",
    "    # define epochs numbers to look into input images and predictions, no more than 10 times per full training\n",
    "    vis_step = np.ceil(num_epochs/10).astype(int)\n",
    "    visual_epochs = list(range(0, num_epochs, vis_step))\n",
    "    # metrics to wathch for model checkpointing\n",
    "    best_qwk = -100 if not checkpoint else checkpoint['best_qwk']\n",
    "    best_val_loss = np.inf if not checkpoint else checkpoint[\"best_val_loss\"]\n",
    "    \n",
    "    start_epoch = 0 if not checkpoint else checkpoint[\"epoch\"] + 1\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('=' * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        # Set training mode\n",
    "        model.train();\n",
    "        train_running_loss = 0.0\n",
    "        train_epoch_preds, train_epoch_labels = [], []\n",
    "        \n",
    "        # We accumulate, zero at training epoch begins\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Iterate over train data.\n",
    "        tk_train = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for i, data in tk_train:\n",
    "            # Calculate global step for TensorBoard\n",
    "            train_global_step = epoch * len(train_dataloader) + i\n",
    "\n",
    "            inputs, labels = data\n",
    "            # Visualize input before model at the middle of epoch:\n",
    "            if epoch in visual_epochs and i == len(train_dataloader) // 2:\n",
    "                input_img_to_tb(inputs, train_global_step)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if CFG.use_amp:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            if (i+1)% accum_step == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # loss is mean across batch, divide by number of steps in epoch (so loss is normalized)\n",
    "            train_running_loss += loss.item() / len(train_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Training loss {tb_tag}\", scalar_value=loss.item(), global_step=train_global_step)\n",
    "\n",
    "            # collect train preds and labels for QWK\n",
    "            train_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            train_epoch_labels.append(labels.to('cpu').numpy())\n",
    "            # Add Batch Type Scheduler step here:\n",
    "            if scheduler and not sch_is_epoch_type:\n",
    "                scheduler.step()\n",
    "        # Validation Phase\n",
    "        # Set evaluation mode\n",
    "        model.eval();\n",
    "        val_running_loss = 0.0\n",
    "        val_epoch_preds, val_epoch_labels = [], []\n",
    "        # Iterate over val data\n",
    "        tk_val = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "        for j, data in tk_val:\n",
    "            # Calculate global step\n",
    "            val_global_step = epoch * len(val_dataloader) + j\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() / len(val_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Validation loss {tb_tag}\", scalar_value=loss.item(), global_step=val_global_step)\n",
    "\n",
    "            # collect validation preds and labels for QWK\n",
    "            val_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            val_epoch_labels.append(labels.to('cpu').numpy())\n",
    "\n",
    "            # visualise predictions for 0th validation batch\n",
    "            if epoch in visual_epochs and j == 0:\n",
    "                text_preds_to_tb(outputs, labels, val_global_step)\n",
    "        \n",
    "        # Epoch type Schedulers\n",
    "        if scheduler and sch_is_epoch_type:\n",
    "            scheduler.step(val_running_loss)\n",
    "        # Write lr to TBD\n",
    "        if CFG.finetune == \"1stage\":\n",
    "            writer.add_scalar(tag=f\"lr Interim {tb_tag}:\", scalar_value=optimizer.param_groups[0][\"lr\"], global_step=train_global_step)\n",
    "            writer.add_scalar(tag=f\"lr Classifier {tb_tag}:\", scalar_value=optimizer.param_groups[1][\"lr\"], global_step=train_global_step)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(tag=f\"lr {tb_tag}:\", scalar_value=optimizer.param_groups[0][\"lr\"], global_step=train_global_step)\n",
    "        \n",
    "        # \"End of Epoch\" Phase\n",
    "        print(f'Training Loss: {train_running_loss:.4f}\\tValidation Loss: {val_running_loss:.4f}')\n",
    "        \n",
    "        # Calculate epoch predictions distribution\n",
    "        train_epoch_preds = np.concatenate(train_epoch_preds)\n",
    "        train_epoch_labels = np.concatenate(train_epoch_labels)\n",
    "        val_epoch_preds = np.concatenate(val_epoch_preds)\n",
    "        val_epoch_labels = np.concatenate(val_epoch_labels)\n",
    "        print(f'Counter train preds: {Counter(train_epoch_preds)}\\tCounter val preds: {Counter(val_epoch_preds)}')\n",
    "        # Calculate epoch QWK\n",
    "        train_qwk = cohen_kappa_score(train_epoch_preds, train_epoch_labels, weights='quadratic')\n",
    "        val_qwk = cohen_kappa_score(val_epoch_preds, val_epoch_labels, weights='quadratic')\n",
    "        print(f\"Epoch train QWK: {train_qwk:.3f}\\tval QWK: {val_qwk:.3f}\")\n",
    "        writer.add_scalar(tag=f\"Training QWK {tb_tag}\", scalar_value=train_qwk, global_step=epoch)\n",
    "        writer.add_scalar(tag=f\"Validation QWK {tb_tag}\", scalar_value=val_qwk, global_step=epoch)\n",
    "        \n",
    "        # On the best val loss do:\n",
    "        if val_running_loss < best_val_loss:\n",
    "            # update best and save model\n",
    "            best_val_loss = val_running_loss\n",
    "            print(f'  Epoch {epoch} - Save Best Loss: {best_val_loss:.4f} Model')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_qwk': best_qwk,\n",
    "            }, f'{MODEL_PATH}/{model_name}_loss.pth')\n",
    "            # add losses as text to TB\n",
    "            metrics_to_tb(\"loss\", train_running_loss, train_qwk, val_running_loss, val_qwk, val_global_step)\n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                weights_to_tb(val_global_step)\n",
    "            # add confusion matrix to TB\n",
    "            conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, val_global_step)\n",
    "        # On the best QWK\n",
    "        if val_qwk > best_qwk:\n",
    "            # update best and save model\n",
    "            best_qwk = val_qwk\n",
    "            print(f'  Epoch {epoch} - Save Best QWK: {best_qwk:.4f} Model')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_qwk': best_qwk,\n",
    "            }, f'{MODEL_PATH}/{model_name}_qwk.pth')\n",
    "            # add losses and qwk as text to TB\n",
    "            metrics_to_tb(\"qwk\", train_running_loss, train_qwk, val_running_loss, val_qwk, val_global_step)\n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                weights_to_tb(val_global_step)  \n",
    "            # add confusion matrix to TB\n",
    "            conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, val_global_step)\n",
    "    # End of loop\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CV - strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    folds_fn = \"folds_db.csv\"\n",
    "    try: \n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.sample(n=100, random_state=CFG.seed).reset_index(drop=True).copy()\n",
    "else:\n",
    "    folds_fn = \"folds.csv\"\n",
    "    try:\n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PANDA_PATH/folds_fn).exists():\n",
    "    train_labels = folds[CFG.target_col].values\n",
    "    kf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n",
    "        folds.loc[val_index, 'fold'] = int(fold)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(PANDA_PATH/folds_fn, index=None)\n",
    "    folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   image_id       100 non-null    object\n",
      " 1   data_provider  100 non-null    object\n",
      " 2   isup_grade     100 non-null    int64 \n",
      " 3   gleason_score  100 non-null    object\n",
      " 4   fold           100 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "folds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: True seed: 1982 img_height: 1024 img_width: 1024 target_size: 6 img_id_col: image_id target_col: isup_grade tiff_layer: 1 stoch_sample: True num_tiles: 16 tile_sz: 256 batch_size: 4 accum_step: 16 dataset: hdf5 aug_type: light finetune: False model_cls: one_layer schedule_type: none cawr_T: 1 cawr_Tmult: 2 loss: cce optim: adam lr: 0.0001 rlopp: 3 epoch: 70 n_fold: 4 use_amp: True\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Experiment Description:\", \" \".join([f\"{key}: {val}\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedulers\n",
    "def get_scheduler(optimizer,train_dataloader, schedule_type=CFG.schedule_type, resume=False):\n",
    "    assert schedule_type in SCHEDULERS, f\"{schedule_type} not in SCHEDULERS\"\n",
    "    if schedule_type == \"reduce_on_plateau\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, 'min', factor=0.5, patience=CFG.rlopp if not resume else CFG.rlopp + 2, verbose=True), \n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    if schedule_type == \"one_cycle\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, max_lr=[CFG.lr, CFG.lr*10] if CFG.finetune == \"1stage\" else CFG.lr,\n",
    "                                             steps_per_epoch=len(train_dataloader), epochs=CFG.epoch, pct_start=0.05),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    if schedule_type == \"cawr\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, T_0=len(train_dataloader)*CFG.cawr_T, T_mult=CFG.cawr_Tmult),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    else:\n",
    "        return (SCHEDULERS[schedule_type][0],\n",
    "                SCHEDULERS[schedule_type][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16/125 [00:04<00:28,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 96/125 [00:25<00:07,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.84it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6961\tValidation Loss: 1.3562\n",
      "Counter train preds: Counter({0: 303, 1: 124, 2: 61, 3: 8, 5: 3, 4: 1})\tCounter val preds: Counter({0: 199, 1: 129, 2: 79, 5: 51, 4: 25, 3: 17})\n",
      "Epoch train QWK: 0.071\tval QWK: 0.482\n",
      "  Epoch 0 - Save Best Loss: 1.3562 Model\n",
      "Confusion matrix, without normalization\n",
      "[[100  18   4   1   0   3]\n",
      " [ 37  77  14   0   3   5]\n",
      " [ 19  15  25   1   4   7]\n",
      " [ 13   5  18   8   0   4]\n",
      " [ 15  11  17   4  16   5]\n",
      " [ 15   3   1   3   2  27]]\n",
      "  Epoch 0 - Save Best QWK: 0.4820 Model\n",
      "Confusion matrix, without normalization\n",
      "[[100  18   4   1   0   3]\n",
      " [ 37  77  14   0   3   5]\n",
      " [ 19  15  25   1   4   7]\n",
      " [ 13   5  18   8   0   4]\n",
      " [ 15  11  17   4  16   5]\n",
      " [ 15   3   1   3   2  27]]\n",
      "Epoch 1/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:33<00:00,  3.71it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4177\tValidation Loss: 1.0833\n",
      "Counter train preds: Counter({0: 177, 1: 151, 2: 75, 5: 46, 4: 36, 3: 15})\tCounter val preds: Counter({0: 166, 1: 100, 4: 80, 5: 74, 2: 62, 3: 18})\n",
      "Epoch train QWK: 0.442\tval QWK: 0.720\n",
      "  Epoch 1 - Save Best Loss: 1.0833 Model\n",
      "Confusion matrix, without normalization\n",
      "[[113   3   0   0   8   2]\n",
      " [ 32  82  10   0   7   5]\n",
      " [ 10   7  36   1   7  10]\n",
      " [  4   2   7  16  12   7]\n",
      " [  3   4   9   1  41  10]\n",
      " [  4   2   0   0   5  40]]\n",
      "  Epoch 1 - Save Best QWK: 0.7199 Model\n",
      "Confusion matrix, without normalization\n",
      "[[113   3   0   0   8   2]\n",
      " [ 32  82  10   0   7   5]\n",
      " [ 10   7  36   1   7  10]\n",
      " [  4   2   7  16  12   7]\n",
      " [  3   4   9   1  41  10]\n",
      " [  4   2   0   0   5  40]]\n",
      "Epoch 2/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:36<00:00,  3.38it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1816\tValidation Loss: 0.8396\n",
      "Counter train preds: Counter({0: 184, 1: 122, 2: 70, 5: 57, 4: 48, 3: 19})\tCounter val preds: Counter({0: 170, 1: 123, 5: 70, 4: 59, 2: 55, 3: 23})\n",
      "Epoch train QWK: 0.590\tval QWK: 0.803\n",
      "  Epoch 2 - Save Best Loss: 0.8396 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   0   0   0   2   1]\n",
      " [ 20 110   1   0   3   2]\n",
      " [ 11   8  43   1   3   5]\n",
      " [  7   3   4  21   4   9]\n",
      " [  5   2   6   1  45   9]\n",
      " [  4   0   1   0   2  44]]\n",
      "  Epoch 2 - Save Best QWK: 0.8028 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   0   0   0   2   1]\n",
      " [ 20 110   1   0   3   2]\n",
      " [ 11   8  43   1   3   5]\n",
      " [  7   3   4  21   4   9]\n",
      " [  5   2   6   1  45   9]\n",
      " [  4   0   1   0   2  44]]\n",
      "Epoch 3/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:33<00:00,  3.78it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0395\tValidation Loss: 0.6663\n",
      "Counter train preds: Counter({0: 168, 1: 156, 2: 60, 5: 56, 4: 40, 3: 20})\tCounter val preds: Counter({1: 147, 0: 138, 5: 66, 2: 62, 4: 57, 3: 30})\n",
      "Epoch train QWK: 0.680\tval QWK: 0.890\n",
      "  Epoch 3 - Save Best Loss: 0.6663 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   2   0   0   1   0]\n",
      " [  0 134   0   1   1   0]\n",
      " [  5   6  54   1   1   4]\n",
      " [  6   2   4  27   3   6]\n",
      " [  3   3   3   1  49   9]\n",
      " [  1   0   1   0   2  47]]\n",
      "  Epoch 3 - Save Best QWK: 0.8903 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   2   0   0   1   0]\n",
      " [  0 134   0   1   1   0]\n",
      " [  5   6  54   1   1   4]\n",
      " [  6   2   4  27   3   6]\n",
      " [  3   3   3   1  49   9]\n",
      " [  1   0   1   0   2  47]]\n",
      "Epoch 4/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:35<00:00,  3.56it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9074\tValidation Loss: 0.4801\n",
      "Counter train preds: Counter({0: 155, 1: 152, 2: 71, 4: 50, 5: 49, 3: 23})\tCounter val preds: Counter({0: 133, 1: 133, 2: 68, 4: 67, 5: 62, 3: 37})\n",
      "Epoch train QWK: 0.754\tval QWK: 0.940\n",
      "  Epoch 4 - Save Best Loss: 0.4801 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   1   0   0   1   1]\n",
      " [  5 127   2   1   1   0]\n",
      " [  2   3  63   0   1   2]\n",
      " [  2   1   2  35   3   5]\n",
      " [  1   1   1   1  61   3]\n",
      " [  0   0   0   0   0  51]]\n",
      "  Epoch 4 - Save Best QWK: 0.9404 Model\n",
      "Confusion matrix, without normalization\n",
      "[[123   1   0   0   1   1]\n",
      " [  5 127   2   1   1   0]\n",
      " [  2   3  63   0   1   2]\n",
      " [  2   1   2  35   3   5]\n",
      " [  1   1   1   1  61   3]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 5/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:34<00:00,  3.67it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7693\tValidation Loss: 0.3636\n",
      "Counter train preds: Counter({0: 153, 1: 151, 2: 62, 4: 54, 5: 47, 3: 33})\tCounter val preds: Counter({1: 133, 0: 129, 4: 71, 2: 70, 5: 54, 3: 43})\n",
      "Epoch train QWK: 0.780\tval QWK: 0.977\n",
      "  Epoch 5 - Save Best Loss: 0.3636 Model\n",
      "Confusion matrix, without normalization\n",
      "[[125   0   0   0   1   0]\n",
      " [  3 131   1   0   0   1]\n",
      " [  1   1  67   0   2   0]\n",
      " [  0   1   1  43   2   1]\n",
      " [  0   0   1   0  66   1]\n",
      " [  0   0   0   0   0  51]]\n",
      "  Epoch 5 - Save Best QWK: 0.9774 Model\n",
      "Confusion matrix, without normalization\n",
      "[[125   0   0   0   1   0]\n",
      " [  3 131   1   0   0   1]\n",
      " [  1   1  67   0   2   0]\n",
      " [  0   1   1  43   2   1]\n",
      " [  0   0   1   0  66   1]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 6/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:33<00:00,  3.69it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6031\tValidation Loss: 0.2834\n",
      "Counter train preds: Counter({1: 147, 0: 135, 2: 69, 4: 63, 5: 50, 3: 36})\tCounter val preds: Counter({1: 135, 0: 126, 2: 71, 4: 66, 5: 56, 3: 46})\n",
      "Epoch train QWK: 0.891\tval QWK: 0.989\n",
      "  Epoch 6 - Save Best Loss: 0.2834 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 135   1   0   0   0]\n",
      " [  0   0  69   0   0   2]\n",
      " [  0   0   0  46   0   2]\n",
      " [  0   0   1   0  66   1]\n",
      " [  0   0   0   0   0  51]]\n",
      "  Epoch 6 - Save Best QWK: 0.9888 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 135   1   0   0   0]\n",
      " [  0   0  69   0   0   2]\n",
      " [  0   0   0  46   0   2]\n",
      " [  0   0   1   0  66   1]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 7/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.84it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.5679\tValidation Loss: 0.1768\n",
      "Counter train preds: Counter({1: 158, 0: 124, 2: 69, 4: 62, 5: 51, 3: 36})\tCounter val preds: Counter({1: 137, 0: 126, 2: 72, 4: 67, 5: 51, 3: 47})\n",
      "Epoch train QWK: 0.883\tval QWK: 0.997\n",
      "  Epoch 7 - Save Best Loss: 0.1768 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   1   0  47   0   0]\n",
      " [  0   0   1   0  67   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "  Epoch 7 - Save Best QWK: 0.9972 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   1   0  47   0   0]\n",
      " [  0   0   1   0  67   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 8/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4894\tValidation Loss: 0.1257\n",
      "Counter train preds: Counter({1: 149, 0: 133, 4: 68, 2: 63, 5: 48, 3: 39})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.932\tval QWK: 1.000\n",
      "  Epoch 8 - Save Best Loss: 0.1257 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "  Epoch 8 - Save Best QWK: 1.0000 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 9/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.84it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4029\tValidation Loss: 0.0795\n",
      "Counter train preds: Counter({1: 137, 0: 131, 2: 72, 4: 64, 5: 49, 3: 47})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.952\tval QWK: 1.000\n",
      "  Epoch 9 - Save Best Loss: 0.0795 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 10/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.83it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3184\tValidation Loss: 0.0648\n",
      "Counter train preds: Counter({1: 144, 0: 129, 2: 69, 4: 66, 5: 51, 3: 41})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.964\tval QWK: 1.000\n",
      "  Epoch 10 - Save Best Loss: 0.0648 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 11/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2865\tValidation Loss: 0.0570\n",
      "Counter train preds: Counter({1: 136, 0: 133, 2: 71, 4: 68, 5: 50, 3: 42})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.958\tval QWK: 1.000\n",
      "  Epoch 11 - Save Best Loss: 0.0570 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 12/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.83it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2564\tValidation Loss: 0.0332\n",
      "Counter train preds: Counter({1: 137, 0: 134, 2: 68, 4: 62, 3: 50, 5: 49})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.939\tval QWK: 1.000\n",
      "  Epoch 12 - Save Best Loss: 0.0332 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 13/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2271\tValidation Loss: 0.0383\n",
      "Counter train preds: Counter({1: 139, 0: 128, 2: 70, 4: 66, 5: 49, 3: 48})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.970\tval QWK: 1.000\n",
      "Epoch 14/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:33<00:00,  3.73it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:10<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2187\tValidation Loss: 0.0261\n",
      "Counter train preds: Counter({1: 135, 0: 129, 2: 71, 4: 71, 3: 48, 5: 46})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.954\tval QWK: 1.000\n",
      "  Epoch 14 - Save Best Loss: 0.0261 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 15/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.81it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1831\tValidation Loss: 0.0276\n",
      "Counter train preds: Counter({1: 135, 0: 129, 2: 70, 4: 67, 5: 51, 3: 48})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.981\tval QWK: 1.000\n",
      "Epoch 16/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1886\tValidation Loss: 0.0206\n",
      "Counter train preds: Counter({1: 142, 0: 121, 4: 70, 2: 70, 5: 49, 3: 48})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.981\tval QWK: 1.000\n",
      "  Epoch 16 - Save Best Loss: 0.0206 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n",
      "Epoch 17/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1741\tValidation Loss: 0.0225\n",
      "Counter train preds: Counter({1: 131, 0: 128, 2: 74, 4: 69, 5: 51, 3: 47})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.977\tval QWK: 1.000\n",
      "Epoch 18/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.83it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1868\tValidation Loss: 0.0233\n",
      "Counter train preds: Counter({1: 141, 0: 127, 4: 68, 2: 67, 5: 51, 3: 46})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.983\tval QWK: 1.000\n",
      "Epoch 19/19\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:32<00:00,  3.85it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add file 0 to cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:09<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1793\tValidation Loss: 0.0164\n",
      "Counter train preds: Counter({1: 139, 0: 123, 2: 72, 4: 67, 5: 51, 3: 48})\tCounter val preds: Counter({1: 136, 0: 126, 2: 71, 4: 68, 5: 51, 3: 48})\n",
      "Epoch train QWK: 0.985\tval QWK: 1.000\n",
      "  Epoch 19 - Save Best Loss: 0.0164 Model\n",
      "Confusion matrix, without normalization\n",
      "[[126   0   0   0   0   0]\n",
      " [  0 136   0   0   0   0]\n",
      " [  0   0  71   0   0   0]\n",
      " [  0   0   0  48   0   0]\n",
      " [  0   0   0   0  68   0]\n",
      " [  0   0   0   0   0  51]]\n"
     ]
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "elif CFG.dataset == \"hdf5\":\n",
    "    train_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patches500.h5\"])\n",
    "    sampler = SeqenceRandomSampler(len(train_ds), train_ds._common_len)\n",
    "    val_ds = train_ds\n",
    "else:\n",
    "    print(f\"No such dataset {CFG.dataset}\")\n",
    "\n",
    "# define a data loader\n",
    "if CFG.dataset == \"hdf5\":\n",
    "    # use specific sampler (so not to load hdf5 files to memory too frequently)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler, num_workers=1, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "\n",
    "model_ft = PatchModel()\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)\n",
    "\n",
    "train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39527bfec9a5472097e0dcab65b96d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 401
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    \n",
    "# define a data loader\n",
    "train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "\n",
    "model_ft = Model(arch=\"resnet34\")\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "model_ft.to(device)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr * 1e-4, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr * 1e-4, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr * 1e-4)\n",
    "    \n",
    "if CFG.use_amp:\n",
    "    model_ft, optimizer = amp.initialize(model_ft, optimizer, opt_level='O1')\n",
    "    \n",
    "lr_finder = LRFinder(model_ft, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(train_dataloader, end_lr=1e-2, num_iter=200, step_mode=\"exp\", accumulation_steps=CFG.accum_step)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-5 == 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: False\n",
      " seed: 1982\n",
      " img_height: 256\n",
      " img_width: 256\n",
      " target_size: 6\n",
      " img_id_col: image_id\n",
      " target_col: isup_grade\n",
      " tiff_layer: 1\n",
      " stoch_sample: True\n",
      " num_tiles: 20\n",
      " tile_sz: 256\n",
      " batch_size: 4\n",
      " accum_step: 8\n",
      " dataset: patch\n",
      " aug_type: light\n",
      " finetune: False\n",
      " model_cls: one_layer\n",
      " schedule_type: none\n",
      " cawr_T: 1\n",
      " cawr_Tmult: 2\n",
      " loss: ls_soft_ce\n",
      " optim: adam\n",
      " lr: 0.0001\n",
      " rlopp: 3\n",
      " epoch: 40\n",
      " n_fold: 4\n",
      " use_amp: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\\n\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Experiment Description:\", \" \".join([f\"{key}: {val}\\n\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedulers\n",
    "def get_scheduler(optimizer,train_dataloader, schedule_type=CFG.schedule_type, resume=False):\n",
    "    assert schedule_type in SCHEDULERS, f\"{schedule_type} not in SCHEDULERS\"\n",
    "    if schedule_type == \"reduce_on_plateau\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, 'min', factor=0.5, patience=CFG.rlopp if not resume else CFG.rlopp + 2, verbose=True), \n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"one_cycle\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, max_lr=[CFG.lr, CFG.lr*10] if CFG.finetune == \"1stage\" else CFG.lr,\n",
    "                                             steps_per_epoch=len(train_dataloader), epochs=CFG.epoch, pct_start=0.05),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"cawr\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, T_0=len(train_dataloader)*CFG.cawr_T, T_mult=CFG.cawr_Tmult),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    else:\n",
    "        return (SCHEDULERS[schedule_type][0],\n",
    "                SCHEDULERS[schedule_type][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch 0/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:04<14:49,  2.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/1991 [00:08<07:45,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 448/1991 [01:47<06:12,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:51<00:00,  4.22it/s]\n",
      "100%|██████████| 664/664 [02:26<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6035\tValidation Loss: 1.4785\n",
      "Counter train preds: Counter({0: 3956, 1: 2218, 2: 551, 4: 503, 3: 424, 5: 310})\tCounter val preds: Counter({0: 1067, 1: 509, 5: 468, 2: 304, 3: 204, 4: 102})\n",
      "Epoch train QWK: 0.276\tval QWK: 0.555\n",
      "  Epoch 0 - Save Best Loss: 1.4785 Model\n",
      "Confusion matrix, without normalization\n",
      "[[563  97   6   4  25  28]\n",
      " [250 209 138  38   8  23]\n",
      " [ 71  82 107  49   3  23]\n",
      " [ 63  57  23  63  11  94]\n",
      " [ 65  38  17  27  32 134]\n",
      " [ 55  26  13  23  23 166]]\n",
      "  Epoch 0 - Save Best QWK: 0.5547 Model\n",
      "Confusion matrix, without normalization\n",
      "[[563  97   6   4  25  28]\n",
      " [250 209 138  38   8  23]\n",
      " [ 71  82 107  49   3  23]\n",
      " [ 63  57  23  63  11  94]\n",
      " [ 65  38  17  27  32 134]\n",
      " [ 55  26  13  23  23 166]]\n",
      "Epoch 1/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:04<14:35,  2.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:08<00:00,  4.08it/s]\n",
      "100%|██████████| 664/664 [02:29<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4960\tValidation Loss: 1.3691\n",
      "Counter train preds: Counter({0: 2911, 1: 2727, 5: 880, 2: 540, 3: 482, 4: 422})\tCounter val preds: Counter({1: 1084, 0: 1010, 5: 336, 4: 140, 3: 47, 2: 37})\n",
      "Epoch train QWK: 0.474\tval QWK: 0.575\n",
      "  Epoch 1 - Save Best Loss: 1.3691 Model\n",
      "Confusion matrix, without normalization\n",
      "[[606 102   1   0   1  13]\n",
      " [166 475  17   2   2   4]\n",
      " [ 55 253   7   6   1  13]\n",
      " [ 60 110   9  21  33  78]\n",
      " [ 70  95   3   9  55  81]\n",
      " [ 53  49   0   9  48 147]]\n",
      "  Epoch 1 - Save Best QWK: 0.5749 Model\n",
      "Confusion matrix, without normalization\n",
      "[[606 102   1   0   1  13]\n",
      " [166 475  17   2   2   4]\n",
      " [ 55 253   7   6   1  13]\n",
      " [ 60 110   9  21  33  78]\n",
      " [ 70  95   3   9  55  81]\n",
      " [ 53  49   0   9  48 147]]\n",
      "Epoch 2/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:04<13:57,  2.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:05<00:00,  4.10it/s]\n",
      "100%|██████████| 664/664 [02:31<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4686\tValidation Loss: 1.3614\n",
      "Counter train preds: Counter({0: 3042, 1: 2411, 5: 948, 4: 691, 3: 451, 2: 419})\tCounter val preds: Counter({0: 1226, 1: 689, 5: 309, 3: 240, 4: 147, 2: 43})\n",
      "Epoch train QWK: 0.520\tval QWK: 0.606\n",
      "  Epoch 2 - Save Best Loss: 1.3614 Model\n",
      "Confusion matrix, without normalization\n",
      "[[681   9   1   0  23   9]\n",
      " [270 357  11  12  11   5]\n",
      " [ 72 180  21  53   6   3]\n",
      " [ 64  75   4 100  14  54]\n",
      " [ 84  51   3  36  52  87]\n",
      " [ 55  17   3  39  41 151]]\n",
      "  Epoch 2 - Save Best QWK: 0.6057 Model\n",
      "Confusion matrix, without normalization\n",
      "[[681   9   1   0  23   9]\n",
      " [270 357  11  12  11   5]\n",
      " [ 72 180  21  53   6   3]\n",
      " [ 64  75   4 100  14  54]\n",
      " [ 84  51   3  36  52  87]\n",
      " [ 55  17   3  39  41 151]]\n",
      "Epoch 3/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:56<00:00,  4.18it/s]\n",
      "100%|██████████| 664/664 [02:26<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4227\tValidation Loss: 1.3089\n",
      "Counter train preds: Counter({0: 3092, 1: 2125, 5: 939, 2: 740, 3: 735, 4: 331})\tCounter val preds: Counter({0: 1096, 1: 666, 5: 531, 2: 223, 4: 102, 3: 36})\n",
      "Epoch train QWK: 0.547\tval QWK: 0.673\n",
      "  Epoch 3 - Save Best Loss: 1.3089 Model\n",
      "Confusion matrix, without normalization\n",
      "[[675  30   2   0   8   8]\n",
      " [198 379  75   4   4   6]\n",
      " [ 56 144  94  11   3  27]\n",
      " [ 52  65  29  15  15 135]\n",
      " [ 66  32  14   4  54 143]\n",
      " [ 49  16   9   2  18 212]]\n",
      "  Epoch 3 - Save Best QWK: 0.6731 Model\n",
      "Confusion matrix, without normalization\n",
      "[[675  30   2   0   8   8]\n",
      " [198 379  75   4   4   6]\n",
      " [ 56 144  94  11   3  27]\n",
      " [ 52  65  29  15  15 135]\n",
      " [ 66  32  14   4  54 143]\n",
      " [ 49  16   9   2  18 212]]\n",
      "Epoch 4/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:03<12:04,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4199\tValidation Loss: 1.3386\n",
      "Counter train preds: Counter({0: 2780, 1: 2633, 5: 1311, 3: 467, 4: 389, 2: 382})\tCounter val preds: Counter({0: 926, 1: 636, 2: 495, 5: 459, 3: 72, 4: 66})\n",
      "Epoch train QWK: 0.544\tval QWK: 0.638\n",
      "Epoch 5/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:34<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4042\tValidation Loss: 1.2856\n",
      "Counter train preds: Counter({0: 2884, 1: 2590, 5: 1066, 3: 569, 4: 442, 2: 411})\tCounter val preds: Counter({0: 982, 1: 738, 5: 305, 4: 258, 3: 238, 2: 133})\n",
      "Epoch train QWK: 0.546\tval QWK: 0.674\n",
      "  Epoch 5 - Save Best Loss: 1.2856 Model\n",
      "Confusion matrix, without normalization\n",
      "[[630  79   1   1   3   9]\n",
      " [140 443  55  12  14   2]\n",
      " [ 45 131  54  61  33  11]\n",
      " [ 54  45  13  83  68  48]\n",
      " [ 61  32   6  50  99  65]\n",
      " [ 52   8   4  31  41 170]]\n",
      "  Epoch 5 - Save Best QWK: 0.6735 Model\n",
      "Confusion matrix, without normalization\n",
      "[[630  79   1   1   3   9]\n",
      " [140 443  55  12  14   2]\n",
      " [ 45 131  54  61  33  11]\n",
      " [ 54  45  13  83  68  48]\n",
      " [ 61  32   6  50  99  65]\n",
      " [ 52   8   4  31  41 170]]\n",
      "Epoch 6/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:35<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3947\tValidation Loss: 1.3460\n",
      "Counter train preds: Counter({0: 2860, 1: 2166, 5: 1270, 3: 621, 2: 620, 4: 425})\tCounter val preds: Counter({0: 995, 1: 688, 5: 444, 3: 254, 4: 163, 2: 110})\n",
      "Epoch train QWK: 0.582\tval QWK: 0.647\n",
      "Epoch 7/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:34<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4058\tValidation Loss: 1.2797\n",
      "Counter train preds: Counter({0: 2887, 1: 2165, 5: 1019, 2: 835, 4: 592, 3: 464})\tCounter val preds: Counter({0: 984, 1: 865, 5: 509, 4: 163, 2: 121, 3: 12})\n",
      "Epoch train QWK: 0.544\tval QWK: 0.700\n",
      "  Epoch 7 - Save Best Loss: 1.2797 Model\n",
      "Confusion matrix, without normalization\n",
      "[[654  53   1   0   0  15]\n",
      " [153 481  17   1   4  10]\n",
      " [ 45 187  64   5  10  24]\n",
      " [ 50  78  25   3  52 103]\n",
      " [ 41  49   7   3  76 137]\n",
      " [ 41  17   7   0  21 220]]\n",
      "  Epoch 7 - Save Best QWK: 0.6996 Model\n",
      "Confusion matrix, without normalization\n",
      "[[654  53   1   0   0  15]\n",
      " [153 481  17   1   4  10]\n",
      " [ 45 187  64   5  10  24]\n",
      " [ 50  78  25   3  52 103]\n",
      " [ 41  49   7   3  76 137]\n",
      " [ 41  17   7   0  21 220]]\n",
      "Epoch 8/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/1991 [04:44<02:46,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:34<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3728\tValidation Loss: 1.2753\n",
      "Counter train preds: Counter({0: 2759, 1: 2490, 5: 1204, 3: 617, 4: 504, 2: 388})\tCounter val preds: Counter({0: 978, 1: 828, 5: 407, 3: 231, 4: 123, 2: 87})\n",
      "Epoch train QWK: 0.607\tval QWK: 0.679\n",
      "  Epoch 8 - Save Best Loss: 1.2753 Model\n",
      "Confusion matrix, without normalization\n",
      "[[649  32   1   1   7  33]\n",
      " [168 476   8   4   5   5]\n",
      " [ 39 204  36  40   8   8]\n",
      " [ 41  67  26  84  21  72]\n",
      " [ 41  39  11  57  63 102]\n",
      " [ 40  10   5  45  19 187]]\n",
      "Epoch 9/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1112/1991 [04:13<03:17,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3632\tValidation Loss: 1.2637\n",
      "Counter train preds: Counter({0: 2792, 1: 2630, 5: 913, 3: 553, 2: 546, 4: 528})\tCounter val preds: Counter({0: 1098, 1: 911, 4: 238, 5: 221, 3: 142, 2: 44})\n",
      "Epoch train QWK: 0.583\tval QWK: 0.635\n",
      "  Epoch 9 - Save Best Loss: 1.2637 Model\n",
      "Confusion matrix, without normalization\n",
      "[[695  23   0   0   3   2]\n",
      " [170 481   7   2   6   0]\n",
      " [ 47 234  20  15  13   6]\n",
      " [ 56  90  16  68  53  28]\n",
      " [ 65  57   1  31  97  62]\n",
      " [ 65  26   0  26  66 123]]\n",
      "Epoch 10/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:03<11:35,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:34<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3480\tValidation Loss: 1.2530\n",
      "Counter train preds: Counter({0: 2775, 1: 2561, 5: 1008, 4: 578, 2: 547, 3: 493})\tCounter val preds: Counter({0: 1015, 1: 861, 4: 402, 3: 152, 5: 143, 2: 81})\n",
      "Epoch train QWK: 0.615\tval QWK: 0.674\n",
      "  Epoch 10 - Save Best Loss: 1.2530 Model\n",
      "Confusion matrix, without normalization\n",
      "[[672  46   1   0   3   1]\n",
      " [126 513  16   7   4   0]\n",
      " [ 36 190  36  51  17   5]\n",
      " [ 55  71  14  62  82  27]\n",
      " [ 69  29  10  24 162  19]\n",
      " [ 57  12   4   8 134  91]]\n",
      "Epoch 11/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:34<00:00,  4.38it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3497\tValidation Loss: 1.2679\n",
      "Counter train preds: Counter({0: 2722, 1: 2554, 5: 1219, 4: 557, 3: 478, 2: 432})\tCounter val preds: Counter({0: 1064, 1: 831, 5: 378, 4: 203, 3: 114, 2: 64})\n",
      "Epoch train QWK: 0.624\tval QWK: 0.659\n",
      "Epoch 12/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:03<12:05,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:47<00:00,  4.26it/s]\n",
      "100%|██████████| 664/664 [02:24<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3386\tValidation Loss: 1.3209\n",
      "Counter train preds: Counter({0: 2762, 1: 2336, 5: 1185, 2: 605, 3: 597, 4: 477})\tCounter val preds: Counter({0: 881, 5: 605, 1: 566, 2: 344, 3: 202, 4: 56})\n",
      "Epoch train QWK: 0.624\tval QWK: 0.716\n",
      "  Epoch 12 - Save Best QWK: 0.7158 Model\n",
      "Confusion matrix, without normalization\n",
      "[[621  62   3   1  14  22]\n",
      " [131 364 142   9   8  12]\n",
      " [ 26  83 140  52   5  29]\n",
      " [ 37  27  36  74   5 132]\n",
      " [ 33  23  13  52  20 172]\n",
      " [ 33   7  10  14   4 238]]\n",
      "Epoch 13/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:16<00:00,  4.01it/s]\n",
      "100%|██████████| 664/664 [02:29<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3407\tValidation Loss: 1.2463\n",
      "Counter train preds: Counter({0: 2717, 1: 2606, 5: 930, 4: 650, 2: 574, 3: 485})\tCounter val preds: Counter({0: 969, 1: 738, 5: 318, 3: 233, 4: 218, 2: 178})\n",
      "Epoch train QWK: 0.597\tval QWK: 0.703\n",
      "  Epoch 13 - Save Best Loss: 1.2463 Model\n",
      "Confusion matrix, without normalization\n",
      "[[666  28   5   3  12   9]\n",
      " [146 455  27  24  10   4]\n",
      " [ 30 173  73  38  14   7]\n",
      " [ 39  49  42  86  43  52]\n",
      " [ 52  26  15  46  84  90]\n",
      " [ 36   7  16  36  55 156]]\n",
      "Epoch 14/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:02<00:00,  4.13it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3271\tValidation Loss: 1.2281\n",
      "Counter train preds: Counter({0: 2760, 1: 2417, 3: 876, 5: 842, 4: 582, 2: 485})\tCounter val preds: Counter({0: 990, 1: 776, 5: 292, 4: 256, 3: 173, 2: 167})\n",
      "Epoch train QWK: 0.625\tval QWK: 0.705\n",
      "  Epoch 14 - Save Best Loss: 1.2281 Model\n",
      "Confusion matrix, without normalization\n",
      "[[670  46   1   1   1   4]\n",
      " [139 464  41  18   4   0]\n",
      " [ 38 163  80  23  15  16]\n",
      " [ 48  53  29  62  51  68]\n",
      " [ 52  36  12  50 119  44]\n",
      " [ 43  14   4  19  66 160]]\n",
      "Epoch 15/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:03<12:35,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:06<00:00,  4.09it/s]\n",
      "100%|██████████| 664/664 [02:27<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3338\tValidation Loss: 1.2473\n",
      "Counter train preds: Counter({0: 2612, 1: 2409, 5: 872, 3: 865, 4: 707, 2: 497})\tCounter val preds: Counter({0: 835, 1: 818, 3: 393, 4: 368, 5: 128, 2: 112})\n",
      "Epoch train QWK: 0.634\tval QWK: 0.703\n",
      "Epoch 16/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 1312/1991 [05:18<02:43,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:01<00:00,  4.13it/s]\n",
      "100%|██████████| 664/664 [02:25<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3129\tValidation Loss: 1.2241\n",
      "Counter train preds: Counter({0: 2733, 1: 2181, 5: 1036, 2: 707, 3: 673, 4: 632})\tCounter val preds: Counter({0: 1022, 1: 622, 2: 300, 5: 282, 4: 265, 3: 163})\n",
      "Epoch train QWK: 0.641\tval QWK: 0.698\n",
      "  Epoch 16 - Save Best Loss: 1.2241 Model\n",
      "Confusion matrix, without normalization\n",
      "[[677  20   7   0  13   6]\n",
      " [154 422  66  12  11   1]\n",
      " [ 47 125 110  33   8  12]\n",
      " [ 47  33  62  75  43  51]\n",
      " [ 52  16  35  25 125  60]\n",
      " [ 45   6  20  18  65 152]]\n",
      "Epoch 17/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:08<00:00,  4.07it/s]\n",
      "100%|██████████| 664/664 [02:22<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2982\tValidation Loss: 1.2609\n",
      "Counter train preds: Counter({0: 2757, 1: 2084, 2: 900, 5: 853, 3: 779, 4: 589})\tCounter val preds: Counter({0: 897, 1: 831, 5: 395, 4: 222, 2: 176, 3: 133})\n",
      "Epoch train QWK: 0.646\tval QWK: 0.709\n",
      "Epoch 18/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 1400/1991 [05:38<02:14,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:59<00:00,  4.15it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3142\tValidation Loss: 1.2553\n",
      "Counter train preds: Counter({0: 2687, 1: 2402, 5: 1156, 4: 637, 3: 613, 2: 467})\tCounter val preds: Counter({0: 905, 1: 781, 5: 536, 2: 233, 3: 136, 4: 63})\n",
      "Epoch train QWK: 0.646\tval QWK: 0.716\n",
      "  Epoch 18 - Save Best QWK: 0.7159 Model\n",
      "Confusion matrix, without normalization\n",
      "[[641  62   3   2   0  15]\n",
      " [107 483  52   9   3  12]\n",
      " [ 33 143 100  27  14  18]\n",
      " [ 42  55  45  64  16  89]\n",
      " [ 43  31  17  25  21 176]\n",
      " [ 39   7  16   9   9 226]]\n",
      "Epoch 19/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:05<17:42,  1.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:02<00:00,  4.13it/s]\n",
      "100%|██████████| 664/664 [02:27<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2749\tValidation Loss: 1.2410\n",
      "Counter train preds: Counter({0: 2644, 1: 2311, 5: 897, 2: 760, 4: 693, 3: 657})\tCounter val preds: Counter({0: 958, 1: 929, 5: 297, 3: 214, 4: 188, 2: 68})\n",
      "Epoch train QWK: 0.669\tval QWK: 0.691\n",
      "Epoch 20/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:56<00:00,  4.18it/s]\n",
      "100%|██████████| 664/664 [02:22<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2857\tValidation Loss: 1.2329\n",
      "Counter train preds: Counter({0: 2825, 1: 2143, 5: 1018, 3: 790, 2: 694, 4: 492})\tCounter val preds: Counter({0: 1032, 1: 795, 5: 384, 2: 196, 3: 171, 4: 76})\n",
      "Epoch train QWK: 0.665\tval QWK: 0.669\n",
      "Epoch 21/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 112/1991 [00:28<07:36,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:52<00:00,  4.21it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2730\tValidation Loss: 1.2054\n",
      "Counter train preds: Counter({0: 2699, 1: 2457, 5: 849, 3: 764, 4: 743, 2: 450})\tCounter val preds: Counter({0: 956, 1: 660, 4: 295, 2: 262, 5: 259, 3: 222})\n",
      "Epoch train QWK: 0.659\tval QWK: 0.736\n",
      "  Epoch 21 - Save Best Loss: 1.2054 Model\n",
      "Confusion matrix, without normalization\n",
      "[[674  27   5   3   5   9]\n",
      " [143 433  60  21   5   4]\n",
      " [ 29 127 117  48   8   6]\n",
      " [ 37  39  43  94  46  52]\n",
      " [ 44  24  23  38 141  43]\n",
      " [ 29  10  14  18  90 145]]\n",
      "  Epoch 21 - Save Best QWK: 0.7356 Model\n",
      "Confusion matrix, without normalization\n",
      "[[674  27   5   3   5   9]\n",
      " [143 433  60  21   5   4]\n",
      " [ 29 127 117  48   8   6]\n",
      " [ 37  39  43  94  46  52]\n",
      " [ 44  24  23  38 141  43]\n",
      " [ 29  10  14  18  90 145]]\n",
      "Epoch 22/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 48/1991 [00:14<07:48,  4.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:01<00:00,  4.13it/s]\n",
      "100%|██████████| 664/664 [02:26<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2898\tValidation Loss: 1.2700\n",
      "Counter train preds: Counter({0: 2661, 1: 2253, 4: 875, 5: 782, 2: 775, 3: 616})\tCounter val preds: Counter({0: 731, 1: 697, 5: 440, 2: 344, 3: 280, 4: 162})\n",
      "Epoch train QWK: 0.652\tval QWK: 0.737\n",
      "  Epoch 22 - Save Best QWK: 0.7371 Model\n",
      "Confusion matrix, without normalization\n",
      "[[554 126   3  16  11  13]\n",
      " [ 75 426 118  39   5   3]\n",
      " [ 20  83 150  58   7  17]\n",
      " [ 30  25  42 100  27  87]\n",
      " [ 29  27  22  46  80 109]\n",
      " [ 23  10   9  21  32 211]]\n",
      "Epoch 23/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:57<00:00,  4.17it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2813\tValidation Loss: 1.2171\n",
      "Counter train preds: Counter({0: 2665, 1: 2314, 5: 937, 4: 748, 3: 722, 2: 576})\tCounter val preds: Counter({1: 863, 0: 834, 4: 378, 5: 302, 2: 236, 3: 41})\n",
      "Epoch train QWK: 0.672\tval QWK: 0.729\n",
      "Epoch 24/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:04<14:54,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:04<00:00,  4.11it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2673\tValidation Loss: 1.2580\n",
      "Counter train preds: Counter({0: 2600, 1: 2221, 5: 982, 4: 794, 2: 693, 3: 672})\tCounter val preds: Counter({0: 957, 1: 692, 5: 397, 4: 316, 2: 206, 3: 86})\n",
      "Epoch train QWK: 0.684\tval QWK: 0.702\n",
      "Epoch 25/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [08:00<00:00,  4.15it/s]\n",
      "100%|██████████| 664/664 [02:24<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2578\tValidation Loss: 1.3557\n",
      "Counter train preds: Counter({0: 2649, 1: 2225, 5: 984, 4: 960, 2: 775, 3: 369})\tCounter val preds: Counter({0: 931, 5: 657, 1: 557, 4: 215, 3: 155, 2: 139})\n",
      "Epoch train QWK: 0.694\tval QWK: 0.725\n",
      "Epoch 26/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 648/1991 [02:42<05:08,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:04<00:00,  4.11it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2480\tValidation Loss: 1.1857\n",
      "Counter train preds: Counter({0: 2453, 1: 2139, 2: 996, 5: 989, 4: 732, 3: 653})\tCounter val preds: Counter({0: 1005, 1: 698, 4: 265, 5: 264, 3: 249, 2: 173})\n",
      "Epoch train QWK: 0.702\tval QWK: 0.723\n",
      "  Epoch 26 - Save Best Loss: 1.1857 Model\n",
      "Confusion matrix, without normalization\n",
      "[[682  30   1   0   3   7]\n",
      " [145 459  41  13   6   2]\n",
      " [ 41 138  81  48  22   5]\n",
      " [ 44  43  28  98  65  33]\n",
      " [ 49  26  14  48 124  52]\n",
      " [ 44   2   8  42  45 165]]\n",
      "Epoch 27/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:52<00:00,  4.21it/s]\n",
      "100%|██████████| 664/664 [02:22<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2340\tValidation Loss: 1.2042\n",
      "Counter train preds: Counter({0: 2513, 1: 2317, 2: 861, 5: 860, 4: 709, 3: 702})\tCounter val preds: Counter({0: 999, 1: 697, 4: 329, 5: 300, 2: 174, 3: 155})\n",
      "Epoch train QWK: 0.698\tval QWK: 0.733\n",
      "Epoch 28/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:04<14:19,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:56<00:00,  4.18it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2486\tValidation Loss: 1.2032\n",
      "Counter train preds: Counter({0: 2466, 1: 2404, 4: 901, 5: 891, 3: 793, 2: 507})\tCounter val preds: Counter({1: 914, 0: 907, 5: 448, 4: 132, 2: 130, 3: 123})\n",
      "Epoch train QWK: 0.698\tval QWK: 0.722\n",
      "Epoch 29/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:03<12:45,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:49<00:00,  4.24it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2353\tValidation Loss: 1.1944\n",
      "Counter train preds: Counter({0: 2561, 1: 2213, 5: 989, 2: 914, 4: 716, 3: 569})\tCounter val preds: Counter({0: 883, 1: 713, 4: 363, 5: 325, 3: 228, 2: 142})\n",
      "Epoch train QWK: 0.697\tval QWK: 0.740\n",
      "  Epoch 29 - Save Best QWK: 0.7397 Model\n",
      "Confusion matrix, without normalization\n",
      "[[641  43   1   0  19  19]\n",
      " [128 466  39  17  12   4]\n",
      " [ 23 142  68  64  20  18]\n",
      " [ 28  37  20  95  71  60]\n",
      " [ 38  21  10  31 155  58]\n",
      " [ 25   4   4  21  86 166]]\n",
      "Epoch 30/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/1991 [00:03<13:10,  2.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:37<00:00,  4.35it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2307\tValidation Loss: 1.2239\n",
      "Counter train preds: Counter({0: 2466, 1: 2368, 5: 1006, 3: 862, 4: 632, 2: 628})\tCounter val preds: Counter({1: 970, 0: 866, 5: 301, 3: 181, 4: 168, 2: 168})\n",
      "Epoch train QWK: 0.694\tval QWK: 0.708\n",
      "Epoch 31/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:19<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2078\tValidation Loss: 1.1962\n",
      "Counter train preds: Counter({0: 2637, 1: 2264, 5: 894, 2: 839, 4: 671, 3: 657})\tCounter val preds: Counter({1: 901, 0: 826, 5: 364, 2: 245, 4: 188, 3: 130})\n",
      "Epoch train QWK: 0.718\tval QWK: 0.747\n",
      "  Epoch 31 - Save Best QWK: 0.7471 Model\n",
      "Confusion matrix, without normalization\n",
      "[[620  89   1   0   4   9]\n",
      " [ 88 538  31   2   5   2]\n",
      " [ 27 167 105  18   4  14]\n",
      " [ 35  56  66  59  33  62]\n",
      " [ 27  40  29  33 102  82]\n",
      " [ 29  11  13  18  40 195]]\n",
      "Epoch 32/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:19<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2020\tValidation Loss: 1.1854\n",
      "Counter train preds: Counter({0: 2498, 1: 2444, 5: 1080, 2: 719, 3: 679, 4: 542})\tCounter val preds: Counter({0: 822, 1: 788, 4: 324, 5: 281, 3: 233, 2: 206})\n",
      "Epoch train QWK: 0.707\tval QWK: 0.769\n",
      "  Epoch 32 - Save Best Loss: 1.1854 Model\n",
      "Confusion matrix, without normalization\n",
      "[[638  63   2   4  13   3]\n",
      " [ 80 516  39  21   9   1]\n",
      " [ 25 151  92  35  12  20]\n",
      " [ 30  29  47  91  58  56]\n",
      " [ 24  25  19  51 149  45]\n",
      " [ 25   4   7  31  83 156]]\n",
      "  Epoch 32 - Save Best QWK: 0.7695 Model\n",
      "Confusion matrix, without normalization\n",
      "[[638  63   2   4  13   3]\n",
      " [ 80 516  39  21   9   1]\n",
      " [ 25 151  92  35  12  20]\n",
      " [ 30  29  47  91  58  56]\n",
      " [ 24  25  19  51 149  45]\n",
      " [ 25   4   7  31  83 156]]\n",
      "Epoch 33/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 112/1991 [00:27<07:05,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:19<00:00,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1976\tValidation Loss: 1.2801\n",
      "Counter train preds: Counter({0: 2529, 1: 2313, 5: 883, 4: 805, 2: 778, 3: 654})\tCounter val preds: Counter({1: 954, 0: 851, 5: 384, 3: 187, 4: 169, 2: 109})\n",
      "Epoch train QWK: 0.718\tval QWK: 0.652\n",
      "Epoch 34/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:03<12:18,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:33<00:00,  4.39it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2088\tValidation Loss: 1.1984\n",
      "Counter train preds: Counter({0: 2545, 1: 2487, 5: 885, 4: 699, 3: 693, 2: 653})\tCounter val preds: Counter({0: 848, 1: 759, 5: 331, 4: 277, 2: 275, 3: 164})\n",
      "Epoch train QWK: 0.710\tval QWK: 0.753\n",
      "Epoch 35/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [08:23<00:00,  3.95it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2086\tValidation Loss: 1.1950\n",
      "Counter train preds: Counter({0: 2667, 1: 2166, 4: 839, 3: 822, 2: 818, 5: 650})\tCounter val preds: Counter({0: 826, 1: 774, 5: 383, 3: 256, 4: 254, 2: 161})\n",
      "Epoch train QWK: 0.690\tval QWK: 0.748\n",
      "Epoch 36/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:03<13:34,  2.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:59<00:00,  4.15it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1834\tValidation Loss: 1.1888\n",
      "Counter train preds: Counter({0: 2578, 1: 2274, 5: 1033, 3: 744, 2: 732, 4: 601})\tCounter val preds: Counter({0: 960, 1: 720, 5: 405, 2: 246, 4: 181, 3: 142})\n",
      "Epoch train QWK: 0.717\tval QWK: 0.743\n",
      "Epoch 37/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 752/1991 [03:04<04:42,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:05<00:00,  4.10it/s]\n",
      "100%|██████████| 664/664 [02:25<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1664\tValidation Loss: 1.2020\n",
      "Counter train preds: Counter({0: 2566, 1: 2252, 5: 807, 3: 800, 2: 777, 4: 760})\tCounter val preds: Counter({1: 950, 0: 835, 4: 240, 5: 231, 3: 212, 2: 186})\n",
      "Epoch train QWK: 0.723\tval QWK: 0.713\n",
      "Epoch 38/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:54<00:00,  4.19it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1745\tValidation Loss: 1.2443\n",
      "Counter train preds: Counter({0: 2409, 1: 2347, 2: 926, 5: 793, 3: 787, 4: 700})\tCounter val preds: Counter({0: 932, 1: 754, 2: 291, 5: 289, 4: 270, 3: 118})\n",
      "Epoch train QWK: 0.732\tval QWK: 0.720\n",
      "Epoch 39/39\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:47<00:00,  4.26it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1722\tValidation Loss: 1.2147\n",
      "Counter train preds: Counter({0: 2437, 1: 2228, 5: 1015, 2: 894, 4: 772, 3: 616})\tCounter val preds: Counter({0: 886, 1: 675, 5: 396, 2: 281, 4: 245, 3: 171})\n",
      "Epoch train QWK: 0.728\tval QWK: 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "    \n",
    "# define a data loader\n",
    "train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "\n",
    "model_ft = Model(arch=\"resnet34\")\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)\n",
    "\n",
    "train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, model_name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "    \n",
    "# define a data loader\n",
    "train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(f'{MODEL_PATH}/{PREV_NAME}_loss.pth')\n",
    "\n",
    "model_ft = Model(arch=\"resnet34\")\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_ft.to(device)\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# set smaller lr here\n",
    "for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = CFG.lr / 10\n",
    "\n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Epoch 42/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 112/1991 [00:28<06:35,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1936/1991 [07:33<00:12,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:46<00:00,  4.27it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0242\tValidation Loss: 1.1500\n",
      "Counter train preds: Counter({0: 2374, 1: 2223, 5: 944, 3: 823, 2: 823, 4: 775})\tCounter val preds: Counter({0: 857, 1: 776, 5: 357, 2: 247, 4: 228, 3: 189})\n",
      "Epoch train QWK: 0.821\tval QWK: 0.767\n",
      "Epoch 43/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:37<00:00,  4.36it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.0048\tValidation Loss: 1.1754\n",
      "Counter train preds: Counter({0: 2385, 1: 2274, 5: 1002, 2: 808, 3: 769, 4: 724})\tCounter val preds: Counter({0: 887, 1: 774, 5: 443, 2: 232, 4: 174, 3: 144})\n",
      "Epoch train QWK: 0.826\tval QWK: 0.764\n",
      "Epoch 44/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 680/1991 [02:41<04:43,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:42<00:00,  4.30it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9964\tValidation Loss: 1.1647\n",
      "Counter train preds: Counter({0: 2323, 1: 2256, 5: 972, 2: 901, 4: 772, 3: 738})\tCounter val preds: Counter({0: 830, 1: 746, 2: 399, 5: 315, 4: 222, 3: 142})\n",
      "Epoch train QWK: 0.829\tval QWK: 0.761\n",
      "Epoch 45/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 1944/1991 [10:22<00:19,  2.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:36<00:00,  3.13it/s]\n",
      "100%|██████████| 664/664 [02:33<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9951\tValidation Loss: 1.1545\n",
      "Counter train preds: Counter({0: 2382, 1: 2189, 2: 893, 5: 888, 4: 860, 3: 750})\tCounter val preds: Counter({0: 916, 1: 762, 5: 309, 3: 231, 4: 220, 2: 216})\n",
      "Epoch train QWK: 0.827\tval QWK: 0.756\n",
      "Epoch 46/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|██████▎   | 1264/1991 [05:07<02:50,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [08:09<00:00,  4.07it/s]\n",
      "100%|██████████| 664/664 [02:28<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9811\tValidation Loss: 1.1511\n",
      "Counter train preds: Counter({0: 2383, 1: 2240, 5: 858, 4: 850, 2: 833, 3: 798})\tCounter val preds: Counter({0: 923, 1: 691, 2: 277, 4: 270, 5: 264, 3: 229})\n",
      "Epoch train QWK: 0.830\tval QWK: 0.770\n",
      "Epoch 47/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [19:04<00:00,  1.74it/s]\n",
      "100%|██████████| 664/664 [02:22<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9774\tValidation Loss: 1.1689\n",
      "Counter train preds: Counter({0: 2386, 1: 2184, 5: 1003, 2: 872, 3: 785, 4: 732})\tCounter val preds: Counter({0: 924, 1: 723, 5: 358, 2: 275, 4: 230, 3: 144})\n",
      "Epoch train QWK: 0.833\tval QWK: 0.766\n",
      "Epoch 48/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/1991 [00:02<08:48,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:29<00:00,  4.43it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9715\tValidation Loss: 1.1707\n",
      "Counter train preds: Counter({0: 2372, 1: 2192, 5: 935, 2: 877, 4: 822, 3: 764})\tCounter val preds: Counter({0: 888, 1: 769, 5: 322, 2: 279, 4: 267, 3: 129})\n",
      "Epoch train QWK: 0.838\tval QWK: 0.767\n",
      "Epoch 49/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 617/1991 [02:18<04:37,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:30<00:00,  4.42it/s]\n",
      "100%|██████████| 664/664 [02:20<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9653\tValidation Loss: 1.1681\n",
      "Counter train preds: Counter({0: 2375, 1: 2139, 5: 1003, 2: 914, 4: 821, 3: 710})\tCounter val preds: Counter({0: 907, 1: 651, 5: 381, 2: 283, 4: 220, 3: 212})\n",
      "Epoch train QWK: 0.842\tval QWK: 0.774\n",
      "  Epoch 49 - Save Best QWK: 0.7735 Model\n",
      "Confusion matrix, without normalization\n",
      "[[667  40   6   0   3   7]\n",
      " [115 457  73  10   8   3]\n",
      " [ 22 117 128  42  10  16]\n",
      " [ 35  19  48 102  48  59]\n",
      " [ 37  13  21  37 115  90]\n",
      " [ 31   5   7  21  36 206]]\n",
      "Epoch 50/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/1991 [00:03<09:34,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:31<00:00,  4.41it/s]\n",
      "100%|██████████| 664/664 [02:21<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9539\tValidation Loss: 1.1952\n",
      "Counter train preds: Counter({0: 2316, 1: 2189, 5: 956, 2: 907, 4: 892, 3: 702})\tCounter val preds: Counter({0: 949, 1: 781, 5: 327, 4: 235, 3: 201, 2: 161})\n",
      "Epoch train QWK: 0.852\tval QWK: 0.738\n",
      "Epoch 51/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:32<00:00,  4.40it/s]\n",
      "100%|██████████| 664/664 [02:22<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9425\tValidation Loss: 1.1649\n",
      "Counter train preds: Counter({0: 2293, 1: 2180, 5: 969, 2: 961, 4: 819, 3: 740})\tCounter val preds: Counter({0: 888, 1: 707, 4: 327, 5: 316, 2: 244, 3: 172})\n",
      "Epoch train QWK: 0.844\tval QWK: 0.776\n",
      "  Epoch 51 - Save Best QWK: 0.7756 Model\n",
      "Confusion matrix, without normalization\n",
      "[[659  49   1   0   7   7]\n",
      " [113 473  61   8   8   3]\n",
      " [ 22 136 114  31  17  15]\n",
      " [ 35  25  42  87  74  48]\n",
      " [ 31  18  18  30 157  59]\n",
      " [ 28   6   8  16  64 184]]\n",
      "Epoch 52/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 376/1991 [01:29<06:02,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:40<00:00,  4.33it/s]\n",
      "100%|██████████| 664/664 [02:24<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9375\tValidation Loss: 1.1874\n",
      "Counter train preds: Counter({0: 2353, 1: 2113, 2: 999, 5: 920, 4: 878, 3: 699})\tCounter val preds: Counter({0: 946, 1: 727, 5: 339, 2: 272, 4: 224, 3: 146})\n",
      "Epoch train QWK: 0.857\tval QWK: 0.746\n",
      "Epoch 53/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:03<10:56,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:42<00:00,  4.31it/s]\n",
      "100%|██████████| 664/664 [02:26<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9320\tValidation Loss: 1.1796\n",
      "Counter train preds: Counter({0: 2342, 1: 2113, 5: 961, 2: 933, 4: 874, 3: 739})\tCounter val preds: Counter({0: 878, 1: 715, 5: 407, 2: 281, 4: 204, 3: 169})\n",
      "Epoch train QWK: 0.847\tval QWK: 0.760\n",
      "Epoch 54/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [07:44<00:00,  4.28it/s]\n",
      "100%|██████████| 664/664 [02:23<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9323\tValidation Loss: 1.1785\n",
      "Counter train preds: Counter({0: 2321, 1: 2114, 2: 1030, 4: 918, 5: 835, 3: 744})\tCounter val preds: Counter({0: 912, 1: 649, 5: 304, 4: 289, 2: 263, 3: 237})\n",
      "Epoch train QWK: 0.846\tval QWK: 0.771\n",
      "Epoch 55/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 8/1991 [00:02<10:15,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [07:39<00:00,  4.33it/s]\n",
      "100%|██████████| 664/664 [02:26<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.9163\tValidation Loss: 1.1703\n",
      "Counter train preds: Counter({0: 2321, 1: 2101, 2: 972, 5: 946, 4: 823, 3: 799})\tCounter val preds: Counter({0: 939, 1: 634, 2: 361, 5: 287, 4: 237, 3: 196})\n",
      "Epoch train QWK: 0.868\tval QWK: 0.761\n",
      "Epoch 56/69\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 1052/1991 [10:27<09:19,  1.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-500926fac9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_eval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msch_is_epoch_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPREV_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-709fd7364933>\u001b[0m in \u001b[0;36mtrain_eval_loop\u001b[0;34m(train_dataloader, val_dataloader, model, optimizer, criterion, scheduler, sch_is_epoch_type, accum_step, checkpoint, num_epochs, device, tb_tag, model_name)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Iterate over train data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtk_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtk_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Calculate global step for TensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mtrain_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, model_name=PREV_NAME, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with CV, on fold 0\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7832\tValidation Loss: 1.6735\n",
      "Counter train preds: Counter({1: 50, 4: 11, 3: 8, 0: 6})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.193\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5393\tValidation Loss: 1.6932\n",
      "Counter train preds: Counter({1: 39, 0: 21, 3: 7, 4: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.236\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4436\tValidation Loss: 1.7056\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 7, 5: 5, 4: 3})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.321\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4152\tValidation Loss: 1.6723\n",
      "Counter train preds: Counter({0: 33, 1: 31, 3: 5, 4: 5, 5: 1})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.282\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3904\tValidation Loss: 1.6386\n",
      "Counter train preds: Counter({1: 33, 0: 28, 4: 6, 3: 5, 5: 3})\tCounter val preds: Counter({1: 15, 5: 3, 0: 3, 2: 2, 4: 1, 3: 1})\n",
      "Epoch train QWK: 0.393\tval QWK: 0.186\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3730\tValidation Loss: 1.6927\n",
      "Counter train preds: Counter({0: 33, 1: 26, 5: 7, 3: 4, 4: 4, 2: 1})\tCounter val preds: Counter({1: 13, 5: 6, 2: 4, 3: 1, 0: 1})\n",
      "Epoch train QWK: 0.517\tval QWK: 0.545\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3238\tValidation Loss: 1.8837\n",
      "Counter train preds: Counter({0: 30, 1: 29, 5: 6, 3: 6, 4: 4})\tCounter val preds: Counter({1: 9, 5: 7, 2: 6, 3: 3})\n",
      "Epoch train QWK: 0.438\tval QWK: 0.329\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3055\tValidation Loss: 2.0990\n",
      "Counter train preds: Counter({1: 34, 0: 22, 5: 8, 3: 7, 4: 2, 2: 2})\tCounter val preds: Counter({2: 12, 5: 5, 3: 5, 1: 2, 4: 1})\n",
      "Epoch train QWK: 0.552\tval QWK: 0.326\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.53it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3063\tValidation Loss: 2.0883\n",
      "Counter train preds: Counter({1: 35, 0: 25, 4: 7, 3: 5, 5: 3})\tCounter val preds: Counter({2: 13, 5: 5, 1: 3, 3: 2, 4: 1, 0: 1})\n",
      "Epoch train QWK: 0.549\tval QWK: 0.199\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.8377\n",
      "Counter train preds: Counter({1: 37, 0: 24, 5: 7, 4: 3, 3: 3, 2: 1})\tCounter val preds: Counter({1: 21, 3: 2, 2: 1, 5: 1})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.305\n",
      "Train with CV, on fold 1\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7209\tValidation Loss: 1.7380\n",
      "Counter train preds: Counter({0: 59, 3: 15, 1: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.263\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5459\tValidation Loss: 1.7958\n",
      "Counter train preds: Counter({0: 36, 1: 32, 3: 5, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.331\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4606\tValidation Loss: 1.9763\n",
      "Counter train preds: Counter({1: 34, 0: 29, 4: 8, 3: 4})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4206\tValidation Loss: 1.8872\n",
      "Counter train preds: Counter({1: 32, 0: 24, 4: 8, 3: 6, 5: 3, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.441\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4067\tValidation Loss: 2.2129\n",
      "Counter train preds: Counter({1: 36, 0: 25, 3: 10, 5: 2, 2: 1, 4: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3640\tValidation Loss: 2.9000\n",
      "Counter train preds: Counter({1: 33, 0: 24, 3: 12, 2: 4, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.364\tval QWK: 0.000\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3085\tValidation Loss: 2.7819\n",
      "Counter train preds: Counter({1: 33, 0: 20, 3: 11, 2: 4, 4: 4, 5: 3})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.568\tval QWK: 0.000\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3142\tValidation Loss: 2.3783\n",
      "Counter train preds: Counter({1: 36, 0: 21, 3: 9, 2: 5, 5: 3, 4: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.116\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2917\tValidation Loss: 3.1009\n",
      "Counter train preds: Counter({1: 38, 0: 19, 2: 6, 4: 5, 3: 4, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.433\tval QWK: 0.009\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2545\tValidation Loss: 2.9466\n",
      "Counter train preds: Counter({1: 32, 0: 20, 3: 10, 4: 5, 2: 5, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.635\tval QWK: 0.009\n",
      "Train with CV, on fold 2\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6856\tValidation Loss: 1.8174\n",
      "Counter train preds: Counter({1: 48, 3: 15, 0: 12})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.208\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5455\tValidation Loss: 2.4182\n",
      "Counter train preds: Counter({1: 37, 0: 21, 3: 16, 2: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.313\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4741\tValidation Loss: 2.2700\n",
      "Counter train preds: Counter({1: 33, 0: 26, 3: 14, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.287\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4289\tValidation Loss: 2.4097\n",
      "Counter train preds: Counter({1: 35, 0: 28, 3: 7, 2: 5})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.247\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3615\tValidation Loss: 2.0392\n",
      "Counter train preds: Counter({1: 39, 0: 25, 3: 7, 2: 4})\tCounter val preds: Counter({0: 24, 2: 1})\n",
      "Epoch train QWK: 0.307\tval QWK: 0.064\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4250\tValidation Loss: 1.6867\n",
      "Counter train preds: Counter({1: 41, 0: 26, 3: 8})\tCounter val preds: Counter({0: 20, 2: 3, 1: 2})\n",
      "Epoch train QWK: 0.266\tval QWK: 0.214\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3328\tValidation Loss: 1.7360\n",
      "Counter train preds: Counter({1: 34, 0: 24, 3: 12, 2: 4, 5: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.365\tval QWK: 0.130\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3236\tValidation Loss: 1.8248\n",
      "Counter train preds: Counter({1: 33, 0: 21, 2: 13, 3: 6, 5: 2})\tCounter val preds: Counter({0: 17, 1: 5, 2: 3})\n",
      "Epoch train QWK: 0.316\tval QWK: 0.272\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2498\tValidation Loss: 2.4719\n",
      "Counter train preds: Counter({1: 34, 0: 24, 2: 8, 3: 8, 5: 1})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.392\tval QWK: 0.259\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2657\tValidation Loss: 2.4212\n",
      "Counter train preds: Counter({1: 39, 0: 21, 2: 6, 3: 6, 5: 3})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.409\tval QWK: 0.259\n",
      "Train with CV, on fold 3\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7337\tValidation Loss: 1.6500\n",
      "Counter train preds: Counter({1: 49, 2: 14, 0: 6, 5: 3, 3: 3})\tCounter val preds: Counter({1: 24, 0: 1})\n",
      "Epoch train QWK: 0.123\tval QWK: -0.030\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5647\tValidation Loss: 1.7000\n",
      "Counter train preds: Counter({1: 40, 0: 18, 3: 12, 2: 5})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.232\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4733\tValidation Loss: 1.6935\n",
      "Counter train preds: Counter({1: 33, 0: 27, 3: 13, 2: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.337\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4141\tValidation Loss: 1.6876\n",
      "Counter train preds: Counter({0: 29, 1: 28, 3: 10, 2: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.475\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3655\tValidation Loss: 1.6186\n",
      "Counter train preds: Counter({1: 35, 0: 26, 3: 7, 5: 4, 2: 3})\tCounter val preds: Counter({1: 21, 2: 3, 0: 1})\n",
      "Epoch train QWK: 0.395\tval QWK: 0.012\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3591\tValidation Loss: 1.6763\n",
      "Counter train preds: Counter({1: 32, 0: 23, 3: 11, 2: 8, 5: 1})\tCounter val preds: Counter({2: 17, 0: 6, 1: 2})\n",
      "Epoch train QWK: 0.413\tval QWK: 0.313\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.6529\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 5, 2: 4, 4: 4, 5: 2})\tCounter val preds: Counter({1: 12, 2: 9, 5: 2, 0: 2})\n",
      "Epoch train QWK: 0.424\tval QWK: 0.269\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3050\tValidation Loss: 1.7019\n",
      "Counter train preds: Counter({1: 36, 0: 21, 2: 6, 3: 5, 5: 4, 4: 3})\tCounter val preds: Counter({2: 13, 5: 7, 4: 3, 0: 2})\n",
      "Epoch train QWK: 0.454\tval QWK: 0.364\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.99it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2645\tValidation Loss: 1.7029\n",
      "Counter train preds: Counter({1: 36, 0: 22, 5: 7, 2: 5, 3: 4, 4: 1})\tCounter val preds: Counter({2: 10, 5: 5, 0: 5, 1: 4, 3: 1})\n",
      "Epoch train QWK: 0.461\tval QWK: 0.309\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2169\tValidation Loss: 2.0975\n",
      "Counter train preds: Counter({1: 33, 0: 22, 2: 9, 3: 6, 5: 5})\tCounter val preds: Counter({4: 14, 5: 8, 0: 3})\n",
      "Epoch train QWK: 0.530\tval QWK: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"test_fold_{}.pth\"\n",
    "for fold in range(CFG.n_fold):\n",
    "    train_df = folds[folds[\"fold\"] != fold].copy()\n",
    "    val_df = folds[folds[\"fold\"] == fold].copy()\n",
    "    \n",
    "    train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "    val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "    \n",
    "    model = TinyV2ConvNet(CFG.target_size)\n",
    "    # initialize bias in the model\n",
    "    cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "    model = init_last_layer_bias(model, cls_probas)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    print(f\"Train with CV, on fold {fold}\")\n",
    "    model = train_eval_loop(train_ds, val_ds, model, optimizer, criterion, tb_tag=fold)\n",
    "    torch.save(model.state_dict(), MODEL_PATH/checkpoint.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestxray",
   "language": "python",
   "name": "chestxray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
