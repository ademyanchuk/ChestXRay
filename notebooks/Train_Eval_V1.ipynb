{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingWarmRestarts\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from apex import amp\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2\n",
    "import skimage.io\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "from chestxray.config import (PANDA_PATH,\n",
    "                              MODEL_PATH,\n",
    "                              PANDA_IMGS,\n",
    "                              PANDA_MASKS,\n",
    "                              TRAIN_CSV)\n",
    "# Competition related config\n",
    "from chestxray.config import CFG\n",
    "\n",
    "# Misc\n",
    "from chestxray.misc import seed_torch\n",
    "\n",
    "# Datasets\n",
    "from chestxray.datasets import get_transforms, TrainDataset, TilesTrainDataset, LazyTilesDataset, PatchTrainDataset, H5PatchDataset, SeqenceRandomSampler\n",
    "\n",
    "# Viz\n",
    "from chestxray.visualize import (show_from_ids, show_batch, imshow, \n",
    "                                 plot_classes_preds, reverse_show_img, \n",
    "                                 plot_confusion_matrix, text_classes_preds)\n",
    "\n",
    "# Nets\n",
    "from chestxray.nets import TinyV2ConvNet, freeze_botom, PatchModel\n",
    "from chestxray.model_utils import (trainable_params, cce_loss_at_init, \n",
    "                                   init_last_layer_bias)\n",
    "# Losses\n",
    "from chestxray.losses import LabelSmoothSoftmaxCEV1\n",
    "\n",
    "# Optim\n",
    "from chestxray.optimizers import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='GeForce RTX 2070 SUPER', major=7, minor=5, total_memory=7979MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = pd.read_csv(TRAIN_CSV)\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 381
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = TRAIN_DF[CFG.target_col].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-06-2020-08-31\n"
     ]
    }
   ],
   "source": [
    "CFG.debug = False\n",
    "now = datetime.now()\n",
    "\n",
    "EXP_NAME = now.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "print(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs version 1\n",
    "writer = SummaryWriter(f'runs_v1/{EXP_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter(f'runs/{EXP_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if resume should define from what to start\n",
    "PREV_NAME = \"03-06-2020-07-43\"\n",
    "writer = SummaryWriter(f\"runs_v1/{PREV_NAME}_b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = {\n",
    "    \"cce\" : nn.CrossEntropyLoss(),\n",
    "    \"ls_soft_ce\" : LabelSmoothSoftmaxCEV1(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key - string, value - tuple(sceduler, if it epoch type)\n",
    "epoch_type = True\n",
    "SCHEDULERS = {\n",
    "    \"reduce_on_plateau\" : (ReduceLROnPlateau, epoch_type),\n",
    "    \"one_cycle\": (OneCycleLR, not epoch_type),\n",
    "    \"cawr\": (CosineAnnealingWarmRestarts, not epoch_type),\n",
    "    \"none\": (None, None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Eval Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_loop(train_dataloader, val_dataloader, model, optimizer, criterion, scheduler, sch_is_epoch_type, accum_step=CFG.accum_step, checkpoint=False,\n",
    "                    num_epochs=CFG.epoch, device=device, tb_tag=\"\", model_name=\"debug\"):\n",
    "    \"\"\"Split it into the set of inner functions to siplify the loop itself\"\"\"\n",
    "    # Inner Functions\n",
    "    # write to TensorBoard helpers\n",
    "    def weights_to_tb(step=0):\n",
    "        conv1_weight = list(model.parameters())[0].data.to(\"cpu\")\n",
    "        img_grid = torchvision.utils.make_grid(conv1_weight.float(), normalize=True)\n",
    "        writer.add_image(tag=f\"Model conv1 weights {tb_tag}\", img_tensor=img_grid, global_step=step)\n",
    "    \n",
    "    def input_img_to_tb(inputs, step):\n",
    "        img = reverse_show_img(inputs[0], denorm=True)\n",
    "        writer.add_image(tag=f\"Input Image {tb_tag}\", img_tensor=img, global_step=step, dataformats=\"HWC\")\n",
    "        del img\n",
    "    \n",
    "    def preds_to_tb(outputs, inputs, labels, step):\n",
    "        figure=plot_classes_preds(outputs.to('cpu'), inputs.to('cpu'), labels.to('cpu'))\n",
    "        writer.add_figure(tag=f\"Actuals vs Predictions {tb_tag}\", figure=figure, global_step=step)\n",
    "    \n",
    "    def text_preds_to_tb(outputs, labels, step):\n",
    "        preds_text = text_classes_preds(outputs.to(\"cpu\"), labels.to(\"cpu\"))\n",
    "        writer.add_text(f\"Actuals vs Predictions {tb_tag}\", preds_text, global_step=step)\n",
    "        \n",
    "    def metrics_to_tb(mode, train_loss, train_score, val_loss, val_score, step):\n",
    "        writer.add_text(f\"On best {mode} save:\", \n",
    "                        f\"tr_loss: {train_loss:.4f}, tr_qwk: {train_score:.4f}, val_loss: {val_loss:.4f}, val_qwk: {val_score:.4f}\", \n",
    "                        global_step=step)\n",
    "    \n",
    "    def conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, step):\n",
    "        writer.add_figure(tag=f\"Confusion matrix {tb_tag}\", figure=plot_confusion_matrix(val_epoch_labels, val_epoch_preds, normalize=True),\n",
    "                          global_step=step)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Train/Eval Loop\n",
    "    # write first layer weights to TB @ init phase\n",
    "    if not CFG.debug:\n",
    "        weights_to_tb()\n",
    "    \n",
    "    # prepare model and optimizer\n",
    "    model.to(device)\n",
    "    if CFG.use_amp: # automatic mixed precision\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n",
    "    # define epochs numbers to look into input images and predictions, no more than 10 times per full training\n",
    "    vis_step = np.ceil(num_epochs/10).astype(int)\n",
    "    visual_epochs = list(range(0, num_epochs, vis_step))\n",
    "    # metrics to wathch for model checkpointing\n",
    "    best_qwk = -100 if not checkpoint else checkpoint['best_qwk']\n",
    "    best_val_loss = np.inf if not checkpoint else checkpoint[\"best_val_loss\"]\n",
    "    \n",
    "    start_epoch = 0 if not checkpoint else checkpoint[\"epoch\"] + 1\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('=' * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        # Set training mode\n",
    "        model.train();\n",
    "        train_running_loss = 0.0\n",
    "        train_epoch_preds, train_epoch_labels = [], []\n",
    "        \n",
    "        # We accumulate, zero at training epoch begins\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Iterate over train data.\n",
    "        tk_train = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for i, data in tk_train:\n",
    "            # Calculate global step for TensorBoard\n",
    "            train_global_step = epoch * len(train_dataloader) + i\n",
    "\n",
    "            inputs, labels = data\n",
    "            # Visualize input before model at the middle of epoch:\n",
    "            if epoch in visual_epochs and i == len(train_dataloader) // 2:\n",
    "                input_img_to_tb(inputs, train_global_step)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if CFG.use_amp:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            # we accumulate gradients and make optimization step once per # of accum_step\n",
    "            if (i+1)% accum_step == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # loss is mean across batch, divide by number of steps in epoch (so loss is normalized)\n",
    "            train_running_loss += loss.item() / len(train_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Training loss {tb_tag}\", scalar_value=loss.item(), global_step=train_global_step)\n",
    "\n",
    "            # collect train preds and labels for QWK\n",
    "            train_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            train_epoch_labels.append(labels.to('cpu').numpy())\n",
    "            # Add Batch Type Scheduler step here:\n",
    "            if scheduler and not sch_is_epoch_type:\n",
    "                scheduler.step()\n",
    "        # Validation Phase\n",
    "        # Set evaluation mode\n",
    "        model.eval();\n",
    "        val_running_loss = 0.0\n",
    "        val_epoch_preds, val_epoch_labels = [], []\n",
    "        # Iterate over val data\n",
    "        tk_val = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "        for j, data in tk_val:\n",
    "            # Calculate global step\n",
    "            val_global_step = epoch * len(val_dataloader) + j\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() / len(val_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(tag=f\"Validation loss {tb_tag}\", scalar_value=loss.item(), global_step=val_global_step)\n",
    "\n",
    "            # collect validation preds and labels for QWK\n",
    "            val_epoch_preds.append(outputs.data.to('cpu').numpy().argmax(1))\n",
    "            val_epoch_labels.append(labels.to('cpu').numpy())\n",
    "\n",
    "            # visualise predictions for 0th validation batch\n",
    "            if epoch in visual_epochs and j == 0:\n",
    "                text_preds_to_tb(outputs, labels, val_global_step)\n",
    "        \n",
    "        # Epoch type Schedulers\n",
    "        if scheduler and sch_is_epoch_type:\n",
    "            scheduler.step(val_running_loss)\n",
    "        # Write lr to TBD\n",
    "        if CFG.finetune == \"1stage\":\n",
    "            writer.add_scalar(tag=f\"lr Interim {tb_tag}:\", scalar_value=optimizer.param_groups[0][\"lr\"], global_step=train_global_step)\n",
    "            writer.add_scalar(tag=f\"lr Classifier {tb_tag}:\", scalar_value=optimizer.param_groups[1][\"lr\"], global_step=train_global_step)\n",
    "            \n",
    "        else:\n",
    "            writer.add_scalar(tag=f\"lr {tb_tag}:\", scalar_value=optimizer.param_groups[0][\"lr\"], global_step=train_global_step)\n",
    "        \n",
    "        # \"End of Epoch\" Phase\n",
    "        print(f'Training Loss: {train_running_loss:.4f}\\tValidation Loss: {val_running_loss:.4f}')\n",
    "        \n",
    "        # Calculate epoch predictions distribution\n",
    "        train_epoch_preds = np.concatenate(train_epoch_preds)\n",
    "        train_epoch_labels = np.concatenate(train_epoch_labels)\n",
    "        val_epoch_preds = np.concatenate(val_epoch_preds)\n",
    "        val_epoch_labels = np.concatenate(val_epoch_labels)\n",
    "        print(f'Counter train preds: {Counter(train_epoch_preds)}\\tCounter val preds: {Counter(val_epoch_preds)}')\n",
    "        # Calculate epoch QWK\n",
    "        train_qwk = cohen_kappa_score(train_epoch_preds, train_epoch_labels, weights='quadratic')\n",
    "        val_qwk = cohen_kappa_score(val_epoch_preds, val_epoch_labels, weights='quadratic')\n",
    "        print(f\"Epoch train QWK: {train_qwk:.3f}\\tval QWK: {val_qwk:.3f}\")\n",
    "        writer.add_scalar(tag=f\"Training QWK {tb_tag}\", scalar_value=train_qwk, global_step=epoch)\n",
    "        writer.add_scalar(tag=f\"Validation QWK {tb_tag}\", scalar_value=val_qwk, global_step=epoch)\n",
    "        \n",
    "        # On the best val loss do:\n",
    "        if val_running_loss < best_val_loss:\n",
    "            # update best and save model\n",
    "            best_val_loss = val_running_loss\n",
    "            print(f'  Epoch {epoch} - Save Best Loss: {best_val_loss:.4f} Model')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_qwk': best_qwk,\n",
    "            }, f'{MODEL_PATH}/{model_name}_loss.pth')\n",
    "            # add losses as text to TB\n",
    "            metrics_to_tb(\"loss\", train_running_loss, train_qwk, val_running_loss, val_qwk, val_global_step)\n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                weights_to_tb(val_global_step)\n",
    "            # add confusion matrix to TB\n",
    "            conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, val_global_step)\n",
    "        # On the best QWK\n",
    "        if val_qwk > best_qwk:\n",
    "            # update best and save model\n",
    "            best_qwk = val_qwk\n",
    "            print(f'  Epoch {epoch} - Save Best QWK: {best_qwk:.4f} Model')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_qwk': best_qwk,\n",
    "            }, f'{MODEL_PATH}/{model_name}_qwk.pth')\n",
    "            # add losses and qwk as text to TB\n",
    "            metrics_to_tb(\"qwk\", train_running_loss, train_qwk, val_running_loss, val_qwk, val_global_step)\n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                weights_to_tb(val_global_step)  \n",
    "            # add confusion matrix to TB\n",
    "            conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, val_global_step)\n",
    "    # End of loop\n",
    "    return model, best_val_loss, best_qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CV - strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    folds_fn = \"folds_db.csv\"\n",
    "    try: \n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.sample(n=100, random_state=CFG.seed).reset_index(drop=True).copy()\n",
    "else:\n",
    "    folds_fn = \"folds.csv\"\n",
    "    try:\n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PANDA_PATH/folds_fn).exists():\n",
    "    train_labels = folds[CFG.target_col].values\n",
    "    kf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n",
    "        folds.loc[val_index, 'fold'] = int(fold)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(PANDA_PATH/folds_fn, index=None)\n",
    "    folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10616 entries, 0 to 10615\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   image_id       10616 non-null  object\n",
      " 1   data_provider  10616 non-null  object\n",
      " 2   isup_grade     10616 non-null  int64 \n",
      " 3   gleason_score  10616 non-null  object\n",
      " 4   fold           10616 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 414.8+ KB\n"
     ]
    }
   ],
   "source": [
    "folds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter(f'runs/debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: True seed: 1982 img_height: 256 img_width: 256 target_size: 6 img_id_col: image_id target_col: isup_grade tiff_layer: 1 stoch_sample: True num_tiles: 32 tile_sz: 256 batch_size: 2 accum_step: 2 dataset: patch aug_type: heavy arch: bitM finetune: False model_cls: one_layer loss: ls_soft_ce optim: radam lr: 5e-05 schedule_type: none cawr_T: 1 cawr_Tmult: 2 rlopp: 1 epoch: 30 n_fold: 4 use_amp: True\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedulers\n",
    "def get_scheduler(optimizer,train_dataloader, schedule_type=CFG.schedule_type, resume=False):\n",
    "    assert schedule_type in SCHEDULERS, f\"{schedule_type} not in SCHEDULERS\"\n",
    "    if schedule_type == \"reduce_on_plateau\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, 'min', factor=0.5, patience=CFG.rlopp if not resume else CFG.rlopp + 2, verbose=True), \n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    if schedule_type == \"one_cycle\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, max_lr=[CFG.lr, CFG.lr*10] if CFG.finetune == \"1stage\" else CFG.lr,\n",
    "                                             steps_per_epoch=len(train_dataloader), epochs=CFG.epoch, pct_start=0.05),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    if schedule_type == \"cawr\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, T_0=len(train_dataloader)*CFG.cawr_T, T_mult=CFG.cawr_Tmult),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    else:\n",
    "        return (SCHEDULERS[schedule_type][0],\n",
    "                SCHEDULERS[schedule_type][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9b5e98882a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m# initialize bias in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcls_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ChestXRay/chestxray/nets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arch, n, pretrained)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# BiT Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0march\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bitM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_BiT_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ChestXRay/chestxray/nets.py\u001b[0m in \u001b[0;36mmake_BiT_model\u001b[0;34m(num_classes, pretrained)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_BiT_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BiT-M-R50x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNetV2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBLOCK_UNITS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r50'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ChestXRay/chestxray/bit_net.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(bit_variant)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbit_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     response = requests.get(\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;34mf\"https://storage.googleapis.com/bit_models/{bit_variant}.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "elif CFG.dataset == \"hdf5\":\n",
    "    train_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patches500.h5\"])\n",
    "    sampler = SeqenceRandomSampler(len(train_ds), train_ds._common_len)\n",
    "    val_ds = train_ds\n",
    "else:\n",
    "    print(f\"No such dataset {CFG.dataset}\")\n",
    "\n",
    "# define a data loader\n",
    "if CFG.dataset == \"hdf5\":\n",
    "    # use specific sampler (so not to load hdf5 files to memory too frequently)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler, num_workers=1, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "\n",
    "model_ft = PatchModel(arch=CFG.arch)\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)\n",
    "\n",
    "_ = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "#### Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39527bfec9a5472097e0dcab65b96d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 401
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    \n",
    "# define a data loader\n",
    "train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "\n",
    "model_ft = Model(arch=\"resnet34\")\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "model_ft.to(device)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr * 1e-4, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr * 1e-4, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr * 1e-4)\n",
    "    \n",
    "if CFG.use_amp:\n",
    "    model_ft, optimizer = amp.initialize(model_ft, optimizer, opt_level='O1')\n",
    "    \n",
    "lr_finder = LRFinder(model_ft, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(train_dataloader, end_lr=1e-2, num_iter=200, step_mode=\"exp\", accumulation_steps=CFG.accum_step)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: False\n",
      " seed: 1982\n",
      " img_height: 256\n",
      " img_width: 256\n",
      " target_size: 6\n",
      " img_id_col: image_id\n",
      " target_col: isup_grade\n",
      " tiff_layer: 1\n",
      " stoch_sample: True\n",
      " num_tiles: 32\n",
      " tile_sz: 256\n",
      " batch_size: 2\n",
      " accum_step: 2\n",
      " dataset: patch\n",
      " aug_type: heavy\n",
      " arch: bitM\n",
      " finetune: False\n",
      " model_cls: one_layer\n",
      " loss: ls_soft_ce\n",
      " optim: radam\n",
      " lr: 5e-05\n",
      " schedule_type: none\n",
      " cawr_T: 1\n",
      " cawr_Tmult: 2\n",
      " rlopp: 1\n",
      " epoch: 30\n",
      " n_fold: 4\n",
      " use_amp: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\\n\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Experiment Description:\", \"BitM, 256x32 heavy aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedulers\n",
    "def get_scheduler(optimizer,train_dataloader, schedule_type=CFG.schedule_type, resume=False):\n",
    "    assert schedule_type in SCHEDULERS, f\"{schedule_type} not in SCHEDULERS\"\n",
    "    if schedule_type == \"reduce_on_plateau\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, 'min', factor=0.5, patience=CFG.rlopp if not resume else CFG.rlopp + 2, verbose=True), \n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"one_cycle\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, max_lr=[CFG.lr, CFG.lr*10] if CFG.finetune == \"1stage\" else CFG.lr,\n",
    "                                             steps_per_epoch=len(train_dataloader), epochs=CFG.epoch, pct_start=0.05),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"cawr\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, T_0=len(train_dataloader)*CFG.cawr_T, T_mult=CFG.cawr_Tmult),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    else:\n",
    "        return (SCHEDULERS[schedule_type][0],\n",
    "                SCHEDULERS[schedule_type][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folds (all experiments validated on fold 0)\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "elif CFG.dataset == \"hdf5\":\n",
    "    train_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_1.h5\", \"patch256x16x1_fold_2.h5\", \"patch256x16x1_fold_3.h5\"])\n",
    "    val_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_0.h5\"])\n",
    "else:\n",
    "    print(f\"No such dataset {CFG.dataset}\")\n",
    "    \n",
    "# define a data loader\n",
    "if CFG.dataset == \"hdf5\":\n",
    "    # use specific sampler (so not to load hdf5 files to memory too frequently)\n",
    "    sampler = SeqenceRandomSampler(len(train_ds), train_ds._common_len)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "\n",
    "model_ft = PatchModel(arch=CFG.arch)\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3981 [00:01<53:47,  1.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3981 [00:01<36:57,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3981 [00:02<28:38,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/3981 [00:03<24:56,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3981 [00:03<22:43,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/3981 [00:04<21:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3981 [00:05<21:13,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/3981 [00:05<21:20,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/3981 [00:06<21:16,  3.11it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "  1%|          | 20/3981 [00:07<21:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/3981 [00:07<21:35,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/3981 [00:09<21:46,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 2142/3981 [11:34<09:53,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:24<00:00,  3.10it/s]\n",
      "100%|| 1327/1327 [04:07<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 19.1603\tValidation Loss: 7.1565\n",
      "Counter train preds: Counter({0: 2117, 1: 1941, 2: 1052, 4: 1016, 3: 924, 5: 912})\tCounter val preds: Counter({1: 1380, 2: 1170, 4: 88, 3: 16})\n",
      "Epoch train QWK: 0.189\tval QWK: 0.201\n",
      "  Epoch 0 - Save Best Loss: 7.1565 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.70401107 0.27524205 0.00829876 0.01244813 0.        ]\n",
      " [0.         0.6021021  0.38888889 0.0015015  0.00750751 0.        ]\n",
      " [0.         0.4238806  0.5641791  0.00597015 0.00597015 0.        ]\n",
      " [0.         0.32475884 0.62700965 0.00643087 0.04180064 0.        ]\n",
      " [0.         0.43769968 0.47284345 0.00638978 0.08306709 0.        ]\n",
      " [0.         0.29411765 0.58823529 0.00980392 0.10784314 0.        ]]\n",
      "  Epoch 0 - Save Best QWK: 0.2008 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.70401107 0.27524205 0.00829876 0.01244813 0.        ]\n",
      " [0.         0.6021021  0.38888889 0.0015015  0.00750751 0.        ]\n",
      " [0.         0.4238806  0.5641791  0.00597015 0.00597015 0.        ]\n",
      " [0.         0.32475884 0.62700965 0.00643087 0.04180064 0.        ]\n",
      " [0.         0.43769968 0.47284345 0.00638978 0.08306709 0.        ]\n",
      " [0.         0.29411765 0.58823529 0.00980392 0.10784314 0.        ]]\n",
      "Epoch 1/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1282/3981 [06:55<14:10,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:27<00:00,  3.09it/s]\n",
      "100%|| 1327/1327 [04:16<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.5010\tValidation Loss: 5.2417\n",
      "Counter train preds: Counter({0: 2169, 1: 1980, 2: 1080, 5: 926, 4: 910, 3: 897})\tCounter val preds: Counter({0: 2631, 5: 21, 2: 2})\n",
      "Epoch train QWK: 0.298\tval QWK: 0.029\n",
      "  Epoch 1 - Save Best Loss: 5.2417 Model\n",
      "Normalized confusion matrix\n",
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [0.97427653 0.         0.00321543 0.         0.         0.02250804]\n",
      " [0.99041534 0.         0.00319489 0.         0.         0.00638978]\n",
      " [0.96078431 0.         0.         0.         0.         0.03921569]]\n",
      "Epoch 2/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 1360/3981 [07:21<13:45,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 3372/3981 [18:15<03:14,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|| 1327/1327 [04:07<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.8300\tValidation Loss: 2.3861\n",
      "Counter train preds: Counter({0: 2281, 1: 2006, 2: 1111, 5: 878, 4: 846, 3: 840})\tCounter val preds: Counter({0: 2286, 3: 310, 5: 54, 2: 4})\n",
      "Epoch train QWK: 0.397\tval QWK: 0.277\n",
      "  Epoch 2 - Save Best Loss: 2.3861 Model\n",
      "Normalized confusion matrix\n",
      "[[0.99861687 0.         0.         0.00138313 0.         0.        ]\n",
      " [0.97597598 0.         0.003003   0.02102102 0.         0.        ]\n",
      " [0.87462687 0.         0.00597015 0.11940299 0.         0.        ]\n",
      " [0.72025723 0.         0.         0.26045016 0.         0.0192926 ]\n",
      " [0.74121406 0.         0.         0.22044728 0.         0.03833866]\n",
      " [0.53921569 0.         0.         0.34313725 0.         0.11764706]]\n",
      "  Epoch 2 - Save Best QWK: 0.2770 Model\n",
      "Normalized confusion matrix\n",
      "[[0.99861687 0.         0.         0.00138313 0.         0.        ]\n",
      " [0.97597598 0.         0.003003   0.02102102 0.         0.        ]\n",
      " [0.87462687 0.         0.00597015 0.11940299 0.         0.        ]\n",
      " [0.72025723 0.         0.         0.26045016 0.         0.0192926 ]\n",
      " [0.74121406 0.         0.         0.22044728 0.         0.03833866]\n",
      " [0.53921569 0.         0.         0.34313725 0.         0.11764706]]\n",
      "Epoch 3/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|| 1327/1327 [04:11<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2191\tValidation Loss: 1.7778\n",
      "Counter train preds: Counter({0: 2327, 1: 2049, 2: 1043, 5: 893, 3: 832, 4: 818})\tCounter val preds: Counter({1: 1224, 3: 980, 0: 369, 5: 79, 2: 2})\n",
      "Epoch train QWK: 0.507\tval QWK: 0.621\n",
      "  Epoch 3 - Save Best Loss: 1.7778 Model\n",
      "Normalized confusion matrix\n",
      "[[0.43706777 0.48409405 0.         0.07745505 0.         0.00138313]\n",
      " [0.04504505 0.78228228 0.         0.17267267 0.         0.        ]\n",
      " [0.01492537 0.52537313 0.00298507 0.45373134 0.         0.00298507]\n",
      " [0.02250804 0.23151125 0.         0.7266881  0.         0.0192926 ]\n",
      " [0.00958466 0.2428115  0.00319489 0.68690096 0.         0.05750799]\n",
      " [0.02614379 0.09477124 0.         0.70588235 0.         0.17320261]]\n",
      "  Epoch 3 - Save Best QWK: 0.6207 Model\n",
      "Normalized confusion matrix\n",
      "[[0.43706777 0.48409405 0.         0.07745505 0.         0.00138313]\n",
      " [0.04504505 0.78228228 0.         0.17267267 0.         0.        ]\n",
      " [0.01492537 0.52537313 0.00298507 0.45373134 0.         0.00298507]\n",
      " [0.02250804 0.23151125 0.         0.7266881  0.         0.0192926 ]\n",
      " [0.00958466 0.2428115  0.00319489 0.68690096 0.         0.05750799]\n",
      " [0.02614379 0.09477124 0.         0.70588235 0.         0.17320261]]\n",
      "Epoch 4/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 1538/3981 [08:14<12:57,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:20<00:00,  3.11it/s]\n",
      "100%|| 1327/1327 [04:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.8518\tValidation Loss: 1.8433\n",
      "Counter train preds: Counter({0: 2368, 1: 2052, 2: 1015, 5: 887, 4: 839, 3: 801})\tCounter val preds: Counter({1: 2047, 4: 603, 5: 2, 2: 1, 3: 1})\n",
      "Epoch train QWK: 0.580\tval QWK: 0.587\n",
      "Epoch 5/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|        | 718/3981 [03:50<17:17,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 3340/3981 [17:53<03:21,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:21<00:00,  3.11it/s]\n",
      "100%|| 1327/1327 [04:08<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5739\tValidation Loss: 1.2972\n",
      "Counter train preds: Counter({0: 2479, 1: 2085, 2: 933, 5: 910, 4: 823, 3: 732})\tCounter val preds: Counter({1: 1085, 0: 529, 2: 457, 4: 387, 5: 196})\n",
      "Epoch train QWK: 0.627\tval QWK: 0.722\n",
      "  Epoch 5 - Save Best Loss: 1.2972 Model\n",
      "Normalized confusion matrix\n",
      "[[0.60027663 0.38589212 0.00138313 0.         0.01106501 0.00138313]\n",
      " [0.04804805 0.77327327 0.16966967 0.         0.00900901 0.        ]\n",
      " [0.02686567 0.38507463 0.54328358 0.         0.04179104 0.00298507]\n",
      " [0.05466238 0.22508039 0.29903537 0.         0.31832797 0.10289389]\n",
      " [0.0543131  0.20766773 0.12779553 0.         0.50798722 0.10223642]\n",
      " [0.06535948 0.08823529 0.09150327 0.         0.33006536 0.4248366 ]]\n",
      "  Epoch 5 - Save Best QWK: 0.7224 Model\n",
      "Normalized confusion matrix\n",
      "[[0.60027663 0.38589212 0.00138313 0.         0.01106501 0.00138313]\n",
      " [0.04804805 0.77327327 0.16966967 0.         0.00900901 0.        ]\n",
      " [0.02686567 0.38507463 0.54328358 0.         0.04179104 0.00298507]\n",
      " [0.05466238 0.22508039 0.29903537 0.         0.31832797 0.10289389]\n",
      " [0.0543131  0.20766773 0.12779553 0.         0.50798722 0.10223642]\n",
      " [0.06535948 0.08823529 0.09150327 0.         0.33006536 0.4248366 ]]\n",
      "Epoch 6/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 2256/3981 [12:15<09:06,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:35<00:00,  3.07it/s]\n",
      "100%|| 1327/1327 [04:12<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4397\tValidation Loss: 1.3500\n",
      "Counter train preds: Counter({0: 2519, 1: 2075, 2: 947, 5: 869, 4: 816, 3: 736})\tCounter val preds: Counter({0: 1109, 2: 941, 4: 315, 5: 178, 1: 107, 3: 4})\n",
      "Epoch train QWK: 0.670\tval QWK: 0.675\n",
      "Epoch 7/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|        | 548/3981 [02:58<18:14,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:31<00:00,  3.08it/s]\n",
      "100%|| 1327/1327 [04:07<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3493\tValidation Loss: 1.2922\n",
      "Counter train preds: Counter({0: 2503, 1: 2176, 5: 874, 2: 869, 3: 771, 4: 769})\tCounter val preds: Counter({1: 990, 5: 824, 0: 777, 4: 45, 2: 18})\n",
      "Epoch train QWK: 0.689\tval QWK: 0.731\n",
      "  Epoch 7 - Save Best Loss: 1.2922 Model\n",
      "Normalized confusion matrix\n",
      "[[0.85892116 0.1175657  0.         0.         0.00138313 0.02213001]\n",
      " [0.09159159 0.87087087 0.0045045  0.         0.0015015  0.03153153]\n",
      " [0.03283582 0.63880597 0.03283582 0.         0.02686567 0.26865672]\n",
      " [0.08360129 0.19614148 0.0096463  0.         0.04180064 0.66881029]\n",
      " [0.09904153 0.13099042 0.         0.         0.05750799 0.71246006]\n",
      " [0.08823529 0.02941176 0.00326797 0.         0.00980392 0.86928105]]\n",
      "  Epoch 7 - Save Best QWK: 0.7313 Model\n",
      "Normalized confusion matrix\n",
      "[[0.85892116 0.1175657  0.         0.         0.00138313 0.02213001]\n",
      " [0.09159159 0.87087087 0.0045045  0.         0.0015015  0.03153153]\n",
      " [0.03283582 0.63880597 0.03283582 0.         0.02686567 0.26865672]\n",
      " [0.08360129 0.19614148 0.0096463  0.         0.04180064 0.66881029]\n",
      " [0.09904153 0.13099042 0.         0.         0.05750799 0.71246006]\n",
      " [0.08823529 0.02941176 0.00326797 0.         0.00980392 0.86928105]]\n",
      "Epoch 8/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 156/3981 [00:50<20:06,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:34<00:00,  3.07it/s] \n",
      "100%|| 1327/1327 [04:09<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2837\tValidation Loss: 1.3481\n",
      "Counter train preds: Counter({0: 2570, 1: 2151, 5: 906, 2: 845, 4: 778, 3: 712})\tCounter val preds: Counter({1: 1513, 3: 365, 0: 362, 4: 293, 2: 87, 5: 34})\n",
      "Epoch train QWK: 0.714\tval QWK: 0.680\n",
      "Epoch 9/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|         | 306/3981 [01:38<19:37,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 2134/3981 [11:32<10:09,  3.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:27<00:00,  3.09it/s]\n",
      "100%|| 1327/1327 [04:13<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2326\tValidation Loss: 1.3232\n",
      "Counter train preds: Counter({0: 2541, 1: 2245, 5: 892, 2: 820, 4: 751, 3: 713})\tCounter val preds: Counter({0: 962, 1: 810, 3: 471, 2: 233, 5: 178})\n",
      "Epoch train QWK: 0.736\tval QWK: 0.672\n",
      "Epoch 10/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|    | 2160/3981 [11:40<09:33,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:31<00:00,  3.08it/s]\n",
      "100%|| 1327/1327 [04:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2019\tValidation Loss: 1.2750\n",
      "Counter train preds: Counter({0: 2557, 1: 2232, 5: 903, 2: 795, 4: 767, 3: 708})\tCounter val preds: Counter({2: 886, 0: 753, 1: 670, 4: 208, 5: 137})\n",
      "Epoch train QWK: 0.741\tval QWK: 0.698\n",
      "  Epoch 10 - Save Best Loss: 1.2750 Model\n",
      "Normalized confusion matrix\n",
      "[[0.86860304 0.08713693 0.03319502 0.         0.00829876 0.00276625]\n",
      " [0.07807808 0.70720721 0.21021021 0.         0.0045045  0.        ]\n",
      " [0.02686567 0.28656716 0.68656716 0.         0.         0.        ]\n",
      " [0.06752412 0.06430868 0.74919614 0.         0.08360129 0.03536977]\n",
      " [0.06709265 0.04792332 0.45047923 0.         0.36741214 0.06709265]\n",
      " [0.07189542 0.01633987 0.38562092 0.         0.18954248 0.33660131]]\n",
      "Epoch 11/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 586/3981 [03:08<18:04,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 1964/3981 [10:33<10:41,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:25<00:00,  3.10it/s]\n",
      "100%|| 1327/1327 [04:18<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1942\tValidation Loss: 1.1692\n",
      "Counter train preds: Counter({0: 2558, 1: 2249, 5: 900, 2: 792, 4: 764, 3: 699})\tCounter val preds: Counter({0: 904, 1: 730, 5: 417, 3: 399, 2: 201, 4: 3})\n",
      "Epoch train QWK: 0.740\tval QWK: 0.766\n",
      "  Epoch 11 - Save Best Loss: 1.1692 Model\n",
      "Normalized confusion matrix\n",
      "[[0.92807746 0.05809129 0.00276625 0.00138313 0.         0.00968188]\n",
      " [0.14714715 0.74474474 0.08258258 0.02252252 0.         0.003003  ]\n",
      " [0.07761194 0.40597015 0.28656716 0.20597015 0.         0.0238806 ]\n",
      " [0.11254019 0.11254019 0.08038585 0.49517685 0.         0.19935691]\n",
      " [0.14057508 0.0543131  0.0543131  0.36421725 0.00638978 0.38019169]\n",
      " [0.09803922 0.0130719  0.01960784 0.1503268  0.00326797 0.71568627]]\n",
      "  Epoch 11 - Save Best QWK: 0.7657 Model\n",
      "Normalized confusion matrix\n",
      "[[0.92807746 0.05809129 0.00276625 0.00138313 0.         0.00968188]\n",
      " [0.14714715 0.74474474 0.08258258 0.02252252 0.         0.003003  ]\n",
      " [0.07761194 0.40597015 0.28656716 0.20597015 0.         0.0238806 ]\n",
      " [0.11254019 0.11254019 0.08038585 0.49517685 0.         0.19935691]\n",
      " [0.14057508 0.0543131  0.0543131  0.36421725 0.00638978 0.38019169]\n",
      " [0.09803922 0.0130719  0.01960784 0.1503268  0.00326797 0.71568627]]\n",
      "Epoch 12/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 512/3981 [02:45<18:27,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 948/3981 [05:05<16:23,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:30<00:00,  3.08it/s]\n",
      "100%|| 1327/1327 [04:15<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1954\tValidation Loss: 1.1722\n",
      "Counter train preds: Counter({0: 2554, 1: 2235, 5: 886, 4: 794, 2: 775, 3: 718})\tCounter val preds: Counter({1: 1001, 0: 611, 3: 359, 5: 336, 4: 179, 2: 168})\n",
      "Epoch train QWK: 0.749\tval QWK: 0.769\n",
      "  Epoch 12 - Save Best QWK: 0.7694 Model\n",
      "Normalized confusion matrix\n",
      "[[0.73582296 0.20055325 0.00138313 0.02489627 0.02351314 0.01383126]\n",
      " [0.04504505 0.88138138 0.02102102 0.04654655 0.00600601 0.        ]\n",
      " [0.01791045 0.54626866 0.21492537 0.18208955 0.0119403  0.02686567]\n",
      " [0.06109325 0.15755627 0.13504823 0.39549839 0.08038585 0.17041801]\n",
      " [0.02875399 0.09584665 0.08626198 0.26517572 0.28753994 0.23642173]\n",
      " [0.04901961 0.02287582 0.03921569 0.14052288 0.12745098 0.62091503]]\n",
      "Epoch 13/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 3464/3981 [18:42<02:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:29<00:00,  3.09it/s]\n",
      "100%|| 1327/1327 [04:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1819\tValidation Loss: 1.2266\n",
      "Counter train preds: Counter({0: 2564, 1: 2311, 5: 872, 2: 749, 4: 742, 3: 724})\tCounter val preds: Counter({1: 822, 0: 781, 2: 568, 4: 270, 3: 156, 5: 57})\n",
      "Epoch train QWK: 0.742\tval QWK: 0.705\n",
      "Epoch 14/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|    | 2072/3981 [11:11<10:05,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 2088/3981 [11:16<10:02,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:30<00:00,  3.08it/s]\n",
      "100%|| 1327/1327 [04:05<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1747\tValidation Loss: 1.1845\n",
      "Counter train preds: Counter({0: 2554, 1: 2227, 5: 931, 2: 797, 4: 761, 3: 692})\tCounter val preds: Counter({1: 983, 0: 729, 5: 414, 2: 382, 4: 75, 3: 71})\n",
      "Epoch train QWK: 0.753\tval QWK: 0.746\n",
      "Epoch 15/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|      | 1586/3981 [08:34<12:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:38<00:00,  3.07it/s]\n",
      "100%|| 1327/1327 [04:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1715\tValidation Loss: 1.1738\n",
      "Counter train preds: Counter({0: 2569, 1: 2255, 5: 921, 4: 748, 2: 741, 3: 728})\tCounter val preds: Counter({1: 896, 0: 778, 2: 409, 4: 244, 3: 167, 5: 160})\n",
      "Epoch train QWK: 0.753\tval QWK: 0.720\n",
      "Epoch 16/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|     | 1646/3981 [08:55<12:17,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 3110/3981 [16:53<04:35,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|| 1327/1327 [04:16<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1713\tValidation Loss: 1.3259\n",
      "Counter train preds: Counter({0: 2532, 1: 2309, 5: 872, 4: 793, 3: 739, 2: 717})\tCounter val preds: Counter({0: 1155, 5: 745, 2: 432, 1: 244, 4: 43, 3: 35})\n",
      "Epoch train QWK: 0.745\tval QWK: 0.733\n",
      "Epoch 17/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|| 3678/3981 [20:02<01:35,  3.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3968/3981 [21:37<00:04,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:41<00:00,  3.06it/s]\n",
      "100%|| 1327/1327 [04:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1735\tValidation Loss: 1.3451\n",
      "Counter train preds: Counter({0: 2558, 1: 2256, 5: 924, 3: 747, 4: 742, 2: 735})\tCounter val preds: Counter({5: 848, 0: 785, 1: 584, 4: 253, 2: 184})\n",
      "Epoch train QWK: 0.745\tval QWK: 0.717\n",
      "Epoch 18/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|   | 2674/3981 [14:20<06:50,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 3348/3981 [17:57<03:18,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 3354/3981 [17:59<03:17,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:22<00:00,  3.10it/s]\n",
      "100%|| 1327/1327 [04:10<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1787\tValidation Loss: 1.2389\n",
      "Counter train preds: Counter({0: 2541, 1: 2271, 5: 917, 4: 793, 2: 749, 3: 691})\tCounter val preds: Counter({1: 1210, 0: 467, 4: 412, 3: 314, 5: 156, 2: 95})\n",
      "Epoch train QWK: 0.744\tval QWK: 0.731\n",
      "Epoch 19/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 3981/3981 [21:36<00:00,  3.07it/s]\n",
      "100%|| 1327/1327 [04:09<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1880\tValidation Loss: 1.2366\n",
      "Counter train preds: Counter({0: 2530, 1: 2253, 5: 901, 4: 806, 2: 756, 3: 716})\tCounter val preds: Counter({1: 1158, 0: 756, 5: 347, 2: 287, 3: 54, 4: 52})\n",
      "Epoch train QWK: 0.747\tval QWK: 0.714\n",
      "Epoch 20/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|        | 560/3981 [03:03<18:12,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 2812/3981 [15:13<06:05,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 3166/3981 [17:08<04:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 3174/3981 [17:10<04:14,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3981/3981 [21:34<00:00,  3.08it/s]\n",
      "100%|| 1327/1327 [04:11<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2031\tValidation Loss: 1.4486\n",
      "Counter train preds: Counter({0: 2572, 1: 2256, 5: 920, 2: 770, 4: 757, 3: 687})\tCounter val preds: Counter({1: 1220, 2: 558, 0: 462, 4: 339, 3: 64, 5: 11})\n",
      "Epoch train QWK: 0.741\tval QWK: 0.675\n",
      "Epoch 21/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|       | 1002/3981 [05:59<16:59,  2.92it/s]"
     ]
    }
   ],
   "source": [
    "# Start Train/Eval Experiment\n",
    "model_ft, best_loss, best_qwk = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, model_name=EXP_NAME)\n",
    "\n",
    "# After finish collect hyperparams used, best metrics and write to TensorBoard\n",
    "hparam_dict = {key:val for key, val in CFG.__dict__.items() if not key.startswith(\"__\")}\n",
    "metric_dict = {\"hp/best_loss\": best_loss, \"hp/best_qwk\": best_qwk}\n",
    "writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folds (all experiments validated on fold 0)\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "elif CFG.dataset == \"hdf5\":\n",
    "    train_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_1.h5\", \"patch256x16x1_fold_2.h5\", \"patch256x16x1_fold_3.h5\"])\n",
    "    val_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_0.h5\"])\n",
    "else:\n",
    "    print(f\"No such dataset {CFG.dataset}\")\n",
    "    \n",
    "# define a data loader\n",
    "if CFG.dataset == \"hdf5\":\n",
    "    # use specific sampler (so not to load hdf5 files to memory too frequently)\n",
    "    sampler = SeqenceRandomSampler(len(train_ds), train_ds._common_len)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(f'{MODEL_PATH}/{PREV_NAME}_loss.pth')\n",
    "\n",
    "model_ft = PatchModel(arch=CFG.arch)\n",
    "model_ft.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_ft.to(device)\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ])\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# set smaller lr here\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] /= 2\n",
    "\n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-06\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 18/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1991 [00:02<47:59,  1.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1991 [00:02<36:39,  1.11s/it]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "  1%|          | 20/1991 [00:08<10:34,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [11:42<00:00,  2.83it/s]\n",
      "100%|| 664/664 [02:48<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7912\tValidation Loss: 1.0411\n",
      "Counter train preds: Counter({0: 2369, 1: 2107, 2: 919, 5: 874, 4: 857, 3: 836})\tCounter val preds: Counter({1: 801, 0: 785, 5: 329, 4: 296, 2: 236, 3: 207})\n",
      "Epoch train QWK: 0.899\tval QWK: 0.824\n",
      "Epoch 19/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|         | 30/1991 [00:11<10:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 1158/1991 [06:40<04:27,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [11:44<00:00,  2.83it/s]\n",
      "100%|| 664/664 [02:52<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7860\tValidation Loss: 1.0326\n",
      "Counter train preds: Counter({0: 2348, 1: 2076, 2: 946, 5: 895, 4: 865, 3: 832})\tCounter val preds: Counter({0: 810, 1: 757, 2: 311, 4: 276, 5: 261, 3: 239})\n",
      "Epoch train QWK: 0.902\tval QWK: 0.823\n",
      "Epoch 20/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|   | 1286/1991 [07:04<03:43,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:55<00:00,  3.04it/s]\n",
      "100%|| 664/664 [02:49<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7739\tValidation Loss: 1.0376\n",
      "Counter train preds: Counter({0: 2346, 1: 2086, 2: 957, 5: 891, 4: 852, 3: 830})\tCounter val preds: Counter({0: 789, 1: 754, 4: 336, 5: 296, 3: 240, 2: 239})\n",
      "Epoch train QWK: 0.908\tval QWK: 0.832\n",
      "  Epoch 20 - Save Best QWK: 0.8318 Model\n",
      "Normalized confusion matrix\n",
      "[[0.9142462  0.07053942 0.00276625 0.00138313 0.00276625 0.00829876]\n",
      " [0.07507508 0.83333333 0.06306306 0.01651652 0.00900901 0.003003  ]\n",
      " [0.03283582 0.32238806 0.42686567 0.13134328 0.06268657 0.0238806 ]\n",
      " [0.09324759 0.05787781 0.11254019 0.45337621 0.17363344 0.10932476]\n",
      " [0.06389776 0.04792332 0.04792332 0.07348243 0.62939297 0.13738019]\n",
      " [0.05882353 0.02287582 0.00653595 0.06535948 0.18300654 0.66339869]]\n",
      "Epoch 21/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1560/1991 [08:07<02:12,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:21<00:00,  3.20it/s]\n",
      "100%|| 664/664 [02:46<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7603\tValidation Loss: 1.0409\n",
      "Counter train preds: Counter({0: 2350, 1: 2056, 2: 916, 4: 881, 3: 881, 5: 878})\tCounter val preds: Counter({1: 823, 0: 772, 4: 322, 5: 297, 2: 238, 3: 202})\n",
      "Epoch train QWK: 0.913\tval QWK: 0.827\n",
      "Epoch 22/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 1991/1991 [11:03<00:00,  3.00it/s]\n",
      "100%|| 664/664 [02:51<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7578\tValidation Loss: 1.0242\n",
      "Counter train preds: Counter({0: 2364, 1: 2060, 2: 930, 5: 881, 3: 875, 4: 852})\tCounter val preds: Counter({0: 806, 1: 774, 3: 282, 2: 271, 4: 265, 5: 256})\n",
      "Epoch train QWK: 0.905\tval QWK: 0.819\n",
      "  Epoch 22 - Save Best Loss: 1.0242 Model\n",
      "Normalized confusion matrix\n",
      "[[0.91839557 0.06777317 0.00276625 0.00276625 0.00276625 0.0055325 ]\n",
      " [0.08258258 0.84234234 0.05555556 0.01201201 0.003003   0.0045045 ]\n",
      " [0.03283582 0.34925373 0.48358209 0.10447761 0.01791045 0.0119403 ]\n",
      " [0.09967846 0.06430868 0.14790997 0.49839228 0.10289389 0.08681672]\n",
      " [0.08306709 0.06070288 0.0543131  0.15974441 0.5399361  0.10223642]\n",
      " [0.0620915  0.02614379 0.02287582 0.10457516 0.17647059 0.60784314]]\n",
      "Epoch 23/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 532/1991 [02:55<07:40,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:51<00:00,  3.06it/s]\n",
      "100%|| 664/664 [02:51<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7567\tValidation Loss: 1.0275\n",
      "Counter train preds: Counter({0: 2333, 1: 2082, 2: 934, 5: 883, 3: 871, 4: 859})\tCounter val preds: Counter({0: 810, 1: 695, 2: 351, 5: 290, 4: 287, 3: 221})\n",
      "Epoch train QWK: 0.910\tval QWK: 0.825\n",
      "Epoch 24/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 1991/1991 [11:17<00:00,  2.94it/s]\n",
      "100%|| 664/664 [02:50<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7417\tValidation Loss: 1.0299\n",
      "Counter train preds: Counter({0: 2346, 1: 2052, 2: 938, 5: 900, 3: 869, 4: 857})\tCounter val preds: Counter({0: 802, 1: 775, 5: 302, 3: 301, 4: 272, 2: 202})\n",
      "Epoch train QWK: 0.918\tval QWK: 0.829\n",
      "Epoch 25/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|       | 552/1991 [02:54<07:19,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 1424/1991 [07:37<02:50,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:35<00:00,  3.13it/s]\n",
      "100%|| 664/664 [02:47<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7373\tValidation Loss: 1.0288\n",
      "Counter train preds: Counter({0: 2352, 1: 2050, 2: 920, 5: 899, 3: 876, 4: 865})\tCounter val preds: Counter({0: 794, 1: 760, 5: 304, 3: 277, 2: 275, 4: 244})\n",
      "Epoch train QWK: 0.914\tval QWK: 0.827\n",
      "Epoch 26/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|  | 1488/1991 [07:48<02:34,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:30<00:00,  3.16it/s]\n",
      "100%|| 664/664 [02:53<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7313\tValidation Loss: 1.0301\n",
      "Counter train preds: Counter({0: 2340, 1: 2038, 2: 941, 5: 896, 3: 889, 4: 858})\tCounter val preds: Counter({0: 795, 1: 761, 4: 295, 5: 290, 3: 276, 2: 237})\n",
      "Epoch train QWK: 0.919\tval QWK: 0.828\n",
      "Epoch 27/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%| | 1630/1991 [09:15<01:51,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [11:12<00:00,  2.96it/s]\n",
      "100%|| 664/664 [02:48<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7174\tValidation Loss: 1.0293\n",
      "Counter train preds: Counter({0: 2331, 1: 2038, 2: 968, 5: 887, 4: 876, 3: 862})\tCounter val preds: Counter({0: 806, 1: 744, 4: 304, 5: 297, 2: 271, 3: 232})\n",
      "Epoch train QWK: 0.928\tval QWK: 0.830\n",
      "Epoch 28/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|| 1854/1991 [10:05<00:44,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [10:49<00:00,  3.07it/s]\n",
      "100%|| 664/664 [02:45<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7082\tValidation Loss: 1.0334\n",
      "Counter train preds: Counter({0: 2310, 1: 2049, 2: 958, 5: 900, 4: 888, 3: 857})\tCounter val preds: Counter({0: 777, 1: 752, 4: 342, 2: 287, 3: 255, 5: 241})\n",
      "Epoch train QWK: 0.927\tval QWK: 0.836\n",
      "  Epoch 28 - Save Best QWK: 0.8358 Model\n",
      "Normalized confusion matrix\n",
      "[[0.90871369 0.07192254 0.00414938 0.00414938 0.0055325  0.0055325 ]\n",
      " [0.07657658 0.82432432 0.07207207 0.01951952 0.0045045  0.003003  ]\n",
      " [0.02686567 0.33432836 0.48955224 0.09850746 0.03880597 0.0119403 ]\n",
      " [0.08038585 0.06109325 0.15434084 0.45016077 0.17684887 0.07717042]\n",
      " [0.06070288 0.04472843 0.06070288 0.12140575 0.62619808 0.08626198]\n",
      " [0.05228758 0.01960784 0.01633987 0.09150327 0.23202614 0.58823529]]\n",
      "Epoch 29/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1991/1991 [11:31<00:00,  2.88it/s]\n",
      "100%|| 664/664 [02:57<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6978\tValidation Loss: 1.0287\n",
      "Counter train preds: Counter({0: 2313, 1: 2049, 2: 946, 5: 895, 4: 891, 3: 868})\tCounter val preds: Counter({0: 819, 1: 726, 5: 297, 2: 274, 3: 270, 4: 268})\n",
      "Epoch train QWK: 0.932\tval QWK: 0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Train/Eval Experiment\n",
    "model_ft, best_loss, best_qwk = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, checkpoint=checkpoint, model_name=PREV_NAME)\n",
    "\n",
    "# After finish collect hyperparams used, best metrics and write to TensorBoard\n",
    "hparam_dict = {key:val for key, val in CFG.__dict__.items() if not key.startswith(\"__\")}\n",
    "metric_dict = {\"hp/best_loss\": best_loss, \"hp/best_qwk\": best_qwk}\n",
    "writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with CV, on fold 0\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7832\tValidation Loss: 1.6735\n",
      "Counter train preds: Counter({1: 50, 4: 11, 3: 8, 0: 6})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.193\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5393\tValidation Loss: 1.6932\n",
      "Counter train preds: Counter({1: 39, 0: 21, 3: 7, 4: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.236\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4436\tValidation Loss: 1.7056\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 7, 5: 5, 4: 3})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.321\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.88it/s]\n",
      "100%|| 2/2 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4152\tValidation Loss: 1.6723\n",
      "Counter train preds: Counter({0: 33, 1: 31, 3: 5, 4: 5, 5: 1})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.282\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3904\tValidation Loss: 1.6386\n",
      "Counter train preds: Counter({1: 33, 0: 28, 4: 6, 3: 5, 5: 3})\tCounter val preds: Counter({1: 15, 5: 3, 0: 3, 2: 2, 4: 1, 3: 1})\n",
      "Epoch train QWK: 0.393\tval QWK: 0.186\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.49it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3730\tValidation Loss: 1.6927\n",
      "Counter train preds: Counter({0: 33, 1: 26, 5: 7, 3: 4, 4: 4, 2: 1})\tCounter val preds: Counter({1: 13, 5: 6, 2: 4, 3: 1, 0: 1})\n",
      "Epoch train QWK: 0.517\tval QWK: 0.545\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3238\tValidation Loss: 1.8837\n",
      "Counter train preds: Counter({0: 30, 1: 29, 5: 6, 3: 6, 4: 4})\tCounter val preds: Counter({1: 9, 5: 7, 2: 6, 3: 3})\n",
      "Epoch train QWK: 0.438\tval QWK: 0.329\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3055\tValidation Loss: 2.0990\n",
      "Counter train preds: Counter({1: 34, 0: 22, 5: 8, 3: 7, 4: 2, 2: 2})\tCounter val preds: Counter({2: 12, 5: 5, 3: 5, 1: 2, 4: 1})\n",
      "Epoch train QWK: 0.552\tval QWK: 0.326\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.53it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3063\tValidation Loss: 2.0883\n",
      "Counter train preds: Counter({1: 35, 0: 25, 4: 7, 3: 5, 5: 3})\tCounter val preds: Counter({2: 13, 5: 5, 1: 3, 3: 2, 4: 1, 0: 1})\n",
      "Epoch train QWK: 0.549\tval QWK: 0.199\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.73it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.8377\n",
      "Counter train preds: Counter({1: 37, 0: 24, 5: 7, 4: 3, 3: 3, 2: 1})\tCounter val preds: Counter({1: 21, 3: 2, 2: 1, 5: 1})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.305\n",
      "Train with CV, on fold 1\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.69it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7209\tValidation Loss: 1.7380\n",
      "Counter train preds: Counter({0: 59, 3: 15, 1: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.263\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5459\tValidation Loss: 1.7958\n",
      "Counter train preds: Counter({0: 36, 1: 32, 3: 5, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.331\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.36it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4606\tValidation Loss: 1.9763\n",
      "Counter train preds: Counter({1: 34, 0: 29, 4: 8, 3: 4})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4206\tValidation Loss: 1.8872\n",
      "Counter train preds: Counter({1: 32, 0: 24, 4: 8, 3: 6, 5: 3, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.441\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  8.24it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4067\tValidation Loss: 2.2129\n",
      "Counter train preds: Counter({1: 36, 0: 25, 3: 10, 5: 2, 2: 1, 4: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3640\tValidation Loss: 2.9000\n",
      "Counter train preds: Counter({1: 33, 0: 24, 3: 12, 2: 4, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.364\tval QWK: 0.000\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.86it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3085\tValidation Loss: 2.7819\n",
      "Counter train preds: Counter({1: 33, 0: 20, 3: 11, 2: 4, 4: 4, 5: 3})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.568\tval QWK: 0.000\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3142\tValidation Loss: 2.3783\n",
      "Counter train preds: Counter({1: 36, 0: 21, 3: 9, 2: 5, 5: 3, 4: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.116\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  8.07it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2917\tValidation Loss: 3.1009\n",
      "Counter train preds: Counter({1: 38, 0: 19, 2: 6, 4: 5, 3: 4, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.433\tval QWK: 0.009\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2545\tValidation Loss: 2.9466\n",
      "Counter train preds: Counter({1: 32, 0: 20, 3: 10, 4: 5, 2: 5, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.635\tval QWK: 0.009\n",
      "Train with CV, on fold 2\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6856\tValidation Loss: 1.8174\n",
      "Counter train preds: Counter({1: 48, 3: 15, 0: 12})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.208\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.56it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5455\tValidation Loss: 2.4182\n",
      "Counter train preds: Counter({1: 37, 0: 21, 3: 16, 2: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.313\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4741\tValidation Loss: 2.2700\n",
      "Counter train preds: Counter({1: 33, 0: 26, 3: 14, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.287\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4289\tValidation Loss: 2.4097\n",
      "Counter train preds: Counter({1: 35, 0: 28, 3: 7, 2: 5})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.247\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3615\tValidation Loss: 2.0392\n",
      "Counter train preds: Counter({1: 39, 0: 25, 3: 7, 2: 4})\tCounter val preds: Counter({0: 24, 2: 1})\n",
      "Epoch train QWK: 0.307\tval QWK: 0.064\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4250\tValidation Loss: 1.6867\n",
      "Counter train preds: Counter({1: 41, 0: 26, 3: 8})\tCounter val preds: Counter({0: 20, 2: 3, 1: 2})\n",
      "Epoch train QWK: 0.266\tval QWK: 0.214\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3328\tValidation Loss: 1.7360\n",
      "Counter train preds: Counter({1: 34, 0: 24, 3: 12, 2: 4, 5: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.365\tval QWK: 0.130\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.17it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3236\tValidation Loss: 1.8248\n",
      "Counter train preds: Counter({1: 33, 0: 21, 2: 13, 3: 6, 5: 2})\tCounter val preds: Counter({0: 17, 1: 5, 2: 3})\n",
      "Epoch train QWK: 0.316\tval QWK: 0.272\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2498\tValidation Loss: 2.4719\n",
      "Counter train preds: Counter({1: 34, 0: 24, 2: 8, 3: 8, 5: 1})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.392\tval QWK: 0.259\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2657\tValidation Loss: 2.4212\n",
      "Counter train preds: Counter({1: 39, 0: 21, 2: 6, 3: 6, 5: 3})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.409\tval QWK: 0.259\n",
      "Train with CV, on fold 3\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.78it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7337\tValidation Loss: 1.6500\n",
      "Counter train preds: Counter({1: 49, 2: 14, 0: 6, 5: 3, 3: 3})\tCounter val preds: Counter({1: 24, 0: 1})\n",
      "Epoch train QWK: 0.123\tval QWK: -0.030\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5647\tValidation Loss: 1.7000\n",
      "Counter train preds: Counter({1: 40, 0: 18, 3: 12, 2: 5})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.232\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.87it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4733\tValidation Loss: 1.6935\n",
      "Counter train preds: Counter({1: 33, 0: 27, 3: 13, 2: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.337\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.66it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4141\tValidation Loss: 1.6876\n",
      "Counter train preds: Counter({0: 29, 1: 28, 3: 10, 2: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.475\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.39it/s]\n",
      "100%|| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3655\tValidation Loss: 1.6186\n",
      "Counter train preds: Counter({1: 35, 0: 26, 3: 7, 5: 4, 2: 3})\tCounter val preds: Counter({1: 21, 2: 3, 0: 1})\n",
      "Epoch train QWK: 0.395\tval QWK: 0.012\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.47it/s]\n",
      "100%|| 2/2 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3591\tValidation Loss: 1.6763\n",
      "Counter train preds: Counter({1: 32, 0: 23, 3: 11, 2: 8, 5: 1})\tCounter val preds: Counter({2: 17, 0: 6, 1: 2})\n",
      "Epoch train QWK: 0.413\tval QWK: 0.313\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.40it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.6529\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 5, 2: 4, 4: 4, 5: 2})\tCounter val preds: Counter({1: 12, 2: 9, 5: 2, 0: 2})\n",
      "Epoch train QWK: 0.424\tval QWK: 0.269\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 2/2 [00:00<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3050\tValidation Loss: 1.7019\n",
      "Counter train preds: Counter({1: 36, 0: 21, 2: 6, 3: 5, 5: 4, 4: 3})\tCounter val preds: Counter({2: 13, 5: 7, 4: 3, 0: 2})\n",
      "Epoch train QWK: 0.454\tval QWK: 0.364\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.99it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2645\tValidation Loss: 1.7029\n",
      "Counter train preds: Counter({1: 36, 0: 22, 5: 7, 2: 5, 3: 4, 4: 1})\tCounter val preds: Counter({2: 10, 5: 5, 0: 5, 1: 4, 3: 1})\n",
      "Epoch train QWK: 0.461\tval QWK: 0.309\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 5/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|| 2/2 [00:00<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2169\tValidation Loss: 2.0975\n",
      "Counter train preds: Counter({1: 33, 0: 22, 2: 9, 3: 6, 5: 5})\tCounter val preds: Counter({4: 14, 5: 8, 0: 3})\n",
      "Epoch train QWK: 0.530\tval QWK: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"test_fold_{}.pth\"\n",
    "for fold in range(CFG.n_fold):\n",
    "    train_df = folds[folds[\"fold\"] != fold].copy()\n",
    "    val_df = folds[folds[\"fold\"] == fold].copy()\n",
    "    \n",
    "    train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "    val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "    \n",
    "    model = TinyV2ConvNet(CFG.target_size)\n",
    "    # initialize bias in the model\n",
    "    cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "    model = init_last_layer_bias(model, cls_probas)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    print(f\"Train with CV, on fold {fold}\")\n",
    "    model = train_eval_loop(train_ds, val_ds, model, optimizer, criterion, tb_tag=fold)\n",
    "    torch.save(model.state_dict(), MODEL_PATH/checkpoint.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestxray",
   "language": "python",
   "name": "chestxray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
