{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter, OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingWarmRestarts\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from apex import amp\n",
    "\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "from albumentations import Compose, Normalize\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2\n",
    "import skimage.io\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "from chestxray.config import (PANDA_PATH,\n",
    "                              MODEL_PATH,\n",
    "                              PANDA_IMGS,\n",
    "                              PANDA_MASKS,\n",
    "                              TRAIN_CSV)\n",
    "# Competition related config\n",
    "from chestxray.config import CFG\n",
    "\n",
    "# Misc\n",
    "from chestxray.misc import seed_torch\n",
    "\n",
    "# Datasets\n",
    "from chestxray.datasets import get_transforms, TrainDataset, TilesTrainDataset, LazyTilesDataset, PatchTrainDataset, H5PatchDataset, SeqenceRandomSampler\n",
    "\n",
    "# Viz\n",
    "from chestxray.visualize import (show_from_ids, show_batch, imshow, \n",
    "                                 plot_classes_preds, reverse_show_img, \n",
    "                                 plot_confusion_matrix, text_classes_preds)\n",
    "\n",
    "# Nets\n",
    "from chestxray.nets import TinyV2ConvNet, freeze_botom, PatchModel\n",
    "from chestxray.model_utils import (trainable_params, cce_loss_at_init, \n",
    "                                   init_last_layer_bias)\n",
    "# Losses\n",
    "from chestxray.losses import LabelSmoothSoftmaxCEV1\n",
    "\n",
    "# Optim\n",
    "from chestxray.optimizers import RAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='GeForce RTX 2070 SUPER', major=7, minor=5, total_memory=7979MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_properties(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0\n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0\n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4\n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4\n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF = pd.read_csv(TRAIN_CSV)\n",
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 381
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = TRAIN_DF[CFG.target_col].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment: 05-06-2020-18-14\n"
     ]
    }
   ],
   "source": [
    "if not CFG.resume:\n",
    "    now = datetime.now()\n",
    "    EXP_NAME = now.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "    print(f\"Start experiment: {EXP_NAME}\")\n",
    "\n",
    "    writer = SummaryWriter(f\"runs_v1/{EXP_NAME}\")\n",
    "else:\n",
    "    # if resume should define from what to start\n",
    "    PREV_NAME = CFG.prev_exp\n",
    "    writer = SummaryWriter(f\"runs_v1/{PREV_NAME}_{CFG.stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = {\n",
    "    \"cce\" : nn.CrossEntropyLoss(),\n",
    "    \"ls_soft_ce\" : LabelSmoothSoftmaxCEV1(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key - string, value - tuple(sceduler, if it epoch type)\n",
    "epoch_type = True\n",
    "SCHEDULERS = {\n",
    "    \"reduce_on_plateau\" : (ReduceLROnPlateau, epoch_type),\n",
    "    \"one_cycle\": (OneCycleLR, not epoch_type),\n",
    "    \"cawr\": (CosineAnnealingWarmRestarts, not epoch_type),\n",
    "    \"none\": (None, None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Eval Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Eval Loop\n",
    "def train_eval_loop(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler,\n",
    "    sch_is_epoch_type,\n",
    "    accum_step=CFG.accum_step,\n",
    "    checkpoint=False,\n",
    "    num_epochs=CFG.epoch,\n",
    "    device=device,\n",
    "    tb_tag=\"\",\n",
    "    model_name=\"debug\",\n",
    "):\n",
    "    \"\"\"Split it into the set of inner functions to siplify the loop itself\"\"\"\n",
    "    # Inner Functions\n",
    "    # write to TensorBoard helpers\n",
    "    def weights_to_tb(step=0):\n",
    "        conv1_weight = list(model.parameters())[0].data.to(\"cpu\")\n",
    "        img_grid = torchvision.utils.make_grid(conv1_weight.float(), normalize=True)\n",
    "        writer.add_image(\n",
    "            tag=f\"Model conv1 weights {tb_tag}\", img_tensor=img_grid, global_step=step\n",
    "        )\n",
    "\n",
    "    def input_img_to_tb(inputs, step):\n",
    "        img = reverse_show_img(inputs[0], denorm=True)\n",
    "        writer.add_image(\n",
    "            tag=f\"Input Image {tb_tag}\",\n",
    "            img_tensor=img,\n",
    "            global_step=step,\n",
    "            dataformats=\"HWC\",\n",
    "        )\n",
    "        del img\n",
    "\n",
    "    def preds_to_tb(outputs, inputs, labels, step):\n",
    "        figure = plot_classes_preds(\n",
    "            outputs.to(\"cpu\"), inputs.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        )\n",
    "        writer.add_figure(\n",
    "            tag=f\"Actuals vs Predictions {tb_tag}\", figure=figure, global_step=step\n",
    "        )\n",
    "\n",
    "    def text_preds_to_tb(outputs, labels, step):\n",
    "        preds_text = text_classes_preds(outputs.to(\"cpu\"), labels.to(\"cpu\"))\n",
    "        writer.add_text(\n",
    "            f\"Actuals vs Predictions {tb_tag}\", preds_text, global_step=step\n",
    "        )\n",
    "\n",
    "    def metrics_to_tb(mode, train_loss, train_score, val_loss, val_score, step):\n",
    "        writer.add_text(\n",
    "            f\"On best {mode} save:\",\n",
    "            f\"tr_loss: {train_loss:.4f}, tr_qwk: {train_score:.4f}, val_loss: {val_loss:.4f}, val_qwk: {val_score:.4f}\",  # noqa\n",
    "            global_step=step,\n",
    "        )\n",
    "\n",
    "    def conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, step):\n",
    "        writer.add_figure(\n",
    "            tag=f\"Confusion matrix {tb_tag}\",\n",
    "            figure=plot_confusion_matrix(\n",
    "                val_epoch_labels, val_epoch_preds, normalize=True\n",
    "            ),\n",
    "            global_step=step,\n",
    "        )\n",
    "\n",
    "    # Train/Eval Loop\n",
    "    # write first layer weights to TB @ init phase\n",
    "    if not CFG.debug:\n",
    "        weights_to_tb()\n",
    "\n",
    "    # prepare model and optimizer\n",
    "    model.to(device)\n",
    "    if CFG.use_amp:  # automatic mixed precision\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O2\")\n",
    "    # define epochs numbers to look into input images and predictions,\n",
    "    # no more than 10 times per full training\n",
    "    vis_step = np.ceil(num_epochs / 10).astype(int)\n",
    "    visual_epochs = list(range(0, num_epochs, vis_step))\n",
    "    # metrics to wathch for model checkpointing\n",
    "    best_qwk = -100 if not checkpoint else checkpoint[\"best_qwk\"]\n",
    "    best_val_loss = np.inf if not checkpoint else checkpoint[\"best_val_loss\"]\n",
    "\n",
    "    start_epoch = 0 if not checkpoint else checkpoint[\"epoch\"] + 1\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"=\" * 10)\n",
    "\n",
    "        # Training Phase\n",
    "        # Set training mode\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_epoch_preds, train_epoch_labels = [], []\n",
    "\n",
    "        # We accumulate, zero at training epoch begins\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Iterate over train data.\n",
    "        tk_train = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for i, data in tk_train:\n",
    "            # Calculate global step for TensorBoard\n",
    "            train_global_step = epoch * len(train_dataloader) + i\n",
    "\n",
    "            inputs, labels = data\n",
    "            # Visualize input before model at the middle of epoch:\n",
    "            if epoch in visual_epochs and i == len(train_dataloader) // 2:\n",
    "                input_img_to_tb(inputs, train_global_step)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if CFG.use_amp:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            # we accumulate gradients and make optimization step once per\n",
    "            # # of accum_step\n",
    "            if (i + 1) % accum_step == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # loss is mean across batch, divide by number of steps in epoch\n",
    "            # (so loss is normalized)\n",
    "            train_running_loss += loss.item() / len(train_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(\n",
    "                tag=f\"Training loss {tb_tag}\",\n",
    "                scalar_value=loss.item(),\n",
    "                global_step=train_global_step,\n",
    "            )\n",
    "\n",
    "            # collect train preds and labels for QWK\n",
    "            train_epoch_preds.append(outputs.data.to(\"cpu\").numpy().argmax(1))\n",
    "            train_epoch_labels.append(labels.to(\"cpu\").numpy())\n",
    "            # Add Batch Type Scheduler step here:\n",
    "            if scheduler and not sch_is_epoch_type:\n",
    "                scheduler.step()\n",
    "        # Validation Phase\n",
    "        # Set evaluation mode\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_epoch_preds, val_epoch_labels = [], []\n",
    "        # Iterate over val data\n",
    "        tk_val = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "        for j, data in tk_val:\n",
    "            # Calculate global step\n",
    "            val_global_step = epoch * len(val_dataloader) + j\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item() / len(val_dataloader)\n",
    "            # tensorboarding loss\n",
    "            writer.add_scalar(\n",
    "                tag=f\"Validation loss {tb_tag}\",\n",
    "                scalar_value=loss.item(),\n",
    "                global_step=val_global_step,\n",
    "            )\n",
    "\n",
    "            # collect validation preds and labels for QWK\n",
    "            val_epoch_preds.append(outputs.data.to(\"cpu\").numpy().argmax(1))\n",
    "            val_epoch_labels.append(labels.to(\"cpu\").numpy())\n",
    "\n",
    "            # visualise predictions for 0th validation batch\n",
    "            if epoch in visual_epochs and j == 0:\n",
    "                text_preds_to_tb(outputs, labels, val_global_step)\n",
    "\n",
    "        # Epoch type Schedulers\n",
    "        if scheduler and sch_is_epoch_type:\n",
    "            scheduler.step(val_running_loss)\n",
    "        # Write lr to TBD\n",
    "        if CFG.finetune == \"1stage\":\n",
    "            writer.add_scalar(\n",
    "                tag=f\"lr Interim {tb_tag}:\",\n",
    "                scalar_value=optimizer.param_groups[0][\"lr\"],\n",
    "                global_step=train_global_step,\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                tag=f\"lr Classifier {tb_tag}:\",\n",
    "                scalar_value=optimizer.param_groups[1][\"lr\"],\n",
    "                global_step=train_global_step,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            writer.add_scalar(\n",
    "                tag=f\"lr {tb_tag}:\",\n",
    "                scalar_value=optimizer.param_groups[0][\"lr\"],\n",
    "                global_step=train_global_step,\n",
    "            )\n",
    "\n",
    "        # \"End of Epoch\" Phase\n",
    "        print(\n",
    "            f\"Training Loss: {train_running_loss:.4f}\\tValidation Loss: {val_running_loss:.4f}\"  # noqa\n",
    "        )\n",
    "\n",
    "        # Calculate epoch predictions distribution\n",
    "        train_epoch_preds = np.concatenate(train_epoch_preds)\n",
    "        train_epoch_labels = np.concatenate(train_epoch_labels)\n",
    "        val_epoch_preds = np.concatenate(val_epoch_preds)\n",
    "        val_epoch_labels = np.concatenate(val_epoch_labels)\n",
    "        print(\n",
    "            f\"Counter train preds: {Counter(train_epoch_preds)}\\tCounter val preds: {Counter(val_epoch_preds)}\"  # noqa\n",
    "        )\n",
    "        # Calculate epoch QWK\n",
    "        train_qwk = cohen_kappa_score(\n",
    "            train_epoch_preds, train_epoch_labels, weights=\"quadratic\"\n",
    "        )\n",
    "        val_qwk = cohen_kappa_score(\n",
    "            val_epoch_preds, val_epoch_labels, weights=\"quadratic\"\n",
    "        )\n",
    "        print(f\"Epoch train QWK: {train_qwk:.3f}\\tval QWK: {val_qwk:.3f}\")\n",
    "        writer.add_scalar(\n",
    "            tag=f\"Training QWK {tb_tag}\", scalar_value=train_qwk, global_step=epoch\n",
    "        )\n",
    "        writer.add_scalar(\n",
    "            tag=f\"Validation QWK {tb_tag}\", scalar_value=val_qwk, global_step=epoch\n",
    "        )\n",
    "\n",
    "        # On the best val loss do:\n",
    "        if val_running_loss < best_val_loss:\n",
    "            # update best and save model\n",
    "            best_val_loss = val_running_loss\n",
    "            best_qwk = val_qwk\n",
    "            print(f\"  Epoch {epoch} - Save Best Loss: {best_val_loss:.4f} Model\")\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"best_val_loss\": best_val_loss,\n",
    "                    \"best_qwk\": best_qwk,\n",
    "                },\n",
    "                f\"{MODEL_PATH}/{model_name}_{epoch}_loss.pth\",\n",
    "            )\n",
    "            # add losses as text to TB\n",
    "            metrics_to_tb(\n",
    "                \"loss\",\n",
    "                train_running_loss,\n",
    "                train_qwk,\n",
    "                val_running_loss,\n",
    "                val_qwk,\n",
    "                val_global_step,\n",
    "            )\n",
    "            # add image of conv1 weights to TB\n",
    "            if not CFG.debug:\n",
    "                weights_to_tb(val_global_step)\n",
    "            # add confusion matrix to TB\n",
    "            conf_matrix_to_tb(val_epoch_labels, val_epoch_preds, val_global_step)\n",
    "\n",
    "    # End of loop\n",
    "    return model, best_val_loss, best_qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare CV - strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    folds_fn = \"folds_db.csv\"\n",
    "    try: \n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.sample(n=100, random_state=CFG.seed).reset_index(drop=True).copy()\n",
    "else:\n",
    "    folds_fn = \"folds_cleaned.csv\"\n",
    "    try:\n",
    "        folds = pd.read_csv(PANDA_PATH/folds_fn)\n",
    "    except FileNotFoundError:\n",
    "        folds = TRAIN_DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (PANDA_PATH/folds_fn).exists():\n",
    "    train_labels = folds[CFG.target_col].values\n",
    "    kf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(folds.values, train_labels)):\n",
    "        folds.loc[val_index, 'fold'] = int(fold)\n",
    "    folds['fold'] = folds['fold'].astype(int)\n",
    "    folds.to_csv(PANDA_PATH/folds_fn, index=None)\n",
    "    folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   image_id       100 non-null    object\n",
      " 1   data_provider  100 non-null    object\n",
      " 2   isup_grade     100 non-null    int64 \n",
      " 3   gleason_score  100 non-null    object\n",
      " 4   fold           100 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "folds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get folds (all experiments validated on fold 0)\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "val_df = folds[folds[\"fold\"] == 0].copy()\n",
    "\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False) # same allways to compare with previous results\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = TilesTrainDataset(val_df, is_train=False, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    val_ds = PatchTrainDataset(val_df, debug=False)\n",
    "elif CFG.dataset == \"hdf5\":\n",
    "    train_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_1.h5\", \"patch256x16x1_fold_2.h5\", \"patch256x16x1_fold_3.h5\"])\n",
    "    val_ds = H5PatchDataset(file_path=PANDA_PATH / \"hdf5\", fnames=[\"patch256x16x1_fold_0.h5\"])\n",
    "else:\n",
    "    print(f\"No such dataset {CFG.dataset}\")\n",
    "    \n",
    "# define a data loader\n",
    "if CFG.dataset == \"hdf5\":\n",
    "    # use specific sampler (so not to load hdf5 files to memory too frequently)\n",
    "    sampler = SeqenceRandomSampler(len(train_ds), train_ds._common_len)\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, sampler=sampler, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 8), pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=min(CFG.batch_size, 8), pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedulers\n",
    "def get_scheduler(optimizer,train_dataloader, schedule_type=CFG.schedule_type, resume=False):\n",
    "    assert schedule_type in SCHEDULERS, f\"{schedule_type} not in SCHEDULERS\"\n",
    "    if schedule_type == \"reduce_on_plateau\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, 'min', factor=0.5, patience=CFG.rlopp if not resume else CFG.rlopp + 2, verbose=True), \n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"one_cycle\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, max_lr=[CFG.lr, CFG.lr*10] if CFG.finetune == \"1stage\" else CFG.lr,\n",
    "                                             steps_per_epoch=len(train_dataloader), epochs=CFG.epoch, pct_start=0.05),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    elif schedule_type == \"cawr\":\n",
    "        return (SCHEDULERS[schedule_type][0](optimizer, T_0=len(train_dataloader)*CFG.cawr_T, T_mult=CFG.cawr_Tmult),\n",
    "                SCHEDULERS[schedule_type][1])\n",
    "    else:\n",
    "        return (SCHEDULERS[schedule_type][0],\n",
    "                SCHEDULERS[schedule_type][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(train_df=train_df):\n",
    "    model_ft = PatchModel(arch=CFG.arch)\n",
    "    # initialize bias in the model\n",
    "    cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "    model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "    return model_ft\n",
    "\n",
    "\n",
    "def init_optimizer(model_ft):\n",
    "    if CFG.finetune == \"1stage\":\n",
    "        freeze_botom(model_ft)\n",
    "        interm_params = [\n",
    "            p[1]\n",
    "            for p in model_ft.named_parameters()\n",
    "            if (not p[0].startswith(\"fc\") and p[1].requires_grad)\n",
    "        ]\n",
    "        if CFG.optim == \"adam\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {\"params\": interm_params, \"lr\": CFG.lr},\n",
    "                    {\"params\": model_ft.fc.parameters(), \"lr\": CFG.lr * 10},\n",
    "                ]\n",
    "            )\n",
    "        elif CFG.optim == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                [\n",
    "                    {\"params\": interm_params, \"lr\": CFG.lr},\n",
    "                    {\"params\": model_ft.fc.parameters(), \"lr\": CFG.lr * 10},\n",
    "                ],\n",
    "                momentum=0.9,\n",
    "                nesterov=True,\n",
    "            )\n",
    "    else:\n",
    "        if CFG.optim == \"adam\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model_ft.parameters(), lr=CFG.lr, amsgrad=False\n",
    "            )\n",
    "        elif CFG.optim == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                model_ft.parameters(), lr=CFG.lr, momentum=0.9, nesterov=True\n",
    "            )\n",
    "        elif CFG.optim == \"radam\":\n",
    "            optimizer = RAdam(model_ft.parameters(), lr=CFG.lr)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "criterion = LOSSES[CFG.loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: True seed: 1982 img_height: 256 img_width: 256 target_size: 6 img_id_col: image_id target_col: isup_grade tiff_layer: 1 stoch_sample: True num_tiles: 32 tile_sz: 256 batch_size: 2 accum_step: 2 dataset: patch aug_type: light arch: resnet50 finetune: False model_cls: one_layer loss: ls_soft_ce optim: radam lr: 0.0001 schedule_type: none cawr_T: 1 cawr_Tmult: 2 rlopp: 1 resume: False prev_exp: None from_epoch: 0 stage: 0 epoch: 20 n_fold: 4 use_amp: True descript: Try overfit with basic config\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/1\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/38 [00:00<00:19,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4/38 [00:01<00:13,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 6/38 [00:02<00:10,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/38 [00:02<00:09,  3.18it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "100%|██████████| 38/38 [00:10<00:00,  3.61it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.3343\tValidation Loss: 2.4644\n",
      "Counter train preds: Counter({2: 23, 4: 22, 0: 15, 1: 9, 3: 6})\tCounter val preds: Counter({2: 15, 4: 6, 5: 2, 1: 2})\n",
      "Epoch train QWK: 0.105\tval QWK: -0.118\n",
      "  Epoch 0 - Save Best Loss: 2.4644 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.         0.5        0.         0.33333333 0.16666667]\n",
      " [0.         0.125      0.625      0.         0.25       0.        ]\n",
      " [0.         0.         0.66666667 0.         0.33333333 0.        ]\n",
      " [0.         0.         1.         0.         0.         0.        ]\n",
      " [0.         0.         0.33333333 0.         0.33333333 0.33333333]\n",
      " [0.         0.5        0.5        0.         0.         0.        ]]\n",
      "Epoch 1/1\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:11<00:00,  3.44it/s]\n",
      "100%|██████████| 13/13 [00:02<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.1791\tValidation Loss: 1.8085\n",
      "Counter train preds: Counter({1: 46, 2: 13, 4: 12, 5: 2, 3: 2})\tCounter val preds: Counter({1: 13, 2: 4, 5: 3, 3: 3, 0: 2})\n",
      "Epoch train QWK: 0.020\tval QWK: 0.070\n",
      "  Epoch 1 - Save Best Loss: 1.8085 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.5        0.5        0.         0.         0.        ]\n",
      " [0.         0.75       0.         0.125      0.         0.125     ]\n",
      " [0.         0.66666667 0.33333333 0.         0.         0.        ]\n",
      " [0.         0.33333333 0.         0.33333333 0.         0.33333333]\n",
      " [0.         0.33333333 0.         0.33333333 0.         0.33333333]\n",
      " [1.         0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "model_ft = init_model()\n",
    "optimizer = init_optimizer(model_ft)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)\n",
    "\n",
    "_ = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "#### Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39527bfec9a5472097e0dcab65b96d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 401
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get folds\n",
    "train_df = folds[folds[\"fold\"] != 0].copy()\n",
    "# define datasets\n",
    "if CFG.dataset == \"lazy\":\n",
    "    train_ds = LazyTilesDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"tiles\":\n",
    "    train_ds = TilesTrainDataset(train_df, is_train=CFG.stoch_sample, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "elif CFG.dataset == \"patch\":\n",
    "    train_ds = PatchTrainDataset(train_df, transform=get_transforms(data=\"train\", aug=CFG.aug_type), debug=False)\n",
    "    \n",
    "# define a data loader\n",
    "train_dataloader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=min(CFG.batch_size, 10), pin_memory=True)\n",
    "\n",
    "model_ft = Model(arch=\"resnet34\")\n",
    "# initialize bias in the model\n",
    "cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "model_ft = init_last_layer_bias(model_ft, cls_probas)\n",
    "model_ft.to(device)\n",
    "\n",
    "criterion = LOSSES[CFG.loss]\n",
    "\n",
    "\n",
    "if CFG.finetune == \"1stage\":\n",
    "    freeze_botom(model_ft)\n",
    "    interm_params = [p[1] for p in model_ft.named_parameters() if (not p[0].startswith('fc') and p[1].requires_grad)]\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "                ])\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "                    {'params': interm_params, 'lr': CFG.lr},\n",
    "                    {'params': model_ft.fc.parameters(), 'lr': CFG.lr*10}\n",
    "            ], momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    if CFG.optim == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model_ft.parameters(), lr=CFG.lr * 1e-4, amsgrad=False)\n",
    "    elif CFG.optim == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model_ft.parameters(), lr=CFG.lr * 1e-4, momentum=0.9, nesterov=True)\n",
    "    elif CFG.optim == \"radam\":\n",
    "        optimizer = RAdam(model_ft.parameters(), lr=CFG.lr * 1e-4)\n",
    "    \n",
    "if CFG.use_amp:\n",
    "    model_ft, optimizer = amp.initialize(model_ft, optimizer, opt_level='O1')\n",
    "    \n",
    "lr_finder = LRFinder(model_ft, optimizer, criterion, device=device)\n",
    "lr_finder.range_test(train_dataloader, end_lr=1e-2, num_iter=200, step_mode=\"exp\", accumulation_steps=CFG.accum_step)\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: False\n",
      " seed: 1982\n",
      " img_height: 256\n",
      " img_width: 256\n",
      " target_size: 6\n",
      " img_id_col: image_id\n",
      " target_col: isup_grade\n",
      " tiff_layer: 1\n",
      " stoch_sample: True\n",
      " num_tiles: 32\n",
      " tile_sz: 256\n",
      " batch_size: 2\n",
      " accum_step: 2\n",
      " dataset: patch\n",
      " aug_type: heavy\n",
      " arch: bitM\n",
      " finetune: False\n",
      " model_cls: one_layer\n",
      " loss: ls_soft_ce\n",
      " optim: radam\n",
      " lr: 5e-05\n",
      " schedule_type: none\n",
      " cawr_T: 1\n",
      " cawr_Tmult: 2\n",
      " rlopp: 1\n",
      " epoch: 30\n",
      " n_fold: 4\n",
      " use_amp: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([f\"{key}: {val}\\n\" for key, val in CFG.__dict__.items() if not key.startswith(\"__\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text(\"Experiment Description:\", CFG.descript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = init_model()\n",
    "optimizer = init_optimizer(model_ft)\n",
    "    \n",
    "scheduler, sch_is_epoch_type = get_scheduler(optimizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 0/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/3981 [00:01<53:47,  1.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/3981 [00:01<36:57,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3981 [00:02<28:38,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/3981 [00:03<24:56,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3981 [00:03<22:43,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/3981 [00:04<21:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/3981 [00:05<21:13,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/3981 [00:05<21:20,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/3981 [00:06<21:16,  3.11it/s]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "  1%|          | 20/3981 [00:07<21:40,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/3981 [00:07<21:35,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/3981 [00:09<21:46,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2142/3981 [11:34<09:53,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:24<00:00,  3.10it/s]\n",
      "100%|██████████| 1327/1327 [04:07<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 19.1603\tValidation Loss: 7.1565\n",
      "Counter train preds: Counter({0: 2117, 1: 1941, 2: 1052, 4: 1016, 3: 924, 5: 912})\tCounter val preds: Counter({1: 1380, 2: 1170, 4: 88, 3: 16})\n",
      "Epoch train QWK: 0.189\tval QWK: 0.201\n",
      "  Epoch 0 - Save Best Loss: 7.1565 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.70401107 0.27524205 0.00829876 0.01244813 0.        ]\n",
      " [0.         0.6021021  0.38888889 0.0015015  0.00750751 0.        ]\n",
      " [0.         0.4238806  0.5641791  0.00597015 0.00597015 0.        ]\n",
      " [0.         0.32475884 0.62700965 0.00643087 0.04180064 0.        ]\n",
      " [0.         0.43769968 0.47284345 0.00638978 0.08306709 0.        ]\n",
      " [0.         0.29411765 0.58823529 0.00980392 0.10784314 0.        ]]\n",
      "  Epoch 0 - Save Best QWK: 0.2008 Model\n",
      "Normalized confusion matrix\n",
      "[[0.         0.70401107 0.27524205 0.00829876 0.01244813 0.        ]\n",
      " [0.         0.6021021  0.38888889 0.0015015  0.00750751 0.        ]\n",
      " [0.         0.4238806  0.5641791  0.00597015 0.00597015 0.        ]\n",
      " [0.         0.32475884 0.62700965 0.00643087 0.04180064 0.        ]\n",
      " [0.         0.43769968 0.47284345 0.00638978 0.08306709 0.        ]\n",
      " [0.         0.29411765 0.58823529 0.00980392 0.10784314 0.        ]]\n",
      "Epoch 1/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1282/3981 [06:55<14:10,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:27<00:00,  3.09it/s]\n",
      "100%|██████████| 1327/1327 [04:16<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.5010\tValidation Loss: 5.2417\n",
      "Counter train preds: Counter({0: 2169, 1: 1980, 2: 1080, 5: 926, 4: 910, 3: 897})\tCounter val preds: Counter({0: 2631, 5: 21, 2: 2})\n",
      "Epoch train QWK: 0.298\tval QWK: 0.029\n",
      "  Epoch 1 - Save Best Loss: 5.2417 Model\n",
      "Normalized confusion matrix\n",
      "[[1.         0.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [1.         0.         0.         0.         0.         0.        ]\n",
      " [0.97427653 0.         0.00321543 0.         0.         0.02250804]\n",
      " [0.99041534 0.         0.00319489 0.         0.         0.00638978]\n",
      " [0.96078431 0.         0.         0.         0.         0.03921569]]\n",
      "Epoch 2/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1360/3981 [07:21<13:45,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 3372/3981 [18:15<03:14,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|██████████| 1327/1327 [04:07<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.8300\tValidation Loss: 2.3861\n",
      "Counter train preds: Counter({0: 2281, 1: 2006, 2: 1111, 5: 878, 4: 846, 3: 840})\tCounter val preds: Counter({0: 2286, 3: 310, 5: 54, 2: 4})\n",
      "Epoch train QWK: 0.397\tval QWK: 0.277\n",
      "  Epoch 2 - Save Best Loss: 2.3861 Model\n",
      "Normalized confusion matrix\n",
      "[[0.99861687 0.         0.         0.00138313 0.         0.        ]\n",
      " [0.97597598 0.         0.003003   0.02102102 0.         0.        ]\n",
      " [0.87462687 0.         0.00597015 0.11940299 0.         0.        ]\n",
      " [0.72025723 0.         0.         0.26045016 0.         0.0192926 ]\n",
      " [0.74121406 0.         0.         0.22044728 0.         0.03833866]\n",
      " [0.53921569 0.         0.         0.34313725 0.         0.11764706]]\n",
      "  Epoch 2 - Save Best QWK: 0.2770 Model\n",
      "Normalized confusion matrix\n",
      "[[0.99861687 0.         0.         0.00138313 0.         0.        ]\n",
      " [0.97597598 0.         0.003003   0.02102102 0.         0.        ]\n",
      " [0.87462687 0.         0.00597015 0.11940299 0.         0.        ]\n",
      " [0.72025723 0.         0.         0.26045016 0.         0.0192926 ]\n",
      " [0.74121406 0.         0.         0.22044728 0.         0.03833866]\n",
      " [0.53921569 0.         0.         0.34313725 0.         0.11764706]]\n",
      "Epoch 3/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|██████████| 1327/1327 [04:11<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.2191\tValidation Loss: 1.7778\n",
      "Counter train preds: Counter({0: 2327, 1: 2049, 2: 1043, 5: 893, 3: 832, 4: 818})\tCounter val preds: Counter({1: 1224, 3: 980, 0: 369, 5: 79, 2: 2})\n",
      "Epoch train QWK: 0.507\tval QWK: 0.621\n",
      "  Epoch 3 - Save Best Loss: 1.7778 Model\n",
      "Normalized confusion matrix\n",
      "[[0.43706777 0.48409405 0.         0.07745505 0.         0.00138313]\n",
      " [0.04504505 0.78228228 0.         0.17267267 0.         0.        ]\n",
      " [0.01492537 0.52537313 0.00298507 0.45373134 0.         0.00298507]\n",
      " [0.02250804 0.23151125 0.         0.7266881  0.         0.0192926 ]\n",
      " [0.00958466 0.2428115  0.00319489 0.68690096 0.         0.05750799]\n",
      " [0.02614379 0.09477124 0.         0.70588235 0.         0.17320261]]\n",
      "  Epoch 3 - Save Best QWK: 0.6207 Model\n",
      "Normalized confusion matrix\n",
      "[[0.43706777 0.48409405 0.         0.07745505 0.         0.00138313]\n",
      " [0.04504505 0.78228228 0.         0.17267267 0.         0.        ]\n",
      " [0.01492537 0.52537313 0.00298507 0.45373134 0.         0.00298507]\n",
      " [0.02250804 0.23151125 0.         0.7266881  0.         0.0192926 ]\n",
      " [0.00958466 0.2428115  0.00319489 0.68690096 0.         0.05750799]\n",
      " [0.02614379 0.09477124 0.         0.70588235 0.         0.17320261]]\n",
      "Epoch 4/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 1538/3981 [08:14<12:57,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:20<00:00,  3.11it/s]\n",
      "100%|██████████| 1327/1327 [04:14<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.8518\tValidation Loss: 1.8433\n",
      "Counter train preds: Counter({0: 2368, 1: 2052, 2: 1015, 5: 887, 4: 839, 3: 801})\tCounter val preds: Counter({1: 2047, 4: 603, 5: 2, 2: 1, 3: 1})\n",
      "Epoch train QWK: 0.580\tval QWK: 0.587\n",
      "Epoch 5/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 718/3981 [03:50<17:17,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3340/3981 [17:53<03:21,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:21<00:00,  3.11it/s]\n",
      "100%|██████████| 1327/1327 [04:08<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5739\tValidation Loss: 1.2972\n",
      "Counter train preds: Counter({0: 2479, 1: 2085, 2: 933, 5: 910, 4: 823, 3: 732})\tCounter val preds: Counter({1: 1085, 0: 529, 2: 457, 4: 387, 5: 196})\n",
      "Epoch train QWK: 0.627\tval QWK: 0.722\n",
      "  Epoch 5 - Save Best Loss: 1.2972 Model\n",
      "Normalized confusion matrix\n",
      "[[0.60027663 0.38589212 0.00138313 0.         0.01106501 0.00138313]\n",
      " [0.04804805 0.77327327 0.16966967 0.         0.00900901 0.        ]\n",
      " [0.02686567 0.38507463 0.54328358 0.         0.04179104 0.00298507]\n",
      " [0.05466238 0.22508039 0.29903537 0.         0.31832797 0.10289389]\n",
      " [0.0543131  0.20766773 0.12779553 0.         0.50798722 0.10223642]\n",
      " [0.06535948 0.08823529 0.09150327 0.         0.33006536 0.4248366 ]]\n",
      "  Epoch 5 - Save Best QWK: 0.7224 Model\n",
      "Normalized confusion matrix\n",
      "[[0.60027663 0.38589212 0.00138313 0.         0.01106501 0.00138313]\n",
      " [0.04804805 0.77327327 0.16966967 0.         0.00900901 0.        ]\n",
      " [0.02686567 0.38507463 0.54328358 0.         0.04179104 0.00298507]\n",
      " [0.05466238 0.22508039 0.29903537 0.         0.31832797 0.10289389]\n",
      " [0.0543131  0.20766773 0.12779553 0.         0.50798722 0.10223642]\n",
      " [0.06535948 0.08823529 0.09150327 0.         0.33006536 0.4248366 ]]\n",
      "Epoch 6/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2256/3981 [12:15<09:06,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:35<00:00,  3.07it/s]\n",
      "100%|██████████| 1327/1327 [04:12<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4397\tValidation Loss: 1.3500\n",
      "Counter train preds: Counter({0: 2519, 1: 2075, 2: 947, 5: 869, 4: 816, 3: 736})\tCounter val preds: Counter({0: 1109, 2: 941, 4: 315, 5: 178, 1: 107, 3: 4})\n",
      "Epoch train QWK: 0.670\tval QWK: 0.675\n",
      "Epoch 7/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 548/3981 [02:58<18:14,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:31<00:00,  3.08it/s]\n",
      "100%|██████████| 1327/1327 [04:07<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3493\tValidation Loss: 1.2922\n",
      "Counter train preds: Counter({0: 2503, 1: 2176, 5: 874, 2: 869, 3: 771, 4: 769})\tCounter val preds: Counter({1: 990, 5: 824, 0: 777, 4: 45, 2: 18})\n",
      "Epoch train QWK: 0.689\tval QWK: 0.731\n",
      "  Epoch 7 - Save Best Loss: 1.2922 Model\n",
      "Normalized confusion matrix\n",
      "[[0.85892116 0.1175657  0.         0.         0.00138313 0.02213001]\n",
      " [0.09159159 0.87087087 0.0045045  0.         0.0015015  0.03153153]\n",
      " [0.03283582 0.63880597 0.03283582 0.         0.02686567 0.26865672]\n",
      " [0.08360129 0.19614148 0.0096463  0.         0.04180064 0.66881029]\n",
      " [0.09904153 0.13099042 0.         0.         0.05750799 0.71246006]\n",
      " [0.08823529 0.02941176 0.00326797 0.         0.00980392 0.86928105]]\n",
      "  Epoch 7 - Save Best QWK: 0.7313 Model\n",
      "Normalized confusion matrix\n",
      "[[0.85892116 0.1175657  0.         0.         0.00138313 0.02213001]\n",
      " [0.09159159 0.87087087 0.0045045  0.         0.0015015  0.03153153]\n",
      " [0.03283582 0.63880597 0.03283582 0.         0.02686567 0.26865672]\n",
      " [0.08360129 0.19614148 0.0096463  0.         0.04180064 0.66881029]\n",
      " [0.09904153 0.13099042 0.         0.         0.05750799 0.71246006]\n",
      " [0.08823529 0.02941176 0.00326797 0.         0.00980392 0.86928105]]\n",
      "Epoch 8/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 156/3981 [00:50<20:06,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:34<00:00,  3.07it/s] \n",
      "100%|██████████| 1327/1327 [04:09<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2837\tValidation Loss: 1.3481\n",
      "Counter train preds: Counter({0: 2570, 1: 2151, 5: 906, 2: 845, 4: 778, 3: 712})\tCounter val preds: Counter({1: 1513, 3: 365, 0: 362, 4: 293, 2: 87, 5: 34})\n",
      "Epoch train QWK: 0.714\tval QWK: 0.680\n",
      "Epoch 9/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 306/3981 [01:38<19:37,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 2134/3981 [11:32<10:09,  3.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:27<00:00,  3.09it/s]\n",
      "100%|██████████| 1327/1327 [04:13<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2326\tValidation Loss: 1.3232\n",
      "Counter train preds: Counter({0: 2541, 1: 2245, 5: 892, 2: 820, 4: 751, 3: 713})\tCounter val preds: Counter({0: 962, 1: 810, 3: 471, 2: 233, 5: 178})\n",
      "Epoch train QWK: 0.736\tval QWK: 0.672\n",
      "Epoch 10/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 2160/3981 [11:40<09:33,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:31<00:00,  3.08it/s]\n",
      "100%|██████████| 1327/1327 [04:14<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2019\tValidation Loss: 1.2750\n",
      "Counter train preds: Counter({0: 2557, 1: 2232, 5: 903, 2: 795, 4: 767, 3: 708})\tCounter val preds: Counter({2: 886, 0: 753, 1: 670, 4: 208, 5: 137})\n",
      "Epoch train QWK: 0.741\tval QWK: 0.698\n",
      "  Epoch 10 - Save Best Loss: 1.2750 Model\n",
      "Normalized confusion matrix\n",
      "[[0.86860304 0.08713693 0.03319502 0.         0.00829876 0.00276625]\n",
      " [0.07807808 0.70720721 0.21021021 0.         0.0045045  0.        ]\n",
      " [0.02686567 0.28656716 0.68656716 0.         0.         0.        ]\n",
      " [0.06752412 0.06430868 0.74919614 0.         0.08360129 0.03536977]\n",
      " [0.06709265 0.04792332 0.45047923 0.         0.36741214 0.06709265]\n",
      " [0.07189542 0.01633987 0.38562092 0.         0.18954248 0.33660131]]\n",
      "Epoch 11/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 586/3981 [03:08<18:04,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1964/3981 [10:33<10:41,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:25<00:00,  3.10it/s]\n",
      "100%|██████████| 1327/1327 [04:18<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1942\tValidation Loss: 1.1692\n",
      "Counter train preds: Counter({0: 2558, 1: 2249, 5: 900, 2: 792, 4: 764, 3: 699})\tCounter val preds: Counter({0: 904, 1: 730, 5: 417, 3: 399, 2: 201, 4: 3})\n",
      "Epoch train QWK: 0.740\tval QWK: 0.766\n",
      "  Epoch 11 - Save Best Loss: 1.1692 Model\n",
      "Normalized confusion matrix\n",
      "[[0.92807746 0.05809129 0.00276625 0.00138313 0.         0.00968188]\n",
      " [0.14714715 0.74474474 0.08258258 0.02252252 0.         0.003003  ]\n",
      " [0.07761194 0.40597015 0.28656716 0.20597015 0.         0.0238806 ]\n",
      " [0.11254019 0.11254019 0.08038585 0.49517685 0.         0.19935691]\n",
      " [0.14057508 0.0543131  0.0543131  0.36421725 0.00638978 0.38019169]\n",
      " [0.09803922 0.0130719  0.01960784 0.1503268  0.00326797 0.71568627]]\n",
      "  Epoch 11 - Save Best QWK: 0.7657 Model\n",
      "Normalized confusion matrix\n",
      "[[0.92807746 0.05809129 0.00276625 0.00138313 0.         0.00968188]\n",
      " [0.14714715 0.74474474 0.08258258 0.02252252 0.         0.003003  ]\n",
      " [0.07761194 0.40597015 0.28656716 0.20597015 0.         0.0238806 ]\n",
      " [0.11254019 0.11254019 0.08038585 0.49517685 0.         0.19935691]\n",
      " [0.14057508 0.0543131  0.0543131  0.36421725 0.00638978 0.38019169]\n",
      " [0.09803922 0.0130719  0.01960784 0.1503268  0.00326797 0.71568627]]\n",
      "Epoch 12/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 512/3981 [02:45<18:27,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 948/3981 [05:05<16:23,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:30<00:00,  3.08it/s]\n",
      "100%|██████████| 1327/1327 [04:15<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1954\tValidation Loss: 1.1722\n",
      "Counter train preds: Counter({0: 2554, 1: 2235, 5: 886, 4: 794, 2: 775, 3: 718})\tCounter val preds: Counter({1: 1001, 0: 611, 3: 359, 5: 336, 4: 179, 2: 168})\n",
      "Epoch train QWK: 0.749\tval QWK: 0.769\n",
      "  Epoch 12 - Save Best QWK: 0.7694 Model\n",
      "Normalized confusion matrix\n",
      "[[0.73582296 0.20055325 0.00138313 0.02489627 0.02351314 0.01383126]\n",
      " [0.04504505 0.88138138 0.02102102 0.04654655 0.00600601 0.        ]\n",
      " [0.01791045 0.54626866 0.21492537 0.18208955 0.0119403  0.02686567]\n",
      " [0.06109325 0.15755627 0.13504823 0.39549839 0.08038585 0.17041801]\n",
      " [0.02875399 0.09584665 0.08626198 0.26517572 0.28753994 0.23642173]\n",
      " [0.04901961 0.02287582 0.03921569 0.14052288 0.12745098 0.62091503]]\n",
      "Epoch 13/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 3464/3981 [18:42<02:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:29<00:00,  3.09it/s]\n",
      "100%|██████████| 1327/1327 [04:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1819\tValidation Loss: 1.2266\n",
      "Counter train preds: Counter({0: 2564, 1: 2311, 5: 872, 2: 749, 4: 742, 3: 724})\tCounter val preds: Counter({1: 822, 0: 781, 2: 568, 4: 270, 3: 156, 5: 57})\n",
      "Epoch train QWK: 0.742\tval QWK: 0.705\n",
      "Epoch 14/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 2072/3981 [11:11<10:05,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2088/3981 [11:16<10:02,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:30<00:00,  3.08it/s]\n",
      "100%|██████████| 1327/1327 [04:05<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1747\tValidation Loss: 1.1845\n",
      "Counter train preds: Counter({0: 2554, 1: 2227, 5: 931, 2: 797, 4: 761, 3: 692})\tCounter val preds: Counter({1: 983, 0: 729, 5: 414, 2: 382, 4: 75, 3: 71})\n",
      "Epoch train QWK: 0.753\tval QWK: 0.746\n",
      "Epoch 15/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|███▉      | 1586/3981 [08:34<12:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:38<00:00,  3.07it/s]\n",
      "100%|██████████| 1327/1327 [04:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1715\tValidation Loss: 1.1738\n",
      "Counter train preds: Counter({0: 2569, 1: 2255, 5: 921, 4: 748, 2: 741, 3: 728})\tCounter val preds: Counter({1: 896, 0: 778, 2: 409, 4: 244, 3: 167, 5: 160})\n",
      "Epoch train QWK: 0.753\tval QWK: 0.720\n",
      "Epoch 16/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████▏     | 1646/3981 [08:55<12:17,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3110/3981 [16:53<04:35,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:39<00:00,  3.06it/s]\n",
      "100%|██████████| 1327/1327 [04:16<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1713\tValidation Loss: 1.3259\n",
      "Counter train preds: Counter({0: 2532, 1: 2309, 5: 872, 4: 793, 3: 739, 2: 717})\tCounter val preds: Counter({0: 1155, 5: 745, 2: 432, 1: 244, 4: 43, 3: 35})\n",
      "Epoch train QWK: 0.745\tval QWK: 0.733\n",
      "Epoch 17/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 3678/3981 [20:02<01:35,  3.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3968/3981 [21:37<00:04,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:41<00:00,  3.06it/s]\n",
      "100%|██████████| 1327/1327 [04:14<00:00,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1735\tValidation Loss: 1.3451\n",
      "Counter train preds: Counter({0: 2558, 1: 2256, 5: 924, 3: 747, 4: 742, 2: 735})\tCounter val preds: Counter({5: 848, 0: 785, 1: 584, 4: 253, 2: 184})\n",
      "Epoch train QWK: 0.745\tval QWK: 0.717\n",
      "Epoch 18/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2674/3981 [14:20<06:50,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3348/3981 [17:57<03:18,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3354/3981 [17:59<03:17,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:22<00:00,  3.10it/s]\n",
      "100%|██████████| 1327/1327 [04:10<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1787\tValidation Loss: 1.2389\n",
      "Counter train preds: Counter({0: 2541, 1: 2271, 5: 917, 4: 793, 2: 749, 3: 691})\tCounter val preds: Counter({1: 1210, 0: 467, 4: 412, 3: 314, 5: 156, 2: 95})\n",
      "Epoch train QWK: 0.744\tval QWK: 0.731\n",
      "Epoch 19/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3981/3981 [21:36<00:00,  3.07it/s]\n",
      "100%|██████████| 1327/1327 [04:09<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.1880\tValidation Loss: 1.2366\n",
      "Counter train preds: Counter({0: 2530, 1: 2253, 5: 901, 4: 806, 2: 756, 3: 716})\tCounter val preds: Counter({1: 1158, 0: 756, 5: 347, 2: 287, 3: 54, 4: 52})\n",
      "Epoch train QWK: 0.747\tval QWK: 0.714\n",
      "Epoch 20/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 560/3981 [03:03<18:12,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 2812/3981 [15:13<06:05,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 3166/3981 [17:08<04:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 3174/3981 [17:10<04:14,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3981/3981 [21:34<00:00,  3.08it/s]\n",
      "100%|██████████| 1327/1327 [04:11<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2031\tValidation Loss: 1.4486\n",
      "Counter train preds: Counter({0: 2572, 1: 2256, 5: 920, 2: 770, 4: 757, 3: 687})\tCounter val preds: Counter({1: 1220, 2: 558, 0: 462, 4: 339, 3: 64, 5: 11})\n",
      "Epoch train QWK: 0.741\tval QWK: 0.675\n",
      "Epoch 21/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|██████▉   | 2747/3981 [16:15<07:18,  2.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-30b7658bddd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start Train/Eval Experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_qwk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msch_is_epoch_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEXP_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# After finish collect hyperparams used, best metrics and write to TensorBoard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhparam_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-77f737903aff>\u001b[0m in \u001b[0;36mtrain_eval_loop\u001b[0;34m(train_dataloader, val_dataloader, model, optimizer, criterion, scheduler, sch_is_epoch_type, accum_step, checkpoint, num_epochs, device, tb_tag, model_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_with_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mfp16_grads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mpreexisting_fp32_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             preexisting_fp32_grads)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# fp32 params can be treated as they would be in the \"no_master_weights\" case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/chestxray-uNc73CMC-py3.7/src/apex/apex/amp/scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[0;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Train/Eval Experiment\n",
    "model_ft, best_loss, best_qwk = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, model_name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After finish collect hyperparams used, best metrics and write to TensorBoard\n",
    "hparam_dict = {key:val for key, val in CFG.__dict__.items() if not key.startswith(\"__\")}\n",
    "metric_dict = {\"hp/best_loss\": best_loss, \"hp/best_qwk\": best_qwk}\n",
    "writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)\n",
    "\n",
    "# Get the current git commit hash to add it in Tensorboard, to know exp code version\n",
    "label = subprocess.check_output([\"git\", \"describe\", \"--always\"]).strip()\n",
    "writer.add_text(\"Git commit hash:\", label.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"{MODEL_PATH}/{PREV_NAME}_{CFG.from_epoch}_loss.pth\")\n",
    "\n",
    "model_ft = PatchModel(arch=CFG.arch)\n",
    "model_ft.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_ft.to(device)\n",
    "\n",
    "optimizer = init_optimizer(model_ft)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "# set smaller lr here\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group[\"lr\"] = CFG.lr\n",
    "\n",
    "scheduler, sch_is_epoch_type = get_scheduler(\n",
    "    optimizer, train_dataloader, resume=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-06\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O2\n",
      "cast_model_type        : torch.float16\n",
      "patch_torch_functions  : False\n",
      "keep_batchnorm_fp32    : True\n",
      "master_weights         : True\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "Epoch 18/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1991 [00:02<47:59,  1.45s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1991 [00:02<36:39,  1.11s/it]/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
      "  1%|          | 20/1991 [00:08<10:34,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [11:42<00:00,  2.83it/s]\n",
      "100%|██████████| 664/664 [02:48<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7912\tValidation Loss: 1.0411\n",
      "Counter train preds: Counter({0: 2369, 1: 2107, 2: 919, 5: 874, 4: 857, 3: 836})\tCounter val preds: Counter({1: 801, 0: 785, 5: 329, 4: 296, 2: 236, 3: 207})\n",
      "Epoch train QWK: 0.899\tval QWK: 0.824\n",
      "Epoch 19/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 30/1991 [00:11<10:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1158/1991 [06:40<04:27,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [11:44<00:00,  2.83it/s]\n",
      "100%|██████████| 664/664 [02:52<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7860\tValidation Loss: 1.0326\n",
      "Counter train preds: Counter({0: 2348, 1: 2076, 2: 946, 5: 895, 4: 865, 3: 832})\tCounter val preds: Counter({0: 810, 1: 757, 2: 311, 4: 276, 5: 261, 3: 239})\n",
      "Epoch train QWK: 0.902\tval QWK: 0.823\n",
      "Epoch 20/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 1286/1991 [07:04<03:43,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:55<00:00,  3.04it/s]\n",
      "100%|██████████| 664/664 [02:49<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7739\tValidation Loss: 1.0376\n",
      "Counter train preds: Counter({0: 2346, 1: 2086, 2: 957, 5: 891, 4: 852, 3: 830})\tCounter val preds: Counter({0: 789, 1: 754, 4: 336, 5: 296, 3: 240, 2: 239})\n",
      "Epoch train QWK: 0.908\tval QWK: 0.832\n",
      "  Epoch 20 - Save Best QWK: 0.8318 Model\n",
      "Normalized confusion matrix\n",
      "[[0.9142462  0.07053942 0.00276625 0.00138313 0.00276625 0.00829876]\n",
      " [0.07507508 0.83333333 0.06306306 0.01651652 0.00900901 0.003003  ]\n",
      " [0.03283582 0.32238806 0.42686567 0.13134328 0.06268657 0.0238806 ]\n",
      " [0.09324759 0.05787781 0.11254019 0.45337621 0.17363344 0.10932476]\n",
      " [0.06389776 0.04792332 0.04792332 0.07348243 0.62939297 0.13738019]\n",
      " [0.05882353 0.02287582 0.00653595 0.06535948 0.18300654 0.66339869]]\n",
      "Epoch 21/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1560/1991 [08:07<02:12,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:21<00:00,  3.20it/s]\n",
      "100%|██████████| 664/664 [02:46<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7603\tValidation Loss: 1.0409\n",
      "Counter train preds: Counter({0: 2350, 1: 2056, 2: 916, 4: 881, 3: 881, 5: 878})\tCounter val preds: Counter({1: 823, 0: 772, 4: 322, 5: 297, 2: 238, 3: 202})\n",
      "Epoch train QWK: 0.913\tval QWK: 0.827\n",
      "Epoch 22/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [11:03<00:00,  3.00it/s]\n",
      "100%|██████████| 664/664 [02:51<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7578\tValidation Loss: 1.0242\n",
      "Counter train preds: Counter({0: 2364, 1: 2060, 2: 930, 5: 881, 3: 875, 4: 852})\tCounter val preds: Counter({0: 806, 1: 774, 3: 282, 2: 271, 4: 265, 5: 256})\n",
      "Epoch train QWK: 0.905\tval QWK: 0.819\n",
      "  Epoch 22 - Save Best Loss: 1.0242 Model\n",
      "Normalized confusion matrix\n",
      "[[0.91839557 0.06777317 0.00276625 0.00276625 0.00276625 0.0055325 ]\n",
      " [0.08258258 0.84234234 0.05555556 0.01201201 0.003003   0.0045045 ]\n",
      " [0.03283582 0.34925373 0.48358209 0.10447761 0.01791045 0.0119403 ]\n",
      " [0.09967846 0.06430868 0.14790997 0.49839228 0.10289389 0.08681672]\n",
      " [0.08306709 0.06070288 0.0543131  0.15974441 0.5399361  0.10223642]\n",
      " [0.0620915  0.02614379 0.02287582 0.10457516 0.17647059 0.60784314]]\n",
      "Epoch 23/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 532/1991 [02:55<07:40,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:51<00:00,  3.06it/s]\n",
      "100%|██████████| 664/664 [02:51<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7567\tValidation Loss: 1.0275\n",
      "Counter train preds: Counter({0: 2333, 1: 2082, 2: 934, 5: 883, 3: 871, 4: 859})\tCounter val preds: Counter({0: 810, 1: 695, 2: 351, 5: 290, 4: 287, 3: 221})\n",
      "Epoch train QWK: 0.910\tval QWK: 0.825\n",
      "Epoch 24/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1991/1991 [11:17<00:00,  2.94it/s]\n",
      "100%|██████████| 664/664 [02:50<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7417\tValidation Loss: 1.0299\n",
      "Counter train preds: Counter({0: 2346, 1: 2052, 2: 938, 5: 900, 3: 869, 4: 857})\tCounter val preds: Counter({0: 802, 1: 775, 5: 302, 3: 301, 4: 272, 2: 202})\n",
      "Epoch train QWK: 0.918\tval QWK: 0.829\n",
      "Epoch 25/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 552/1991 [02:54<07:19,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1424/1991 [07:37<02:50,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:35<00:00,  3.13it/s]\n",
      "100%|██████████| 664/664 [02:47<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7373\tValidation Loss: 1.0288\n",
      "Counter train preds: Counter({0: 2352, 1: 2050, 2: 920, 5: 899, 3: 876, 4: 865})\tCounter val preds: Counter({0: 794, 1: 760, 5: 304, 3: 277, 2: 275, 4: 244})\n",
      "Epoch train QWK: 0.914\tval QWK: 0.827\n",
      "Epoch 26/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▍  | 1488/1991 [07:48<02:34,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:30<00:00,  3.16it/s]\n",
      "100%|██████████| 664/664 [02:53<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7313\tValidation Loss: 1.0301\n",
      "Counter train preds: Counter({0: 2340, 1: 2038, 2: 941, 5: 896, 3: 889, 4: 858})\tCounter val preds: Counter({0: 795, 1: 761, 4: 295, 5: 290, 3: 276, 2: 237})\n",
      "Epoch train QWK: 0.919\tval QWK: 0.828\n",
      "Epoch 27/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 1630/1991 [09:15<01:51,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [11:12<00:00,  2.96it/s]\n",
      "100%|██████████| 664/664 [02:48<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7174\tValidation Loss: 1.0293\n",
      "Counter train preds: Counter({0: 2331, 1: 2038, 2: 968, 5: 887, 4: 876, 3: 862})\tCounter val preds: Counter({0: 806, 1: 744, 4: 304, 5: 297, 2: 271, 3: 232})\n",
      "Epoch train QWK: 0.928\tval QWK: 0.830\n",
      "Epoch 28/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 1854/1991 [10:05<00:44,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [10:49<00:00,  3.07it/s]\n",
      "100%|██████████| 664/664 [02:45<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.7082\tValidation Loss: 1.0334\n",
      "Counter train preds: Counter({0: 2310, 1: 2049, 2: 958, 5: 900, 4: 888, 3: 857})\tCounter val preds: Counter({0: 777, 1: 752, 4: 342, 2: 287, 3: 255, 5: 241})\n",
      "Epoch train QWK: 0.927\tval QWK: 0.836\n",
      "  Epoch 28 - Save Best QWK: 0.8358 Model\n",
      "Normalized confusion matrix\n",
      "[[0.90871369 0.07192254 0.00414938 0.00414938 0.0055325  0.0055325 ]\n",
      " [0.07657658 0.82432432 0.07207207 0.01951952 0.0045045  0.003003  ]\n",
      " [0.02686567 0.33432836 0.48955224 0.09850746 0.03880597 0.0119403 ]\n",
      " [0.08038585 0.06109325 0.15434084 0.45016077 0.17684887 0.07717042]\n",
      " [0.06070288 0.04472843 0.06070288 0.12140575 0.62619808 0.08626198]\n",
      " [0.05228758 0.01960784 0.01633987 0.09150327 0.23202614 0.58823529]]\n",
      "Epoch 29/29\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1991/1991 [11:31<00:00,  2.88it/s]\n",
      "100%|██████████| 664/664 [02:57<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6978\tValidation Loss: 1.0287\n",
      "Counter train preds: Counter({0: 2313, 1: 2049, 2: 946, 5: 895, 4: 891, 3: 868})\tCounter val preds: Counter({0: 819, 1: 726, 5: 297, 2: 274, 3: 270, 4: 268})\n",
      "Epoch train QWK: 0.932\tval QWK: 0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Train/Eval Experiment\n",
    "model_ft, best_loss, best_qwk = train_eval_loop(train_dataloader, val_dataloader, model_ft, optimizer, criterion, scheduler, sch_is_epoch_type, checkpoint=checkpoint, model_name=PREV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After finish collect hyperparams used, best metrics and write to TensorBoard\n",
    "hparam_dict = {key:val for key, val in CFG.__dict__.items() if not key.startswith(\"__\")}\n",
    "metric_dict = {\"hp/best_loss\": best_loss, \"hp/best_qwk\": best_qwk}\n",
    "writer.add_hparams(hparam_dict=hparam_dict, metric_dict=metric_dict)\n",
    "\n",
    "# Get the current git commit hash to add it in Tensorboard, to know exp code version\n",
    "label = subprocess.check_output([\"git\", \"describe\", \"--always\"]).strip()\n",
    "writer.add_text(\"Git commit hash:\", label.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with CV, on fold 0\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7832\tValidation Loss: 1.6735\n",
      "Counter train preds: Counter({1: 50, 4: 11, 3: 8, 0: 6})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.193\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5393\tValidation Loss: 1.6932\n",
      "Counter train preds: Counter({1: 39, 0: 21, 3: 7, 4: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.236\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4436\tValidation Loss: 1.7056\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 7, 5: 5, 4: 3})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.321\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4152\tValidation Loss: 1.6723\n",
      "Counter train preds: Counter({0: 33, 1: 31, 3: 5, 4: 5, 5: 1})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.282\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3904\tValidation Loss: 1.6386\n",
      "Counter train preds: Counter({1: 33, 0: 28, 4: 6, 3: 5, 5: 3})\tCounter val preds: Counter({1: 15, 5: 3, 0: 3, 2: 2, 4: 1, 3: 1})\n",
      "Epoch train QWK: 0.393\tval QWK: 0.186\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3730\tValidation Loss: 1.6927\n",
      "Counter train preds: Counter({0: 33, 1: 26, 5: 7, 3: 4, 4: 4, 2: 1})\tCounter val preds: Counter({1: 13, 5: 6, 2: 4, 3: 1, 0: 1})\n",
      "Epoch train QWK: 0.517\tval QWK: 0.545\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3238\tValidation Loss: 1.8837\n",
      "Counter train preds: Counter({0: 30, 1: 29, 5: 6, 3: 6, 4: 4})\tCounter val preds: Counter({1: 9, 5: 7, 2: 6, 3: 3})\n",
      "Epoch train QWK: 0.438\tval QWK: 0.329\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3055\tValidation Loss: 2.0990\n",
      "Counter train preds: Counter({1: 34, 0: 22, 5: 8, 3: 7, 4: 2, 2: 2})\tCounter val preds: Counter({2: 12, 5: 5, 3: 5, 1: 2, 4: 1})\n",
      "Epoch train QWK: 0.552\tval QWK: 0.326\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.53it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3063\tValidation Loss: 2.0883\n",
      "Counter train preds: Counter({1: 35, 0: 25, 4: 7, 3: 5, 5: 3})\tCounter val preds: Counter({2: 13, 5: 5, 1: 3, 3: 2, 4: 1, 0: 1})\n",
      "Epoch train QWK: 0.549\tval QWK: 0.199\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.73it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.8377\n",
      "Counter train preds: Counter({1: 37, 0: 24, 5: 7, 4: 3, 3: 3, 2: 1})\tCounter val preds: Counter({1: 21, 3: 2, 2: 1, 5: 1})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.305\n",
      "Train with CV, on fold 1\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7209\tValidation Loss: 1.7380\n",
      "Counter train preds: Counter({0: 59, 3: 15, 1: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.263\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5459\tValidation Loss: 1.7958\n",
      "Counter train preds: Counter({0: 36, 1: 32, 3: 5, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.331\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.36it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4606\tValidation Loss: 1.9763\n",
      "Counter train preds: Counter({1: 34, 0: 29, 4: 8, 3: 4})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4206\tValidation Loss: 1.8872\n",
      "Counter train preds: Counter({1: 32, 0: 24, 4: 8, 3: 6, 5: 3, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.441\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4067\tValidation Loss: 2.2129\n",
      "Counter train preds: Counter({1: 36, 0: 25, 3: 10, 5: 2, 2: 1, 4: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.388\tval QWK: 0.000\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3640\tValidation Loss: 2.9000\n",
      "Counter train preds: Counter({1: 33, 0: 24, 3: 12, 2: 4, 4: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.364\tval QWK: 0.000\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3085\tValidation Loss: 2.7819\n",
      "Counter train preds: Counter({1: 33, 0: 20, 3: 11, 2: 4, 4: 4, 5: 3})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.568\tval QWK: 0.000\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3142\tValidation Loss: 2.3783\n",
      "Counter train preds: Counter({1: 36, 0: 21, 3: 9, 2: 5, 5: 3, 4: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.435\tval QWK: 0.116\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2917\tValidation Loss: 3.1009\n",
      "Counter train preds: Counter({1: 38, 0: 19, 2: 6, 4: 5, 3: 4, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.433\tval QWK: 0.009\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2545\tValidation Loss: 2.9466\n",
      "Counter train preds: Counter({1: 32, 0: 20, 3: 10, 4: 5, 2: 5, 5: 3})\tCounter val preds: Counter({0: 23, 2: 2})\n",
      "Epoch train QWK: 0.635\tval QWK: 0.009\n",
      "Train with CV, on fold 2\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.6856\tValidation Loss: 1.8174\n",
      "Counter train preds: Counter({1: 48, 3: 15, 0: 12})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.208\tval QWK: 0.000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5455\tValidation Loss: 2.4182\n",
      "Counter train preds: Counter({1: 37, 0: 21, 3: 16, 2: 1})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.313\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4741\tValidation Loss: 2.2700\n",
      "Counter train preds: Counter({1: 33, 0: 26, 3: 14, 2: 2})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.287\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4289\tValidation Loss: 2.4097\n",
      "Counter train preds: Counter({1: 35, 0: 28, 3: 7, 2: 5})\tCounter val preds: Counter({0: 25})\n",
      "Epoch train QWK: 0.247\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:01,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3615\tValidation Loss: 2.0392\n",
      "Counter train preds: Counter({1: 39, 0: 25, 3: 7, 2: 4})\tCounter val preds: Counter({0: 24, 2: 1})\n",
      "Epoch train QWK: 0.307\tval QWK: 0.064\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4250\tValidation Loss: 1.6867\n",
      "Counter train preds: Counter({1: 41, 0: 26, 3: 8})\tCounter val preds: Counter({0: 20, 2: 3, 1: 2})\n",
      "Epoch train QWK: 0.266\tval QWK: 0.214\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3328\tValidation Loss: 1.7360\n",
      "Counter train preds: Counter({1: 34, 0: 24, 3: 12, 2: 4, 5: 1})\tCounter val preds: Counter({0: 18, 1: 5, 2: 2})\n",
      "Epoch train QWK: 0.365\tval QWK: 0.130\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3236\tValidation Loss: 1.8248\n",
      "Counter train preds: Counter({1: 33, 0: 21, 2: 13, 3: 6, 5: 2})\tCounter val preds: Counter({0: 17, 1: 5, 2: 3})\n",
      "Epoch train QWK: 0.316\tval QWK: 0.272\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2498\tValidation Loss: 2.4719\n",
      "Counter train preds: Counter({1: 34, 0: 24, 2: 8, 3: 8, 5: 1})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.392\tval QWK: 0.259\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2657\tValidation Loss: 2.4212\n",
      "Counter train preds: Counter({1: 39, 0: 21, 2: 6, 3: 6, 5: 3})\tCounter val preds: Counter({0: 22, 2: 3})\n",
      "Epoch train QWK: 0.409\tval QWK: 0.259\n",
      "Train with CV, on fold 3\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.78it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.7337\tValidation Loss: 1.6500\n",
      "Counter train preds: Counter({1: 49, 2: 14, 0: 6, 5: 3, 3: 3})\tCounter val preds: Counter({1: 24, 0: 1})\n",
      "Epoch train QWK: 0.123\tval QWK: -0.030\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.5647\tValidation Loss: 1.7000\n",
      "Counter train preds: Counter({1: 40, 0: 18, 3: 12, 2: 5})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.232\tval QWK: 0.000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4733\tValidation Loss: 1.6935\n",
      "Counter train preds: Counter({1: 33, 0: 27, 3: 13, 2: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.337\tval QWK: 0.000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.4141\tValidation Loss: 1.6876\n",
      "Counter train preds: Counter({0: 29, 1: 28, 3: 10, 2: 6, 5: 2})\tCounter val preds: Counter({1: 25})\n",
      "Epoch train QWK: 0.475\tval QWK: 0.000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3655\tValidation Loss: 1.6186\n",
      "Counter train preds: Counter({1: 35, 0: 26, 3: 7, 5: 4, 2: 3})\tCounter val preds: Counter({1: 21, 2: 3, 0: 1})\n",
      "Epoch train QWK: 0.395\tval QWK: 0.012\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3591\tValidation Loss: 1.6763\n",
      "Counter train preds: Counter({1: 32, 0: 23, 3: 11, 2: 8, 5: 1})\tCounter val preds: Counter({2: 17, 0: 6, 1: 2})\n",
      "Epoch train QWK: 0.413\tval QWK: 0.313\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3191\tValidation Loss: 1.6529\n",
      "Counter train preds: Counter({1: 34, 0: 26, 3: 5, 2: 4, 4: 4, 5: 2})\tCounter val preds: Counter({1: 12, 2: 9, 5: 2, 0: 2})\n",
      "Epoch train QWK: 0.424\tval QWK: 0.269\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3050\tValidation Loss: 1.7019\n",
      "Counter train preds: Counter({1: 36, 0: 21, 2: 6, 3: 5, 5: 4, 4: 3})\tCounter val preds: Counter({2: 13, 5: 7, 4: 3, 0: 2})\n",
      "Epoch train QWK: 0.454\tval QWK: 0.364\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.99it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2645\tValidation Loss: 1.7029\n",
      "Counter train preds: Counter({1: 36, 0: 22, 5: 7, 2: 5, 3: 4, 4: 1})\tCounter val preds: Counter({2: 10, 5: 5, 0: 5, 1: 4, 3: 1})\n",
      "Epoch train QWK: 0.461\tval QWK: 0.309\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.2169\tValidation Loss: 2.0975\n",
      "Counter train preds: Counter({1: 33, 0: 22, 2: 9, 3: 6, 5: 5})\tCounter val preds: Counter({4: 14, 5: 8, 0: 3})\n",
      "Epoch train QWK: 0.530\tval QWK: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"test_fold_{}.pth\"\n",
    "for fold in range(CFG.n_fold):\n",
    "    train_df = folds[folds[\"fold\"] != fold].copy()\n",
    "    val_df = folds[folds[\"fold\"] == fold].copy()\n",
    "    \n",
    "    train_ds = TrainDataset(train_df, transform=get_transforms(data=\"train\"), debug=False)\n",
    "    val_ds = TrainDataset(val_df, transform=get_transforms(data=\"valid\"), debug=False)\n",
    "    \n",
    "    model = TinyV2ConvNet(CFG.target_size)\n",
    "    # initialize bias in the model\n",
    "    cls_probas = (train_df[CFG.target_col].value_counts() / len(train_df)).values\n",
    "    model = init_last_layer_bias(model, cls_probas)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n",
    "    print(f\"Train with CV, on fold {fold}\")\n",
    "    model = train_eval_loop(train_ds, val_ds, model, optimizer, criterion, tb_tag=fold)\n",
    "    torch.save(model.state_dict(), MODEL_PATH/checkpoint.format(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chestxray",
   "language": "python",
   "name": "chestxray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
